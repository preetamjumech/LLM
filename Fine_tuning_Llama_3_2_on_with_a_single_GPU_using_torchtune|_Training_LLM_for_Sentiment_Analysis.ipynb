{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPFF4ND1gbPpWROQ7mPuQK0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preetamjumech/LLM/blob/main/Fine_tuning_Llama_3_2_on_with_a_single_GPU_using_torchtune%7C_Training_LLM_for_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRfGlyFYtN3a",
        "outputId": "9a9861f1-c5f3-4e55-ddbc-ff69381716fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uqqq pip --progress-bar off\n",
        "!pip install -qqq torchtune==0.3.1 --progress-bar off\n",
        "!pip install -qqq torchao==0.6.1 --progress-bar off\n",
        "!pip install -qqq transformers==4.46.1 --progress-bar off"
      ],
      "metadata": {
        "id": "FNGkEtr9t8y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.colors as colors\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from google.colab import userdata\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "COLORS = [\"#bae1ff\", \"#ffb3ba\", \"#ffdfba\", \"#ffffba\", \"#baffc9\"]\n",
        "\n",
        "sns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.2)\n",
        "sns.set_palette(sns.color_palette(COLORS))\n",
        "\n",
        "cmap = colors.LinearSegmentedColormap.from_list(\"custom_cmap\", COLORS[:2])\n",
        "\n",
        "MY_STYLE = {\n",
        "    \"figure.facecolor\": \"black\",\n",
        "    \"axes.facecolor\": \"black\",\n",
        "    \"axes.edgecolor\": \"white\",\n",
        "    \"axes.labelcolor\": \"white\",\n",
        "    \"axes.linewidth\": 0.5,\n",
        "    \"text.color\": \"white\",\n",
        "    \"xtick.color\": \"white\",\n",
        "    \"ytick.color\": \"white\",\n",
        "    \"grid.color\": \"gray\",\n",
        "    \"grid.linestyle\": \"--\",\n",
        "    \"grid.linewidth\": 0.5,\n",
        "    \"axes.grid\": True,\n",
        "    \"xtick.labelsize\": \"medium\",\n",
        "    \"ytick.labelsize\": \"medium\",\n",
        "    \"axes.titlesize\": \"large\",\n",
        "    \"axes.labelsize\": \"large\",\n",
        "    \"lines.color\": COLORS[0],\n",
        "    \"patch.edgecolor\": \"white\",\n",
        "}\n",
        "\n",
        "mpl.rcParams.update(MY_STYLE)\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "np.random.seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "-B0UKf1CuDS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1UD8fN6JvbJkBOPhfwjlaIONCE45hVH7Q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWIT9O78uDV3",
        "outputId": "661a30d3-107b-421c-cb4c-721b6c27998d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UD8fN6JvbJkBOPhfwjlaIONCE45hVH7Q\n",
            "To: /content/mental-health-sentiment.csv\n",
            "100% 31.5M/31.5M [00:00<00:00, 154MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"mental-health-sentiment.csv\")"
      ],
      "metadata": {
        "id": "FFGvj6h1uDav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "6rAeh6lQuDdG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"word_count\"] = df.statement.apply(lambda x: len(x.split(\" \")))"
      ],
      "metadata": {
        "id": "MBSrjdZxuDfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(\n",
        "    df.word_count, weights=np.ones(len(df.word_count)) / len(df.word_count), bins=30\n",
        ")\n",
        "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
        "plt.xlabel(\"Words\")\n",
        "plt.ylabel(\"Percentage\")\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SgQVc1VWuDiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[[\"statement\", \"status\", \"word_count\"]]"
      ],
      "metadata": {
        "id": "b757uk69vsNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "kn1uTAUSvsQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "status_counts = df[\"status\"].value_counts(normalize=True)\n",
        "plt.bar(status_counts.index, status_counts.values)\n",
        "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
        "plt.xlabel(\"Status\")\n",
        "plt.ylabel(\"Percentage\")\n",
        "plt.ylim(0, 0.5)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1MPIyM5xvsSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df[df.word_count < 1000]) / len(df)"
      ],
      "metadata": {
        "id": "y4odee2FvsUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df.word_count < 1000]\n",
        "df.shape"
      ],
      "metadata": {
        "id": "VyJz1CAjvsW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_samples = 5000\n",
        "df_sampled = df.groupby(\"status\")[[\"statement\", \"status\"]].apply(\n",
        "    lambda x: x.sample(n=min(len(x), max_samples))\n",
        ")\n",
        "df_sampled = df_sampled.reset_index(drop=True)\n",
        "df_sampled.head()"
      ],
      "metadata": {
        "id": "guC0cYVovsbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sampled.shape"
      ],
      "metadata": {
        "id": "VmqQWUEovseY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(\n",
        "    df_sampled, test_size=0.2, random_state=RANDOM_SEED\n",
        ")\n",
        "train_df.shape, test_df.shape"
      ],
      "metadata": {
        "id": "DD9f9YPVwbYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\n",
        "    \"normal\",\n",
        "    \"depression\",\n",
        "    \"suicidal\",\n",
        "    \"anxiety\",\n",
        "    \"bipolar\",\n",
        "    \"stress\",\n",
        "    \"personality disorder\",\n",
        "]\n",
        ""
      ],
      "metadata": {
        "id": "Ygj0uzXLwba2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt(statement: str, class_names: List[str]):\n",
        "    prompt = \"\"\"\n",
        "Classify the text for one of the categories:\n",
        "\n",
        "\n",
        "\n",
        "Choose from one of the category:\n",
        "{classes}\n",
        "Only choose one category, the most appropriate one. Reply only with the category.\n",
        "\"\"\".strip()\n",
        "    return prompt.format(text=statement, classes=\", \".join(class_names))\n",
        ""
      ],
      "metadata": {
        "id": "WytvQuO4wbc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(df):\n",
        "    rows = []\n",
        "    for _, row in tqdm(df.iterrows()):\n",
        "        rows.append(\n",
        "            {\n",
        "                \"input\": create_prompt(row.statement, class_names),\n",
        "                \"output\": row.status.lower(),\n",
        "            }\n",
        "        )\n",
        "    return rows"
      ],
      "metadata": {
        "id": "mcTjyI8cwbff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_rows = create_dataset(train_df)\n",
        "test_rows = create_dataset(test_df)"
      ],
      "metadata": {
        "id": "Tg-6-yz5wbhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Path(\"train_data.json\").write_text(json.dumps(train_rows))\n",
        "Path(\"test_data.json\").write_text(json.dumps(test_rows))"
      ],
      "metadata": {
        "id": "H9DfdPlzwbkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_token = userdata.get(\"HF_TOKEN\")"
      ],
      "metadata": {
        "id": "4j2ZU1vVwbm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tune download \"meta-llama/Llama-3.2-1B-Instruct\" \\\n",
        "  --output-dir \"./Llama-3.2-1B-Instruct\" \\\n",
        "  --hf-token \"{hf_token}\" \\\n",
        "  --ignore-patterns \"[]\""
      ],
      "metadata": {
        "id": "MWtUyNxQwbpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"./Llama-3.2-1B-Instruct\"\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "id": "7FBytELwzikJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predictions = []\n",
        "true_values = []\n",
        "for row in tqdm(test_rows):\n",
        "    messages = [{\"role\": \"user\", \"content\": create_prompt(row[\"input\"], class_names)}]\n",
        "    outputs = generator(\n",
        "        messages, max_new_tokens=32, pad_token_id=generator.tokenizer.eos_token_id\n",
        "    )\n",
        "    predictions.append(outputs[0][\"generated_text\"][-1][\"content\"].lower())\n",
        "    true_values.append(row[\"output\"])\n",
        ""
      ],
      "metadata": {
        "id": "vvRhP-21zinA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regex = r\"^\\W+|\\W+$\"\n",
        "predictions = [re.sub(regex, \"\", p) for p in predictions]"
      ],
      "metadata": {
        "id": "BUdh09rzzipq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(true_values), len(predictions)"
      ],
      "metadata": {
        "id": "PFm0C_2jzir6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(predictions).value_counts()"
      ],
      "metadata": {
        "id": "wUnNBvz7ziuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(true_values, predictions)"
      ],
      "metadata": {
        "id": "_EJ5UdVHziwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df = pd.DataFrame.from_dict({\"label\": true_values, \"prediction\": predictions})\n",
        "eval_df.head()"
      ],
      "metadata": {
        "id": "As7qv4CE0ooo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(eval_df[~eval_df.prediction.isin(class_names)])"
      ],
      "metadata": {
        "id": "JtRhFj-e0oro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df = eval_df[eval_df.prediction.isin(class_names)]"
      ],
      "metadata": {
        "id": "6cPyuZ0L0oth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(eval_df.label, eval_df.prediction))"
      ],
      "metadata": {
        "id": "DiU9Uxlc0ov3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine tuning"
      ],
      "metadata": {
        "id": "4Rim0UJE1L02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = \"\"\"\n",
        "# Model Arguments\n",
        "model:\n",
        "  _component_: torchtune.models.llama3_2.lora_llama3_2_1b\n",
        "  lora_attn_modules: ['q_proj', 'v_proj', 'output_proj']\n",
        "  apply_lora_to_mlp: True\n",
        "  apply_lora_to_output: False\n",
        "  lora_rank: 64\n",
        "  lora_alpha: 128\n",
        "  lora_dropout: 0.0\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer:\n",
        "  _component_: torchtune.models.llama3.llama3_tokenizer\n",
        "  path: ./Llama-3.2-1B-Instruct/original/tokenizer.model\n",
        "  max_seq_len: null\n",
        "\n",
        "checkpointer:\n",
        "  _component_: torchtune.training.FullModelHFCheckpointer\n",
        "  checkpoint_dir: ./Llama-3.2-1B-Instruct\n",
        "  checkpoint_files: [\n",
        "    model.safetensors\n",
        "  ]\n",
        "  recipe_checkpoint: null\n",
        "  output_dir: ./checkpoints\n",
        "  model_type: LLAMA3_2\n",
        "resume_from_checkpoint: False\n",
        "save_adapter_weights_only: False\n",
        "\n",
        "# Dataset and Sampler\n",
        "dataset:\n",
        "  _component_: torchtune.datasets.instruct_dataset\n",
        "  data_files: ./train_data.json\n",
        "  source: json\n",
        "  split: train\n",
        "seed: 42\n",
        "shuffle: True\n",
        "# batch_size: 1\n",
        "batch_size: 4\n",
        "\n",
        "# Optimizer and Scheduler\n",
        "optimizer:\n",
        "  _component_: torch.optim.AdamW\n",
        "  fused: True\n",
        "  weight_decay: 0.01\n",
        "  lr: 3e-4\n",
        "lr_scheduler:\n",
        "  _component_: torchtune.modules.get_cosine_schedule_with_warmup\n",
        "  num_warmup_steps: 100\n",
        "\n",
        "loss:\n",
        "  _component_: torchtune.modules.loss.CEWithChunkedOutputLoss\n",
        "\n",
        "# Training\n",
        "epochs: 1\n",
        "max_steps_per_epoch: null\n",
        "gradient_accumulation_steps: 4\n",
        "compile: False # set it to True for better memory and performance\n",
        "# compile: True # set it to True for better memory and performance\n",
        "\n",
        "# Logging\n",
        "output_dir: ./logs\n",
        "metric_logger:\n",
        "  _component_: torchtune.training.metric_logging.TensorBoardLogger\n",
        "  log_dir: {output_dir} log_every_n_steps: 1 log_peak_memory_stats: False # Environment device: cuda dtype: bf16 # Activations Memory enable_activation_checkpointing: False enable_activation_offloading: False # Profiler (disabled) profiler: _component_: torchtune.training.setup_torch_profiler enabled: False #Output directory of trace artifacts output_dir:\n",
        "{output_dir}/profiling_outputs\n",
        "\n",
        "  #`torch.profiler.ProfilerActivity` types to trace\n",
        "  cpu: True\n",
        "  cuda: True\n",
        "\n",
        "  #trace options passed to `torch.profiler.profile`\n",
        "  profile_memory: False\n",
        "  with_stack: False\n",
        "  record_shapes: True\n",
        "  with_flops: False\n",
        "\n",
        "  # `torch.profiler.schedule` options:\n",
        "  # wait_steps -> wait, warmup_steps -> warmup, active_steps -> active, num_cycles -> repeat\n",
        "  wait_steps: 5\n",
        "  warmup_steps: 5\n",
        "  active_steps: 2\n",
        "  num_cycles: 1\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "AOQAUKSs0oyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Path(\"custom_config.yaml\").write_text(config)"
      ],
      "metadata": {
        "id": "ZyDEtFUB0o0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints"
      ],
      "metadata": {
        "id": "mZBoVfhB3iqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tune run lora_finetune_single_device --config \"custom_config.yaml\" epochs=1"
      ],
      "metadata": {
        "id": "Q4tGU1ME3is9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"logs\""
      ],
      "metadata": {
        "id": "YBn12DJz3ivE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "W8OaUwst3uF9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#upload the model"
      ],
      "metadata": {
        "id": "MJXVrxsW3uJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir hf_repo"
      ],
      "metadata": {
        "id": "Pu7uVqCu3ixz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"checkpoints/hf_model_0001_0.pt\" \"hf_repo/pytorch_model.bin\"\n",
        "!cp \"checkpoints/config.json\" \"hf_repo/\"\n",
        "!cp \"Llama-3.2-1B-Instruct/original/tokenizer.model\" \"hf_repo/\"\n",
        "!cp \"Llama-3.2-1B-Instruct/generation_config.json\" \"hf_repo/\"\n",
        "!cp \"Llama-3.2-1B-Instruct/tokenizer.json\" \"hf_repo/\"\n",
        "!cp \"Llama-3.2-1B-Instruct/tokenizer_config.json\" \"hf_repo/\"\n",
        "!cp \"Llama-3.2-1B-Instruct/special_tokens_map.json\" \"hf_repo/\"\n",
        "!cp \"Llama-3.2-1B-Instruct/LICENSE.txt\" \"hf_repo/\"\n",
        "!cp \"Llama-3.2-1B-Instruct/README.md\" \"hf_repo/\"\n",
        "!cp \"Llama-3.2-1B-Instruct/USE_POLICY.md\" \"hf_repo/\""
      ],
      "metadata": {
        "id": "ulPeQBSk3i0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "K9NyUmng3i2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli upload \"curiousily/Llama-3.2-1B-Mental-Health-Sentiment\" \"hf_repo\""
      ],
      "metadata": {
        "id": "1EmEusxP3i42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = \"curiousily/Llama-3.2-1B-Mental-Health-Sentiment\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH).to(\"cuda\")"
      ],
      "metadata": {
        "id": "l7Rcft6E3i7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation"
      ],
      "metadata": {
        "id": "nLEP86GB4xTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\n",
        "    task=\"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=128,\n",
        "    temperature=0.000001,\n",
        "    return_full_text=False,\n",
        "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    device=\"cuda\",\n",
        ")"
      ],
      "metadata": {
        "id": "CXMb0GML4y89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = json.loads(Path(\"test_data.json\").read_text())"
      ],
      "metadata": {
        "id": "YzO8AWSL42CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = test_data[4][\"input\"]\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "CyXn-Bto42FL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "for example in tqdm(test_data):\n",
        "    statement = example[\"input\"]\n",
        "    prompt = [\n",
        "        {\"role\": \"user\", \"content\": statement},\n",
        "    ]\n",
        "    output = pipe(prompt)\n",
        "    predictions.append(output[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "kVfyF_aA42Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(predictions).value_counts()"
      ],
      "metadata": {
        "id": "WhesP9sH42M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df = pd.DataFrame.from_dict({\"label\": true_values, \"prediction\": predictions})\n",
        "eval_df.head()"
      ],
      "metadata": {
        "id": "Lue6Lrjf5NVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(true_values, predictions)"
      ],
      "metadata": {
        "id": "k5FNOorN5Nad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(eval_df.label, eval_df.prediction))"
      ],
      "metadata": {
        "id": "8tVq8tYa5Nc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vn55dDyk5NfN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}