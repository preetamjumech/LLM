{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7462x7/uCe+FzYBUiDJb8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "57005feab5c144d2a2520d7a072ec4b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f859b3f9cae486ba47a86eaa41f6989",
              "IPY_MODEL_e74a70ab920a46618d28848c1e5c6f7b",
              "IPY_MODEL_d92777bd183a42d9b237752d1a4fda25"
            ],
            "layout": "IPY_MODEL_2187893a050e42d9bd98b199ea454fd8"
          }
        },
        "1f859b3f9cae486ba47a86eaa41f6989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48ba25f4cef641f49253f00f34a4957a",
            "placeholder": "​",
            "style": "IPY_MODEL_cc67073998f242709244ebf163acf347",
            "value": "yolox_l0.05.onnx: 100%"
          }
        },
        "e74a70ab920a46618d28848c1e5c6f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_669ff54985f741ad817391ea8f80d445",
            "max": 216625723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f922c7dfba4446e5beccdca90513f54c",
            "value": 216625723
          }
        },
        "d92777bd183a42d9b237752d1a4fda25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dd3c16930784fed850b2f168bd40137",
            "placeholder": "​",
            "style": "IPY_MODEL_5182812aad1a4ac889e4f7a89c510752",
            "value": " 217M/217M [00:01&lt;00:00, 140MB/s]"
          }
        },
        "2187893a050e42d9bd98b199ea454fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48ba25f4cef641f49253f00f34a4957a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc67073998f242709244ebf163acf347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "669ff54985f741ad817391ea8f80d445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f922c7dfba4446e5beccdca90513f54c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dd3c16930784fed850b2f168bd40137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5182812aad1a4ac889e4f7a89c510752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8f86b6c93c949919535e477b64ae1ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5591526650e451da4a852a3cfcc84b0",
              "IPY_MODEL_52c9d779156d4890a77f6345eca40505",
              "IPY_MODEL_e5a014f8457f4d51a452ee1e85dbf905"
            ],
            "layout": "IPY_MODEL_4a31c2853aef44348e165621881ed43d"
          }
        },
        "f5591526650e451da4a852a3cfcc84b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ccc75a8923d4080abf1ee76a481d282",
            "placeholder": "​",
            "style": "IPY_MODEL_fa744d8af07f40e78d2e5e18ee94b256",
            "value": ""
          }
        },
        "52c9d779156d4890a77f6345eca40505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb1babb721b84f9787a447d7ce87809a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3d2aa8ddc36422b808467787f3202c3",
            "value": 0
          }
        },
        "e5a014f8457f4d51a452ee1e85dbf905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f043c38dc844e05bb315f6b456f8cc8",
            "placeholder": "​",
            "style": "IPY_MODEL_b3d85469e340438aabafb1d842cffbb3",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "4a31c2853aef44348e165621881ed43d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ccc75a8923d4080abf1ee76a481d282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa744d8af07f40e78d2e5e18ee94b256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb1babb721b84f9787a447d7ce87809a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e3d2aa8ddc36422b808467787f3202c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f043c38dc844e05bb315f6b456f8cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3d85469e340438aabafb1d842cffbb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa454f8569f644a3862ff4f92f7711c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5e774eaadab4e039022205e4ef5c22e",
              "IPY_MODEL_2ed2dc4e545647df80779891efe42019",
              "IPY_MODEL_4a5472e320cc4155a0f669ee8f4fa149"
            ],
            "layout": "IPY_MODEL_895a73d8443348aeaa82f30454b3fd9f"
          }
        },
        "d5e774eaadab4e039022205e4ef5c22e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b187ab7d4d194bc9ac1127c3f0b0e280",
            "placeholder": "​",
            "style": "IPY_MODEL_b8dd92320c46431a83f55fbb83f47a65",
            "value": "config.json: 100%"
          }
        },
        "2ed2dc4e545647df80779891efe42019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_711eb369f16146fba4cbd1ee57e4ac27",
            "max": 1469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8e0839363f74df0a20a0945b3a1cb4e",
            "value": 1469
          }
        },
        "4a5472e320cc4155a0f669ee8f4fa149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_282591a7337c4869a75d9f585f018db9",
            "placeholder": "​",
            "style": "IPY_MODEL_5c09134103dd4cceb0ac3bb3195f4ec6",
            "value": " 1.47k/1.47k [00:00&lt;00:00, 93.2kB/s]"
          }
        },
        "895a73d8443348aeaa82f30454b3fd9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b187ab7d4d194bc9ac1127c3f0b0e280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8dd92320c46431a83f55fbb83f47a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "711eb369f16146fba4cbd1ee57e4ac27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8e0839363f74df0a20a0945b3a1cb4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "282591a7337c4869a75d9f585f018db9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c09134103dd4cceb0ac3bb3195f4ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90d8adff903b47ccb9f8d057f38db5cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be949b9dbac64d1ca89783c3df32dc0e",
              "IPY_MODEL_5e6051c5b169414d86c84ab14f04a7fa",
              "IPY_MODEL_b9cb1f3585fa4829af35b847a7bf0c7d"
            ],
            "layout": "IPY_MODEL_6db86b823d5945709f19652c02c24d5c"
          }
        },
        "be949b9dbac64d1ca89783c3df32dc0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32560d95ff17457aa62662719d9281f7",
            "placeholder": "​",
            "style": "IPY_MODEL_4f95af22ced84f8a9ad9104ae01b41ef",
            "value": "model.safetensors: 100%"
          }
        },
        "5e6051c5b169414d86c84ab14f04a7fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58afbfa917074b5bb08a8821ef4c276a",
            "max": 115434268,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93243101441e408e9791a830b4ec4a45",
            "value": 115434268
          }
        },
        "b9cb1f3585fa4829af35b847a7bf0c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc6dd5188054427b360cb93162835b0",
            "placeholder": "​",
            "style": "IPY_MODEL_959059f4bb8b4adc8fcabbe6397397db",
            "value": " 115M/115M [00:01&lt;00:00, 135MB/s]"
          }
        },
        "6db86b823d5945709f19652c02c24d5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32560d95ff17457aa62662719d9281f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f95af22ced84f8a9ad9104ae01b41ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58afbfa917074b5bb08a8821ef4c276a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93243101441e408e9791a830b4ec4a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdc6dd5188054427b360cb93162835b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "959059f4bb8b4adc8fcabbe6397397db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff7fdfc0519b474e8e31a926059bde02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da0d1133dea048068754c5d50f57887a",
              "IPY_MODEL_50e9cd71db554ee4b8ba4708726aed1b",
              "IPY_MODEL_10c48c4d082349209e80550ae839d951"
            ],
            "layout": "IPY_MODEL_7399e5f71ae0468b87807e54c08a3667"
          }
        },
        "da0d1133dea048068754c5d50f57887a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9c5eb1783c84a3aa2ad4998ea9a84d8",
            "placeholder": "​",
            "style": "IPY_MODEL_b23fd39780da48e6918603333629a1cf",
            "value": "model.safetensors: 100%"
          }
        },
        "50e9cd71db554ee4b8ba4708726aed1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a76575a27c7246328aaf14deaf86ef1f",
            "max": 46807446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_715b8dc5a61e41aea4799250add4aad0",
            "value": 46807446
          }
        },
        "10c48c4d082349209e80550ae839d951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adfe3e2bb82741f588323a280dbe89db",
            "placeholder": "​",
            "style": "IPY_MODEL_c979539f796941838bde7c4def0308a1",
            "value": " 46.8M/46.8M [00:00&lt;00:00, 122MB/s]"
          }
        },
        "7399e5f71ae0468b87807e54c08a3667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9c5eb1783c84a3aa2ad4998ea9a84d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b23fd39780da48e6918603333629a1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a76575a27c7246328aaf14deaf86ef1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "715b8dc5a61e41aea4799250add4aad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "adfe3e2bb82741f588323a280dbe89db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c979539f796941838bde7c4def0308a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preetamjumech/LLM/blob/main/Extract_Table_Info_From_SCANNED_PDF_%26_Question_Answering_from_it_Using_Llama3_1_LangChain_05_11_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EL6HAtBP2iJo"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install \"unstructured[all-docs]\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "Xp7xXsbs3DAQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import JSON\n",
        "\n",
        "import json\n",
        "\n",
        "from unstructured.partition.html import partition_html\n",
        "from unstructured.partition.pdf import partition_pdf\n",
        "from unstructured.staging.base import dict_to_elements, elements_to_json"
      ],
      "metadata": {
        "id": "im5GJ7yU3DDf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip show unstructured"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kClE7p8a3DFx",
        "outputId": "eeaec710-a69c-4ba8-a49e-823777971db0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: unstructured\n",
            "Version: 0.16.4\n",
            "Summary: A library that prepares raw documents for downstream ML tasks.\n",
            "Home-page: https://github.com/Unstructured-IO/unstructured\n",
            "Author: Unstructured Technologies\n",
            "Author-email: devops@unstructuredai.io\n",
            "License: Apache-2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: backoff, beautifulsoup4, chardet, dataclasses-json, emoji, filetype, html5lib, langdetect, lxml, nltk, numpy, psutil, python-iso639, python-magic, python-oxmsg, rapidfuzz, requests, tqdm, typing-extensions, unstructured-client, wrapt\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unstructured.partition\n",
        "\n",
        "help(unstructured.partition)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFUkMS323DIH",
        "outputId": "4716fb7a-cef2-4ee7-fec5-a805df6a46d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on package unstructured.partition in unstructured:\n",
            "\n",
            "NAME\n",
            "    unstructured.partition\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "    api\n",
            "    auto\n",
            "    common (package)\n",
            "    csv\n",
            "    doc\n",
            "    docx\n",
            "    email\n",
            "    epub\n",
            "    html (package)\n",
            "    image\n",
            "    json\n",
            "    md\n",
            "    model_init\n",
            "    msg\n",
            "    odt\n",
            "    org\n",
            "    pdf\n",
            "    pdf_image (package)\n",
            "    ppt\n",
            "    pptx\n",
            "    rst\n",
            "    rtf\n",
            "    strategies\n",
            "    text\n",
            "    text_type\n",
            "    tsv\n",
            "    utils (package)\n",
            "    xlsx\n",
            "    xml\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.10/dist-packages/unstructured/partition/__init__.py\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y poppler-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zUm5iA933iP",
        "outputId": "2e1d7a68-f208-4736-b55c-000dc93f4424"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.5 [186 kB]\n",
            "Fetched 186 kB in 1s (212 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 123623 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.5_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGBngi-a33lO",
        "outputId": "5e43320e-e81b-49a5-ad31-9e801ac888d7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 2s (2,875 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123653 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "frdhdL0J4-Ct",
        "outputId": "81f867d0-1536-49be-d4ec-2a6ac76e0e5f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nltk\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "Successfully installed nltk-3.9.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk"
                ]
              },
              "id": "af7ede732bb442fcb60f4470781dfa8c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt', download_dir='/root/nltk_data')\n",
        "nltk.download('punkt_tab', download_dir='/root/nltk_data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH9_J7du380d",
        "outputId": "649aaeb0-b561-4bf2-c812-48c421fd3534"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "print(nltk.__version__) #must be 3.9.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nmrdeWB4vNM",
        "outputId": "0cd89136-bb88-4b86-d00f-c5e6709d280c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured.partition.pdf import partition_pdf\n",
        "\n",
        "# Specify the path to your PDF file\n",
        "filename = \"/content/gpt4all.pdf\"\n",
        "\n",
        "# Call the partition_pdf function\n",
        "# Returns a List[Element] present in the pages of the parsed pdf document\n",
        "elements = partition_pdf(filename)\n",
        "\n",
        "# Now, elements is a list of all elements present in the pages of the parsed pdf document"
      ],
      "metadata": {
        "id": "G6E3nkIz3DKn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elements"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VD2n8yY5iLV",
        "outputId": "044d119d-611f-4b50-fda0-2fb1b19b81b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<unstructured.documents.elements.Text at 0x7a0e72794be0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72795180>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72795570>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e727948b0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72795660>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e727956c0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e727957e0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e727958a0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72795930>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72795a20>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72795b10>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72795bd0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72795cf0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72796650>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72795d50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e72795e40>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e72795f60>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e72796710>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e72796800>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e727968f0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72796a10>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e72795db0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72796200>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e72795390>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e72796ad0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72796590>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e72796b30>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74774be0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72794850>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74638280>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e746383a0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74638460>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74638550>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e74638670>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74638730>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e746388e0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e746389d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74638a60>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e74638b80>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74638b20>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74638d60>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e74638eb0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e74638f40>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74638fa0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74639120>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e74639240>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74639150>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f521ab0>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f521ae0>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f521cc0>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f521db0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f521e70>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f521f60>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f522050>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e74775d20>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f5222f0>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f5224a0>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f522680>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e74777820>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f522a40>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f522c20>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f522e00>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f522200>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f5223e0>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f522590>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f522770>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f522950>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f522b30>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f522d10>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f522ef0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f523190>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f522fe0>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f5230d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74634130>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74634220>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74634610>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74634160>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e74634430>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74634520>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e74634700>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e746347f0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e746348e0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d4190>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e746368f0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f5d42e0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f5d43d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f5d4460>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d4520>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f5d46d0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d4790>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d4820>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d4a00>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f5d4ac0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f5d4bb0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f5d4ca0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f5d4d90>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d4a30>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d4fa0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d5030>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d51b0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f5d5270>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d52d0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d5180>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f5d54b0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d5660>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f5d55a0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d5840>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d58d0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d5930>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f5d5a50>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d5c30>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d5bd0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d5c60>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d5f00>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d5ea0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d5f30>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e6f5d61d0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d62c0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d62f0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d6440>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f5d65f0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d6710>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d6920>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d6860>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f5d67d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f5d6ad0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f5d6bc0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f5d6bf0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f5d6b90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f319360>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e6f318f40>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f3190c0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f319150>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e6f3192a0>]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(elements)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rJLBkXU5iOD",
        "outputId": "4ce96148-ee24-4737-ad53-290f6f593569"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "134"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "element_dict = [el.to_dict() for el in elements]\n",
        "output = json.dumps(element_dict, indent=2)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjJoGjNN5iQL",
        "outputId": "08b4e6f6-c6a0-4273-8949-e64979d6a211"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"b0c5cfcf93a217591e27d5c97845f59b\",\n",
            "    \"text\": \"3 2 0 2\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            16.34,\n",
            "            263.81000000000006\n",
            "          ],\n",
            "          [\n",
            "            16.34,\n",
            "            303.81000000000006\n",
            "          ],\n",
            "          [\n",
            "            36.34,\n",
            "            303.81000000000006\n",
            "          ],\n",
            "          [\n",
            "            36.34,\n",
            "            263.81000000000006\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"d71e9973e25dde0d96dc422b5a8fd429\",\n",
            "    \"text\": \"v o N 6\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            16.34,\n",
            "            308.81000000000006\n",
            "          ],\n",
            "          [\n",
            "            16.34,\n",
            "            358.25\n",
            "          ],\n",
            "          [\n",
            "            36.34,\n",
            "            358.25\n",
            "          ],\n",
            "          [\n",
            "            36.34,\n",
            "            308.81000000000006\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"da9a4b336f710784f847aa01becae2d8\",\n",
            "    \"text\": \"] L C . s c [\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            16.34,\n",
            "            368.24999999999994\n",
            "          ],\n",
            "          [\n",
            "            16.34,\n",
            "            428.78999999999996\n",
            "          ],\n",
            "          [\n",
            "            36.34,\n",
            "            428.78999999999996\n",
            "          ],\n",
            "          [\n",
            "            36.34,\n",
            "            368.24999999999994\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"cf466a5a422c76d228e6f9c56a8428ce\",\n",
            "    \"text\": \"1 v 1 3 9 4 0 . 1 1 3 2 : v i X r a\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            16.34,\n",
            "            438.78999999999996\n",
            "          ],\n",
            "          [\n",
            "            16.34,\n",
            "            604.89\n",
            "          ],\n",
            "          [\n",
            "            36.34,\n",
            "            604.89\n",
            "          ],\n",
            "          [\n",
            "            36.34,\n",
            "            438.78999999999996\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"da9a4b336f710784f847aa01becae2d8\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"741c25a4fb94e81aa7239a1c0534a9e8\",\n",
            "    \"text\": \"GPT4All: An Ecosystem of Open Source Compressed Language Models\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            77.497,\n",
            "            78.40315579999992\n",
            "          ],\n",
            "          [\n",
            "            77.497,\n",
            "            92.74935579999999\n",
            "          ],\n",
            "          [\n",
            "            517.7818779999999,\n",
            "            92.74935579999999\n",
            "          ],\n",
            "          [\n",
            "            517.7818779999999,\n",
            "            78.40315579999992\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"3f394fcdfd3c020fa260d031c7aa3551\",\n",
            "    \"text\": \"Yuvanesh Anand Nomic AI yuvanesh@nomic.ai\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            69.06,\n",
            "            110.08451589999993\n",
            "          ],\n",
            "          [\n",
            "            69.06,\n",
            "            150.07418739999991\n",
            "          ],\n",
            "          [\n",
            "            170.67834999999997,\n",
            "            150.07418739999991\n",
            "          ],\n",
            "          [\n",
            "            170.67834999999997,\n",
            "            110.08451589999993\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"c9f10a02ba1baf5861871dea2427ea13\",\n",
            "    \"text\": \"Zach Nussbaum Nomic AI zach@nomic.ai\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            196.531,\n",
            "            110.08451589999993\n",
            "          ],\n",
            "          [\n",
            "            196.531,\n",
            "            150.07418739999991\n",
            "          ],\n",
            "          [\n",
            "            279.2363818,\n",
            "            150.07418739999991\n",
            "          ],\n",
            "          [\n",
            "            279.2363818,\n",
            "            110.08451589999993\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"1fb7ac4ca22ad79ab5acc099895231b9\",\n",
            "    \"text\": \"Adam Treat Nomic AI adam@nomic.ai\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            318.538,\n",
            "            110.08451589999993\n",
            "          ],\n",
            "          [\n",
            "            318.538,\n",
            "            150.07418739999991\n",
            "          ],\n",
            "          [\n",
            "            396.24615,\n",
            "            150.07418739999991\n",
            "          ],\n",
            "          [\n",
            "            396.24615,\n",
            "            110.08451589999993\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"c3528c06b42170925c8845cd0516afaf\",\n",
            "    \"text\": \"Aaron Miller Nomic AI aaron@nomic.ai\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            435.058,\n",
            "            110.08451589999993\n",
            "          ],\n",
            "          [\n",
            "            435.058,\n",
            "            150.07418739999991\n",
            "          ],\n",
            "          [\n",
            "            518.7436999999999,\n",
            "            150.07418739999991\n",
            "          ],\n",
            "          [\n",
            "            518.7436999999999,\n",
            "            110.08451589999993\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"87aa6b53bb4ad01ca3786c2082164fa2\",\n",
            "    \"text\": \"Richard Guo Nomic AI richard@nomic.ai\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            100.43099999999997,\n",
            "            173.28351589999988\n",
            "          ],\n",
            "          [\n",
            "            100.43099999999997,\n",
            "            213.27318739999987\n",
            "          ],\n",
            "          [\n",
            "            196.07179999999994,\n",
            "            213.27318739999987\n",
            "          ],\n",
            "          [\n",
            "            196.07179999999994,\n",
            "            173.28351589999988\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"0f9ab7485cd89cf606234ade290a822f\",\n",
            "    \"text\": \"Ben Schmidt Nomic AI ben@nomic.ai\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            261.77199999999993,\n",
            "            173.28351589999988\n",
            "          ],\n",
            "          [\n",
            "            261.77199999999993,\n",
            "            213.27318739999987\n",
            "          ],\n",
            "          [\n",
            "            333.5026,\n",
            "            213.27318739999987\n",
            "          ],\n",
            "          [\n",
            "            333.5026,\n",
            "            173.28351589999988\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"9eace5e83f6c7f55784da14b30801a6e\",\n",
            "    \"text\": \"GPT4All Community Planet Earth\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            392.05999999999995,\n",
            "            173.28351589999988\n",
            "          ],\n",
            "          [\n",
            "            392.05999999999995,\n",
            "            199.54930159999992\n",
            "          ],\n",
            "          [\n",
            "            501.98714449999994,\n",
            "            199.54930159999992\n",
            "          ],\n",
            "          [\n",
            "            501.98714449999994,\n",
            "            173.28351589999988\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"adefd49403515997446e8633e38d94f7\",\n",
            "    \"text\": \"Brandon Duderstadt\\u2217 Nomic AI brandon@nomic.ai\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            145.07499999999993,\n",
            "            235.17709939999986\n",
            "          ],\n",
            "          [\n",
            "            145.07499999999993,\n",
            "            276.4731873999999\n",
            "          ],\n",
            "          [\n",
            "            255.25451412999993,\n",
            "            276.4731873999999\n",
            "          ],\n",
            "          [\n",
            "            255.25451412999993,\n",
            "            235.17709939999986\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"\\u2217\",\n",
            "          \"url\": \"Hfootnote.1\",\n",
            "          \"start_index\": 18\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"aa800040abcb3a68245ea9e047eb25a1\",\n",
            "    \"text\": \"Andriy Mulyar\\u2217 Nomic AI andriy@nomic.ai\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            352.39699999999993,\n",
            "            235.17709939999997\n",
            "          ],\n",
            "          [\n",
            "            352.39699999999993,\n",
            "            276.47318740000003\n",
            "          ],\n",
            "          [\n",
            "            442.06024999999994,\n",
            "            276.47318740000003\n",
            "          ],\n",
            "          [\n",
            "            442.06024999999994,\n",
            "            235.17709939999997\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"e083963f2380b8c5311d045f988e23fa\",\n",
            "    \"text\": \"Abstract\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            157.75799999999992,\n",
            "            304.80951590000006\n",
            "          ],\n",
            "          [\n",
            "            157.75799999999992,\n",
            "            316.7646159000001\n",
            "          ],\n",
            "          [\n",
            "            202.24292709999992,\n",
            "            316.7646159000001\n",
            "          ],\n",
            "          [\n",
            "            202.24292709999992,\n",
            "            304.80951590000006\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"a90d3e5cedb83aa21ccdb130e575542b\",\n",
            "    \"text\": \"Large language models (LLMs) have recently achieved human-level performance on a range of professional and academic benchmarks. The accessibility of these models has lagged behind their performance. State-of-the-art LLMs re- quire costly infrastructure; are only accessible via rate-limited, geo-locked, and censored web interfaces; and lack publicly available code and technical reports.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            87.625,\n",
            "            331.47432159999994\n",
            "          ],\n",
            "          [\n",
            "            87.625,\n",
            "            437.07792159999997\n",
            "          ],\n",
            "          [\n",
            "            273.7749204880001,\n",
            "            437.07792159999997\n",
            "          ],\n",
            "          [\n",
            "            273.7749204880001,\n",
            "            331.47432159999994\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"e083963f2380b8c5311d045f988e23fa\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"3f27ae624f926eb91c661791f642f9e3\",\n",
            "    \"text\": \"In this paper, we tell the story of GPT4All, a popular open source repository that aims to democratize access to LLMs. We outline the technical details of the original GPT4All model family, as well as the evolution of the GPT4All project from a single model into a fully fledged open source ecosystem. It is our hope that this paper acts as both a technical overview of the original GPT4All models as well as a case study on the subsequent growth of the GPT4All open source ecosystem.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            87.874,\n",
            "            444.3423216\n",
            "          ],\n",
            "          [\n",
            "            87.874,\n",
            "            573.8569216\n",
            "          ],\n",
            "          [\n",
            "            272.1287004640001,\n",
            "            573.8569216\n",
            "          ],\n",
            "          [\n",
            "            272.1287004640001,\n",
            "            444.3423216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"e083963f2380b8c5311d045f988e23fa\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"185bfce5f50e0f150589bc1d066df5a9\",\n",
            "    \"text\": \"variety of queries, responding only with the now infa- mous \\\"As an AI Language Model, I cannot...\\\" prefix (Vincent, 2023). These transparency and accessibility concerns spurred several developers to begin creating open source large language model (LLM) alternatives. Several grassroots efforts focused on fine tuning Meta\\u2019s open code LLaMA model (Touvron et al., 2023; McMil- lan, 2023), whose weights were leaked on BitTorrent less than a week prior to the release of GPT-4 (Verge, 2023). GPT4All started as one of these variants.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            305.813,\n",
            "            306.45532159999993\n",
            "          ],\n",
            "          [\n",
            "            305.813,\n",
            "            424.01392159999995\n",
            "          ],\n",
            "          [\n",
            "            526.1474706388001,\n",
            "            424.01392159999995\n",
            "          ],\n",
            "          [\n",
            "            526.1474706388001,\n",
            "            306.45532159999993\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Vincent\",\n",
            "          \"url\": \"cite.verge2023ai\",\n",
            "          \"start_index\": 106\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.verge2023ai\",\n",
            "          \"start_index\": 115\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Touvron et al .,\",\n",
            "          \"url\": \"cite.touvron2023llama\",\n",
            "          \"start_index\": 345\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.touvron2023llama\",\n",
            "          \"start_index\": 361\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"McMil -\",\n",
            "          \"url\": \"cite.wsj_llama\",\n",
            "          \"start_index\": 367\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"lan\",\n",
            "          \"url\": \"cite.wsj_llama\",\n",
            "          \"start_index\": 374\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.wsj_llama\",\n",
            "          \"start_index\": 379\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Verge\",\n",
            "          \"url\": \"cite.verge-meta-ai-leak-2023\",\n",
            "          \"start_index\": 474\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.verge-meta-ai-leak-2023\",\n",
            "          \"start_index\": 481\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"e083963f2380b8c5311d045f988e23fa\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"c4a4c71ac956e6c69d6d761d32e81e0f\",\n",
            "    \"text\": \"In this paper, we tell the story of GPT4All. We com- ment on the technical details of the original GPT4All model (Anand et al., 2023), as well as the evolution of GPT4All from a single model to an ecosystem of several models. We remark on the impact that the project has had on the open source community, and discuss future directions. It is our hope that this paper acts as both a technical overview of the original GPT4All models as well as a case study on the subsequent growth of the GPT4All open source ecosystem.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            305.783,\n",
            "            426.5143216\n",
            "          ],\n",
            "          [\n",
            "            305.783,\n",
            "            544.0729216\n",
            "          ],\n",
            "          [\n",
            "            526.0674912600001,\n",
            "            544.0729216\n",
            "          ],\n",
            "          [\n",
            "            526.0674912600001,\n",
            "            426.5143216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Anand et al .,\",\n",
            "          \"url\": \"cite.gpt4all\",\n",
            "          \"start_index\": 114\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.gpt4all\",\n",
            "          \"start_index\": 128\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"e083963f2380b8c5311d045f988e23fa\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"4c756886e4dbf688c1568c8e65bda77d\",\n",
            "    \"text\": \"2 The Original GPT4All Model\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            557.3085159\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            569.2636159\n",
            "          ],\n",
            "          [\n",
            "            474.5295835,\n",
            "            569.2636159\n",
            "          ],\n",
            "          [\n",
            "            474.5295835,\n",
            "            557.3085159\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"49fcd165ead3de8d30afc73d0ac33943\",\n",
            "    \"text\": \"2.1 Data Collection and Curation\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            578.7575833999999\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            588.7201834\n",
            "          ],\n",
            "          [\n",
            "            454.4751514,\n",
            "            588.7201834\n",
            "          ],\n",
            "          [\n",
            "            454.4751514,\n",
            "            578.7575833999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"b06f3763a242682a426d25678eee97da\",\n",
            "    \"text\": \"1\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            589.5385159\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            601.4936159\n",
            "          ],\n",
            "          [\n",
            "            76.84355,\n",
            "            601.4936159\n",
            "          ],\n",
            "          [\n",
            "            76.84355,\n",
            "            589.5385159\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"49fcd165ead3de8d30afc73d0ac33943\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"ce826364cf996377d784570e339ddbcd\",\n",
            "    \"text\": \"Introduction\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            88.79865,\n",
            "            589.5385159\n",
            "          ],\n",
            "          [\n",
            "            88.79865,\n",
            "            601.4936159\n",
            "          ],\n",
            "          [\n",
            "            153.6789777,\n",
            "            601.4936159\n",
            "          ],\n",
            "          [\n",
            "            153.6789777,\n",
            "            589.5385159\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"3abe933a09cfef67aa4b1b9a3a889472\",\n",
            "    \"text\": \"On March 14 2023, OpenAI released GPT-4, a large language model capable of achieving human level per- formance on a variety of professional and academic benchmarks. Despite the popularity of the release, the GPT-4 technical report (OpenAI, 2023) contained virtually no details regarding the architecture, hard- ware, training compute, dataset construction, or training method used to create the model. Moreover, users could only access the model through the internet interface at chat.openai.com, which was severely rate limited and unavailable in several locales (e.g. Italy) (BBC News, 2023). Additionally, GPT-4 refused to answer a wide\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.507,\n",
            "            611.3753216\n",
            "          ],\n",
            "          [\n",
            "            70.507,\n",
            "            752.8449216\n",
            "          ],\n",
            "          [\n",
            "            290.7879641256002,\n",
            "            752.8449216\n",
            "          ],\n",
            "          [\n",
            "            290.7879641256002,\n",
            "            611.3753216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"OpenAI\",\n",
            "          \"url\": \"cite.openai2023gpt4\",\n",
            "          \"start_index\": 232\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.openai2023gpt4\",\n",
            "          \"start_index\": 240\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"BBC News\",\n",
            "          \"url\": \"cite.bbc2023chatgpt\",\n",
            "          \"start_index\": 578\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"ce826364cf996377d784570e339ddbcd\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"b11f30bd83a1069848654cfbd663d188\",\n",
            "    \"text\": \"To train the original GPT4All model, we collected roughly one million prompt-response pairs using the GPT-3.5-Turbo OpenAI API between March 20, 2023 and March 26th, 2023. In particular, we gathered GPT- 3.5-Turbo responses to prompts of three publicly avail- able datasets: the unified chip2 subset of LAION OIG, a random sub-sample of Stackoverflow Questions, and a sub-sample of Bigscience/P3 (Sanh et al., 2021). Fol- lowing the approach in Stanford Alpaca (Taori et al., 2023), an open source LLaMA variant that came just be- fore GPT4All, we focused substantial effort on dataset curation.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            305.833,\n",
            "            595.3333216\n",
            "          ],\n",
            "          [\n",
            "            305.833,\n",
            "            736.8029216\n",
            "          ],\n",
            "          [\n",
            "            526.0666639902,\n",
            "            736.8029216\n",
            "          ],\n",
            "          [\n",
            "            526.0666639902,\n",
            "            595.3333216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Sanh et al .,\",\n",
            "          \"url\": \"cite.sanh2021multitask\",\n",
            "          \"start_index\": 395\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2021\",\n",
            "          \"url\": \"cite.sanh2021multitask\",\n",
            "          \"start_index\": 408\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Taori et al .,\",\n",
            "          \"url\": \"cite.alpaca\",\n",
            "          \"start_index\": 460\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.alpaca\",\n",
            "          \"start_index\": 474\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"ce826364cf996377d784570e339ddbcd\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"3c7c5445f2556bdd972aa11024143f8e\",\n",
            "    \"text\": \"\\u2217 Shared Senior Authorship\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            85.81,\n",
            "            763.3930544\n",
            "          ],\n",
            "          [\n",
            "            85.81,\n",
            "            772.8172968\n",
            "          ],\n",
            "          [\n",
            "            177.0362924,\n",
            "            772.8172968\n",
            "          ],\n",
            "          [\n",
            "            177.0362924,\n",
            "            763.3930544\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 1,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"4ab72a88d0df5f2cb17bd34cb4904132\",\n",
            "    \"text\": \"The collected dataset was loaded into Atlas (AI, 2023)\\u2014a visual interface for exploring and tagging mas- sive unstructured datasets \\u2014for data curation. Using At-\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            739.3033216\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            773.1759216\n",
            "          ],\n",
            "          [\n",
            "            526.0614137000001,\n",
            "            773.1759216\n",
            "          ],\n",
            "          [\n",
            "            526.0614137000001,\n",
            "            739.3033216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"AI\",\n",
            "          \"url\": \"cite.atlas-nomic-ai\",\n",
            "          \"start_index\": 45\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.atlas-nomic-ai\",\n",
            "          \"start_index\": 49\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"3c7c5445f2556bdd972aa11024143f8e\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"3a30a05cb24cdd567f6da500d522c05f\",\n",
            "    \"text\": \"las, we identified and removed subsets of the data where GPT-3.5-Turbo refused to respond, had malformed out- put, or produced a very short response. This resulted in the removal of the entire Bigscience/P3 subset of our data, as many P3 prompts induced responses that were simply one word. After curation, we were left with a set of 437,605 prompt-response pairs, which we visualize in Figure 1a.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            74.0143215999999\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            167.6629216\n",
            "          ],\n",
            "          [\n",
            "            290.7879242752001,\n",
            "            167.6629216\n",
            "          ],\n",
            "          [\n",
            "            290.7879242752001,\n",
            "            74.0143215999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"1a\",\n",
            "          \"url\": \"figure.caption.1\",\n",
            "          \"start_index\": 393\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"3c7c5445f2556bdd972aa11024143f8e\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"b7e78c182dbf1ff32cc960ed1022019c\",\n",
            "    \"text\": \"2.2 Model Training\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            178.24758339999994\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            188.2101833999999\n",
            "          ],\n",
            "          [\n",
            "            159.80213020000002,\n",
            "            188.2101833999999\n",
            "          ],\n",
            "          [\n",
            "            159.80213020000002,\n",
            "            178.24758339999994\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 2,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"1e9fb4a4895681f2277acac805311c72\",\n",
            "    \"text\": \"The original GPT4All model was a fine tuned variant of LLaMA 7B. In order to train it more efficiently, we froze the base weights of LLaMA, and only trained a small set of LoRA (Hu et al., 2021) weights during the fine tuning process. Detailed model hyper-parameters and training code can be found in our associated code repository1.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.557,\n",
            "            194.20532159999993\n",
            "          ],\n",
            "          [\n",
            "            70.557,\n",
            "            275.8989216\n",
            "          ],\n",
            "          [\n",
            "            289.13843652000014,\n",
            "            275.8989216\n",
            "          ],\n",
            "          [\n",
            "            289.13843652000014,\n",
            "            194.20532159999993\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Hu et al .,\",\n",
            "          \"url\": \"cite.hu2021lora\",\n",
            "          \"start_index\": 176\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2021\",\n",
            "          \"url\": \"cite.hu2021lora\",\n",
            "          \"start_index\": 187\n",
            "        },\n",
            "        {\n",
            "          \"text\": \".\",\n",
            "          \"url\": \"Hfootnote.2\",\n",
            "          \"start_index\": 329\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"b7e78c182dbf1ff32cc960ed1022019c\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"c998616eb5519870f1b5eb7207749e66\",\n",
            "    \"text\": \"2.3 Model Access\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.86600000000001,\n",
            "            286.48358339999993\n",
            "          ],\n",
            "          [\n",
            "            70.86600000000001,\n",
            "            296.4461833999999\n",
            "          ],\n",
            "          [\n",
            "            151.10478040000004,\n",
            "            296.4461833999999\n",
            "          ],\n",
            "          [\n",
            "            151.10478040000004,\n",
            "            286.48358339999993\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 2,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"2fd8d8cedd78e9080e5e641d58d85f58\",\n",
            "    \"text\": \"We publicly released all data, training code, and model weights for the community to build upon. Further, we provided a 4-bit quantized version of the model, which enabled users to run it on their own commodity hard- ware without transferring data to a 3rd party service.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.398,\n",
            "            302.4413215999999\n",
            "          ],\n",
            "          [\n",
            "            70.398,\n",
            "            360.2239216\n",
            "          ],\n",
            "          [\n",
            "            290.7888009840001,\n",
            "            360.2239216\n",
            "          ],\n",
            "          [\n",
            "            290.7888009840001,\n",
            "            302.4413215999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"c998616eb5519870f1b5eb7207749e66\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"8dfde8cadfe9b32242bf92a46677da95\",\n",
            "    \"text\": \"Our research and development costs were dominated by \\u223c$800 in GPU spend (rented from Lambda Labs and Paperspace) and \\u223c$500 in OpenAI API spend. Our final GPT4All model could be trained in about eight hours on a Lambda Labs DGX A100 8x 80GB for a total cost of \\u223c$100.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            362.3993216\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            432.1369216\n",
            "          ],\n",
            "          [\n",
            "            289.1357349720001,\n",
            "            432.1369216\n",
            "          ],\n",
            "          [\n",
            "            289.1357349720001,\n",
            "            362.3993216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"c998616eb5519870f1b5eb7207749e66\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"d6d4ad115eb010fa18f8db60b6e16130\",\n",
            "    \"text\": \"2.4 Model Evaluation\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.86600000000001,\n",
            "            442.72158340000004\n",
            "          ],\n",
            "          [\n",
            "            70.86600000000001,\n",
            "            452.68418340000005\n",
            "          ],\n",
            "          [\n",
            "            169.29648800000004,\n",
            "            452.68418340000005\n",
            "          ],\n",
            "          [\n",
            "            169.29648800000004,\n",
            "            442.72158340000004\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 2,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"f62efce43d06b955f6a5dcddf65af02c\",\n",
            "    \"text\": \"We performed a preliminary evaluation of our model using the human evaluation data from the Self Instruct paper (Wang et al., 2023). We reported the ground truth perplexity of our model against what was, to our knowl- edge, the best openly available alpaca-lora model at the time, provided by user chainyo on HuggingFace. Both models had very large perplexities on a small number of tasks, so we reported perplexities clipped to a maximum of 100. We found that GPT4All produces stochastically lower ground truth perplexities than alpaca-lora (Anand et al., 2023).\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.398,\n",
            "            458.6793216\n",
            "          ],\n",
            "          [\n",
            "            70.398,\n",
            "            588.1939216\n",
            "          ],\n",
            "          [\n",
            "            290.78419826280003,\n",
            "            588.1939216\n",
            "          ],\n",
            "          [\n",
            "            290.78419826280003,\n",
            "            458.6793216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Wang et al .,\",\n",
            "          \"url\": \"cite.wang2023selfinstruct\",\n",
            "          \"start_index\": 113\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.wang2023selfinstruct\",\n",
            "          \"start_index\": 126\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Anand\",\n",
            "          \"url\": \"cite.gpt4all\",\n",
            "          \"start_index\": 543\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"et al .,\",\n",
            "          \"url\": \"cite.gpt4all\",\n",
            "          \"start_index\": 549\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.gpt4all\",\n",
            "          \"start_index\": 557\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"d6d4ad115eb010fa18f8db60b6e16130\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"12c1dd0555bedb5ccc2a4d6366af96c7\",\n",
            "    \"text\": \"3 From a Model to an Ecosystem\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            600.3705159\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            612.3256159\n",
            "          ],\n",
            "          [\n",
            "            246.96462300000002,\n",
            "            612.3256159\n",
            "          ],\n",
            "          [\n",
            "            246.96462300000002,\n",
            "            600.3705159\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 2,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"0dffdafdd5dd329002b2c54c4cb1110b\",\n",
            "    \"text\": \"3.1 GPT4All-J: Repository Growth and the implications of the LLaMA License\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            621.0545834\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            642.9721834\n",
            "          ],\n",
            "          [\n",
            "            261.8091916,\n",
            "            642.9721834\n",
            "          ],\n",
            "          [\n",
            "            261.8091916,\n",
            "            621.0545834\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 2,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"eefe269a0febf2b64874bf58517dfd42\",\n",
            "    \"text\": \"The GPT4All repository grew rapidly after its release, gaining over 20000 GitHub stars in just one week, as shown in Figure 2. This growth was supported by an in-person hackathon hosted in New York City three days after the model release, which attracted several hundred participants. As the Nomic discord, the home of online discussion about GPT4All, ballooned to over 10000 people, one thing became very clear - there was massive demand for a model that could be used commercially.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.557,\n",
            "            648.9673216\n",
            "          ],\n",
            "          [\n",
            "            70.557,\n",
            "            754.5709216\n",
            "          ],\n",
            "          [\n",
            "            290.3781824640001,\n",
            "            754.5709216\n",
            "          ],\n",
            "          [\n",
            "            290.3781824640001,\n",
            "            648.9673216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"2\",\n",
            "          \"url\": \"figure.caption.3\",\n",
            "          \"start_index\": 124\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"0dffdafdd5dd329002b2c54c4cb1110b\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"6169a14e40fbcf8d4916ff79139c9731\",\n",
            "    \"text\": \"1https://github.com/nomic-ai/gpt4all\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            82.406,\n",
            "            763.6547055999999\n",
            "          ],\n",
            "          [\n",
            "            82.406,\n",
            "            772.8172968\n",
            "          ],\n",
            "          [\n",
            "            203.33735880000003,\n",
            "            772.8172968\n",
            "          ],\n",
            "          [\n",
            "            203.33735880000003,\n",
            "            763.6547055999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 2,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"0d8886d9a22209bc8437feee3638a5ca\",\n",
            "    \"text\": \"The LLaMA model that GPT4All was based on was licensed for research only, which severely limited the set of domains that GPT4All could be applied in. As a response to this, the Nomic team repeated the model training procedure of the original GPT4All model, but based on the already open source and commercially li- censed GPT-J model (Wang and Komatsuzaki, 2021). GPT4All-J also had an augmented training set, which contained multi-turn QA examples and creative writing such as poetry, rap, and short stories. The creative writ- ing prompts were generated by filling in schemas such as \\\"Write a [CREATIVE STORY TYPE] about [NOUN] in the style of [PERSON].\\\" We again employed Atlas to curate the prompt-response pairs in this data set.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            74.0143215999999\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            239.3939216\n",
            "          ],\n",
            "          [\n",
            "            526.1562576520001,\n",
            "            239.3939216\n",
            "          ],\n",
            "          [\n",
            "            526.1562576520001,\n",
            "            74.0143215999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Wang and Komatsuzaki\",\n",
            "          \"url\": \"cite.gpt-j\",\n",
            "          \"start_index\": 335\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2021\",\n",
            "          \"url\": \"cite.gpt-j\",\n",
            "          \"start_index\": 357\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"6169a14e40fbcf8d4916ff79139c9731\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"92e00ff1cb81d6b459be0fe6dc472d52\",\n",
            "    \"text\": \"Our evaluation methodology also evolved as the project grew. In particular, we began evaluating GPT4All models using a suite of seven reasoning tasks that were used for evaluation of the Databricks Dolly (Conover et al., 2023b) model, which was re- leased on April 12, 2023. Unfortunately, GPT4All-J did not outperform other prominent open source models on this evaluation. As a result, we endeavoured to create a model that did.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            242.06532159999995\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            347.6689216\n",
            "          ],\n",
            "          [\n",
            "            526.064800984,\n",
            "            347.6689216\n",
            "          ],\n",
            "          [\n",
            "            526.064800984,\n",
            "            242.06532159999995\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Conover et al .,\",\n",
            "          \"url\": \"cite.DatabricksBlog2023DollyV2\",\n",
            "          \"start_index\": 205\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023b\",\n",
            "          \"url\": \"cite.DatabricksBlog2023DollyV2\",\n",
            "          \"start_index\": 221\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"6169a14e40fbcf8d4916ff79139c9731\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"73c58b69befd3e9f585d675406001042\",\n",
            "    \"text\": \"3.2 GPT4All-Snoozy: the Emergence of the\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            359.8695834\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            369.8321834\n",
            "          ],\n",
            "          [\n",
            "            496.7365006000001,\n",
            "            369.8321834\n",
            "          ],\n",
            "          [\n",
            "            496.7365006000001,\n",
            "            359.8695834\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 2,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"00433feaf46628cec1f38be5bf01656e\",\n",
            "    \"text\": \"GPT4All Ecosystem\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            328.558,\n",
            "            371.8245834\n",
            "          ],\n",
            "          [\n",
            "            328.558,\n",
            "            381.7871834\n",
            "          ],\n",
            "          [\n",
            "            414.0669958,\n",
            "            381.7871834\n",
            "          ],\n",
            "          [\n",
            "            414.0669958,\n",
            "            371.8245834\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 2,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"024462343235bc2daac9cce9bb6c634e\",\n",
            "    \"text\": \"GPT4All-Snoozy was developed using roughly the same procedure as the previous GPT4All models, but with a few key modifications. First, GPT4All-Snoozy used the LLaMA-13B base model due to its superior base metrics when compared to GPT-J. Next, GPT4All-Snoozy incor- porated the Dolly\\u2019s training data into its train mix. After data curation and deduplication with Atlas, this yielded a training set of 739,259 total prompt-response pairs. We dubbed the model that resulted from training on this improved dataset GPT4All-Snoozy. As shown in Figure 1, GPT4All-Snoozy had the best average score on our evaluation benchmark of any model in the ecosystem at the time of its release.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            305.395,\n",
            "            388.7263216\n",
            "          ],\n",
            "          [\n",
            "            305.395,\n",
            "            542.1499216\n",
            "          ],\n",
            "          [\n",
            "            526.1562576520001,\n",
            "            542.1499216\n",
            "          ],\n",
            "          [\n",
            "            526.1562576520001,\n",
            "            388.7263216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"00433feaf46628cec1f38be5bf01656e\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"59eced6045d5b1cdba3ade16138ac760\",\n",
            "    \"text\": \"Concurrently with the development of GPT4All, sev- eral organizations such as LMSys, Stability AI, BAIR, and Databricks built and deployed open source language models. We heard increasingly from the community that they wanted quantized versions of these models for local use. As we realized that organizations with ever more resources were developing source language models, we decided to pivot our effort away from training increas- ingly capable models and towards providing easy access to the plethora of models being produced by the open source community. Practically, this meant spending our time compressing open source models for use on com- modity hardware, providing stable and simple high level model APIs, and supporting a GUI for no code model experimentation.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            544.8223216\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            722.1569216\n",
            "          ],\n",
            "          [\n",
            "            526.0674912600001,\n",
            "            722.1569216\n",
            "          ],\n",
            "          [\n",
            "            526.0674912600001,\n",
            "            544.8223216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"00433feaf46628cec1f38be5bf01656e\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
            "    \"text\": \"3.3 The Current State of GPT4All\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            734.3565834\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            744.3191833999999\n",
            "          ],\n",
            "          [\n",
            "            457.8823606,\n",
            "            744.3191833999999\n",
            "          ],\n",
            "          [\n",
            "            457.8823606,\n",
            "            734.3565834\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 2,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"cb61f57fcce8e8a2646dc76a8c093748\",\n",
            "    \"text\": \"Today, GPT4All is focused on improving the accessi- bility of open source language models. The repository\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            305.833,\n",
            "            751.2583216\n",
            "          ],\n",
            "          [\n",
            "            305.833,\n",
            "            773.1759216\n",
            "          ],\n",
            "          [\n",
            "            526.0606565440002,\n",
            "            773.1759216\n",
            "          ],\n",
            "          [\n",
            "            526.0606565440002,\n",
            "            751.2583216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"41e0446a073aef5a69d9255c3c4e97d3\",\n",
            "    \"text\": \"(a)\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            120.238,\n",
            "            182.17665599999998\n",
            "          ],\n",
            "          [\n",
            "            120.238,\n",
            "            191.267656\n",
            "          ],\n",
            "          [\n",
            "            130.32900999999998,\n",
            "            191.267656\n",
            "          ],\n",
            "          [\n",
            "            130.32900999999998,\n",
            "            182.17665599999998\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"58733fcd98d72185ade05bca0dfb629e\",\n",
            "    \"text\": \"(b)\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            226.15,\n",
            "            182.17665599999998\n",
            "          ],\n",
            "          [\n",
            "            226.15,\n",
            "            191.267656\n",
            "          ],\n",
            "          [\n",
            "            236.750106,\n",
            "            191.267656\n",
            "          ],\n",
            "          [\n",
            "            236.750106,\n",
            "            182.17665599999998\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"c46d4a1f11826347b7e9e26d86ba9cf0\",\n",
            "    \"text\": \"(c)\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            338.03,\n",
            "            182.17665599999998\n",
            "          ],\n",
            "          [\n",
            "            338.03,\n",
            "            191.267656\n",
            "          ],\n",
            "          [\n",
            "            348.12101,\n",
            "            191.267656\n",
            "          ],\n",
            "          [\n",
            "            348.12101,\n",
            "            182.17665599999998\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"9698a5149dc8973c56d946c401011e29\",\n",
            "    \"text\": \"(d)\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            454.856,\n",
            "            182.17665599999998\n",
            "          ],\n",
            "          [\n",
            "            454.856,\n",
            "            191.267656\n",
            "          ],\n",
            "          [\n",
            "            465.45610600000003,\n",
            "            191.267656\n",
            "          ],\n",
            "          [\n",
            "            465.45610600000003,\n",
            "            182.17665599999998\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"2e03616f70996bcde479197f45b4857c\",\n",
            "    \"text\": \"Figure 1: TSNE visualizations showing the progression of the GPT4All train set. Panel (a) shows the original uncurated data. The red arrow denotes a region of highly homogeneous prompt-response pairs. The coloring denotes which open dataset contributed the prompt. Panel (b) shows the original GPT4All data after curation. This panel, as well as panels (c) and (d) are 10 colored by topic, which Atlas automatically extracts. Notice that the large homogeneous prompt-response blobs no longer appearl. Panel (c) shows the GPT4All-J dataset. The \\\"starburst\\\" clusters introduced on the right side of the panel correspond to the newly added creative data. Panel (d) shows the final GPT4All-snoozy dataset. All datasets have been released to the public, and can be interactively explored online. In the web version of this article, you can click on a panel to be taken to its interactive visualization.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.507,\n",
            "            203.06932159999997\n",
            "          ],\n",
            "          [\n",
            "            70.507,\n",
            "            296.71892160000004\n",
            "          ],\n",
            "          [\n",
            "            525.6591306453995,\n",
            "            296.71892160000004\n",
            "          ],\n",
            "          [\n",
            "            525.6591306453995,\n",
            "            203.06932159999997\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"fac17d1d0abdbbacf59720b80b638801\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
            "    \"text\": \"Model\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            76.844,\n",
            "            313.32293119999997\n",
            "          ],\n",
            "          [\n",
            "            76.844,\n",
            "            321.7911312\n",
            "          ],\n",
            "          [\n",
            "            98.9544702,\n",
            "            321.7911312\n",
            "          ],\n",
            "          [\n",
            "            98.9544702,\n",
            "            313.32293119999997\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"887a46a4686a15ffec4a85995e852a77\",\n",
            "    \"text\": \"BoolQ PIQA HellaSwag WinoG. ARC-e ARC-c OBQA Avg.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            245.318839,\n",
            "            313.32293119999997\n",
            "          ],\n",
            "          [\n",
            "            245.318839,\n",
            "            321.7911312\n",
            "          ],\n",
            "          [\n",
            "            523.1689492000004,\n",
            "            321.7911312\n",
            "          ],\n",
            "          [\n",
            "            523.1689492000004,\n",
            "            313.32293119999997\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"52cfb840240d199decfe24db5e27ce5d\",\n",
            "    \"text\": \"GPT4All-J 6B v1.0* GPT4All-J v1.1-breezy* GPT4All-J v1.2-jazzy* GPT4All-J v1.3-groovy* GPT4All-J Lora 6B* GPT4All LLaMa Lora 7B* GPT4All 13B snoozy* GPT4All Falcon Nous-Hermes (Nous-Research, 2023b) Nous-Hermes2 (Nous-Research, 2023c) Nous-Puffin (Nous-Research, 2023d) Dolly 6B* (Conover et al., 2023a) Dolly 12B* (Conover et al., 2023b) Alpaca 7B* (Taori et al., 2023) Alpaca Lora 7B* (Wang, 2023) GPT-J* 6.7B (Wang and Komatsuzaki, 2021) LLama 7B* (Touvron et al., 2023) LLama 13B* (Touvron et al., 2023) Pythia 6.7B* (Biderman et al., 2023) Pythia 12B* (Biderman et al., 2023) Fastchat T5* (Zheng et al., 2023) Fastchat Vicu\\u00f1a* 7B (Zheng et al., 2023) Fastchat Vicu\\u00f1a 13B* (Zheng et al., 2023) StableVicu\\u00f1a RLHF* (Stability-AI, 2023) StableLM Tuned* (Stability-AI, 2023) StableLM Base* (Stability-AI, 2023) Koala 13B* (Geng et al., 2023) Open Assistant Pythia 12B* Mosaic MPT7B (MosaicML-Team, 2023) Mosaic mpt-instruct (MosaicML-Team, 2023) Mosaic mpt-chat (MosaicML-Team, 2023) Wizard 7B (Xu et al., 2023) Wizard 7B Uncensored (Xu et al., 2023) Wizard 13B Uncensored (Xu et al., 2023) GPT4-x-Vicuna-13b (Nous-Research, 2023a) Falcon 7b (Almazrouei et al., 2023) Falcon 7b instruct (Almazrouei et al., 2023)\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            76.84399999999994,\n",
            "            327.2679312\n",
            "          ],\n",
            "          [\n",
            "            76.84399999999994,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            233.36174060000002,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            233.36174060000002,\n",
            "            327.2679312\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Nous - Research\",\n",
            "          \"url\": \"cite.nousresearch2023noushermes\",\n",
            "          \"start_index\": 177\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023b\",\n",
            "          \"url\": \"cite.nousresearch2023noushermes\",\n",
            "          \"start_index\": 192\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Nous - Research\",\n",
            "          \"url\": \"cite.nousresearch2023noushermesllama\",\n",
            "          \"start_index\": 213\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023c\",\n",
            "          \"url\": \"cite.nousresearch2023noushermesllama\",\n",
            "          \"start_index\": 228\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Nous - Research\",\n",
            "          \"url\": \"cite.nousresearch2023redmondpuffin\",\n",
            "          \"start_index\": 247\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023d\",\n",
            "          \"url\": \"cite.nousresearch2023redmondpuffin\",\n",
            "          \"start_index\": 262\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Conover et al .,\",\n",
            "          \"url\": \"cite.DatabricksBlog2023DollyV1\",\n",
            "          \"start_index\": 280\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023a\",\n",
            "          \"url\": \"cite.DatabricksBlog2023DollyV1\",\n",
            "          \"start_index\": 296\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Conover et al .,\",\n",
            "          \"url\": \"cite.DatabricksBlog2023DollyV2\",\n",
            "          \"start_index\": 315\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023b\",\n",
            "          \"url\": \"cite.DatabricksBlog2023DollyV2\",\n",
            "          \"start_index\": 331\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Taori et al .,\",\n",
            "          \"url\": \"cite.alpaca\",\n",
            "          \"start_index\": 350\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.alpaca\",\n",
            "          \"start_index\": 364\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Wang\",\n",
            "          \"url\": \"cite.alpaca-lora\",\n",
            "          \"start_index\": 387\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.alpaca-lora\",\n",
            "          \"start_index\": 393\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Wang and Komatsuzaki\",\n",
            "          \"url\": \"cite.gpt-j\",\n",
            "          \"start_index\": 412\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2021\",\n",
            "          \"url\": \"cite.gpt-j\",\n",
            "          \"start_index\": 434\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Touvron et al .,\",\n",
            "          \"url\": \"cite.touvron2023llama\",\n",
            "          \"start_index\": 451\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.touvron2023llama\",\n",
            "          \"start_index\": 467\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Touvron et al .,\",\n",
            "          \"url\": \"cite.touvron2023llama\",\n",
            "          \"start_index\": 485\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.touvron2023llama\",\n",
            "          \"start_index\": 501\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Biderman et al .,\",\n",
            "          \"url\": \"cite.biderman2023pythia\",\n",
            "          \"start_index\": 521\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.biderman2023pythia\",\n",
            "          \"start_index\": 538\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Biderman et al .,\",\n",
            "          \"url\": \"cite.biderman2023pythia\",\n",
            "          \"start_index\": 557\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.biderman2023pythia\",\n",
            "          \"start_index\": 574\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Zheng et al .,\",\n",
            "          \"url\": \"cite.zheng2023judging\",\n",
            "          \"start_index\": 594\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.zheng2023judging\",\n",
            "          \"start_index\": 608\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Zheng et al .,\",\n",
            "          \"url\": \"cite.zheng2023judging\",\n",
            "          \"start_index\": 635\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.zheng2023judging\",\n",
            "          \"start_index\": 649\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Zheng et al .,\",\n",
            "          \"url\": \"cite.zheng2023judging\",\n",
            "          \"start_index\": 677\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.zheng2023judging\",\n",
            "          \"start_index\": 691\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Stability - AI\",\n",
            "          \"url\": \"cite.stabilityai2023stablelm\",\n",
            "          \"start_index\": 717\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.stabilityai2023stablelm\",\n",
            "          \"start_index\": 731\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Stability - AI\",\n",
            "          \"url\": \"cite.stabilityai2023stablelm\",\n",
            "          \"start_index\": 754\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.stabilityai2023stablelm\",\n",
            "          \"start_index\": 768\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Stability - AI\",\n",
            "          \"url\": \"cite.stabilityai2023stablelm\",\n",
            "          \"start_index\": 790\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.stabilityai2023stablelm\",\n",
            "          \"start_index\": 804\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Geng et al .,\",\n",
            "          \"url\": \"cite.koala_blogpost_2023\",\n",
            "          \"start_index\": 822\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.koala_blogpost_2023\",\n",
            "          \"start_index\": 835\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"MosaicML - Team\",\n",
            "          \"url\": \"cite.MosaicML2023Introducing\",\n",
            "          \"start_index\": 882\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.MosaicML2023Introducing\",\n",
            "          \"start_index\": 897\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"MosaicML - Team\",\n",
            "          \"url\": \"cite.MosaicML2023Introducing\",\n",
            "          \"start_index\": 924\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.MosaicML2023Introducing\",\n",
            "          \"start_index\": 939\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"MosaicML - Team\",\n",
            "          \"url\": \"cite.MosaicML2023Introducing\",\n",
            "          \"start_index\": 962\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.MosaicML2023Introducing\",\n",
            "          \"start_index\": 977\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Xu et al .,\",\n",
            "          \"url\": \"cite.xu2023wizardlm\",\n",
            "          \"start_index\": 994\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.xu2023wizardlm\",\n",
            "          \"start_index\": 1005\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Xu et al .,\",\n",
            "          \"url\": \"cite.xu2023wizardlm\",\n",
            "          \"start_index\": 1033\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.xu2023wizardlm\",\n",
            "          \"start_index\": 1044\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Xu et al .,\",\n",
            "          \"url\": \"cite.xu2023wizardlm\",\n",
            "          \"start_index\": 1073\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.xu2023wizardlm\",\n",
            "          \"start_index\": 1084\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Nous - Research\",\n",
            "          \"url\": \"cite.nousresearch2023gpt4xvicuna\",\n",
            "          \"start_index\": 1109\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023a\",\n",
            "          \"url\": \"cite.nousresearch2023gpt4xvicuna\",\n",
            "          \"start_index\": 1124\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Almazrouei et al .,\",\n",
            "          \"url\": \"cite.falcon40b\",\n",
            "          \"start_index\": 1142\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.falcon40b\",\n",
            "          \"start_index\": 1161\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"863cef5b45ff3c135f3d6ac488541345\",\n",
            "    \"text\": \"73.4 74 74.8 73.6 68.6 73.1 83.3 77.6 79.5 83.9 81.5 68.8 56.7 73.9 74.3 65.4 73.1 68.5 63.5 67.7 81.5 76.6 81.5 82.3 62.5 60.1 76.5 67.9 74.8 74.3 77.1 78.4 77.7 78.4 81.3 73.6 70.9\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            249.19727459999996,\n",
            "            327.2679312\n",
            "          ],\n",
            "          [\n",
            "            249.19727459999996,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            264.01735,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            264.01735,\n",
            "            327.2679312\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"9292384de68d6f41f3b383a7321eceeb\",\n",
            "    \"text\": \"74.8 75.1 74.9 74.3 75.8 77.6 79.2 79.8 78.9 80.7 80.7 77.3 75.4 77.2 79.3 76.2 77.4 79.1 76.3 76.6 64.6 77.2 76.8 78.6 71.2 67.4 77.9 78 79.3 80.4 78.2 77.2 74.2 75.5 75 80.7 78.6\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            282.32399999999996,\n",
            "            327.2679312\n",
            "          ],\n",
            "          [\n",
            "            282.32399999999996,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            297.14494840000003,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            297.14494840000003,\n",
            "            327.2679312\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"2e76b593bee43831923f1d8063243e50\",\n",
            "    \"text\": \"63.4 63.2 63.6 63.8 66.2 72.1 75 74.9 80 80.1 80.4 67.6 71 73.9 74 66.2 73 76.2 64 67.3 46.3 70.7 73.3 74.1 53.6 41.2 72.6 68.1 76.3 77.2 74.5 69.9 68 72.1 75.2 76.3 69.8\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            322.6919094,\n",
            "            327.2679312\n",
            "          ],\n",
            "          [\n",
            "            322.6919094,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            337.51335,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            337.51335,\n",
            "            327.2679312\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"e4cc6d4975ff77e2c54a0df8341aff4c\",\n",
            "    \"text\": \"64.7 63.6 63.8 63.5 63.5 67.8 71.3 70.1 71.9 71.3 72.5 63.9 62.2 66.1 68.8 64.1 66.9 70.1 61.1 63.8 61.8 67.3 66.7 70.9 54.8 50.1 68.8 65 68.6 67.8 67.5 66.5 65.2 69.5 65 67.3 66.7\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            366.54024899999996,\n",
            "            327.2679312\n",
            "          ],\n",
            "          [\n",
            "            366.54024899999996,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            381.36168960000003,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            381.36168960000003,\n",
            "            327.2679312\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"61bf0aa152722b826ff22a41233dc20c\",\n",
            "    \"text\": \"54.9 55.4 56.6 57.7 56.4 51.1 60.9 67.9 74.2 75.7 77.6 62.9 64.6 59.8 56.6 62.2 52.5 60 61.3 63.9 49.3 53.5 57.4 61 52.4 44.9 54.3 64.2 70 72.2 69.4 56.8 53.5 57.5 58.7 71 67.9\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            403.84267,\n",
            "            327.2679312\n",
            "          ],\n",
            "          [\n",
            "            403.84267,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            418.6641106,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            418.6641106,\n",
            "            327.2679312\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"3ba922161513605086db41d4457e0843\",\n",
            "    \"text\": \"36 34.9 35.3 35 35.7 40.4 44.2 43.4 50.9 52.1 50.7 38.7 38.5 43.3 43.9 36.6 41.4 44.6 35.2 34.8 33.3 41.2 42.7 43.5 31.1 27 41 40.4 42.2 44.6 43.3 40.5 38.7 40.4 43.9 43.3 42.7\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            439.78999999999996,\n",
            "            327.2679312\n",
            "          ],\n",
            "          [\n",
            "            439.78999999999996,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            454.6116196,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            454.6116196,\n",
            "            327.2679312\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"06b88051ebb9bf06a22ceb08cda91320\",\n",
            "    \"text\": \"40.2 38.4 41 38.8 40.2 40.2 43.4 42.6 46.4 46.2 45.6 41.2 40.4 43.4 42.6 38.2 42.4 42.2 37.2 38 39.4 40.8 43.6 44.4 33.4 32 42.8 43.2 42.6 43 44.2 42.6 41.6 44 43.6 44.4 41.2\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            475.736,\n",
            "            327.2679312\n",
            "          ],\n",
            "          [\n",
            "            475.736,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            490.5591286,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            490.5591286,\n",
            "            327.2679312\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"ec630706f6d41c1e8bafe6c8475983ed\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
            "    \"text\": \"text-davinci-003\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            76.844,\n",
            "            646.0699311999999\n",
            "          ],\n",
            "          [\n",
            "            76.844,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            132.522415,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            132.522415,\n",
            "            646.0699311999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"f205dfd163738d0912bd2e3793e41a8e\",\n",
            "    \"text\": \"88.1\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            249.1972746,\n",
            "            646.0699311999999\n",
            "          ],\n",
            "          [\n",
            "            249.1972746,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            264.0166246,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            264.0166246,\n",
            "            646.0699311999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"9f70060bfc2e03397be9c3ca01669dbb\",\n",
            "    \"text\": \"83.8\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            282.324873,\n",
            "            646.0699311999999\n",
            "          ],\n",
            "          [\n",
            "            282.324873,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            297.14422300000007,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            297.14422300000007,\n",
            "            646.0699311999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"efa84942a23a7f4f32030613b47e5d14\",\n",
            "    \"text\": \"83.4\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            322.69278240000006,\n",
            "            646.0699311999999\n",
            "          ],\n",
            "          [\n",
            "            322.69278240000006,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            337.5121324000001,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            337.5121324000001,\n",
            "            646.0699311999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"3e22defdcd8953213ed2b41bc15e9400\",\n",
            "    \"text\": \"75.8\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            366.5411220000001,\n",
            "            646.0699311999999\n",
            "          ],\n",
            "          [\n",
            "            366.5411220000001,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            381.36047200000013,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            381.36047200000013,\n",
            "            646.0699311999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"dd3373b1f28a16333af2e3b8484ac102\",\n",
            "    \"text\": \"83.9\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            403.8435430000001,\n",
            "            646.0699311999999\n",
            "          ],\n",
            "          [\n",
            "            403.8435430000001,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            418.66289300000017,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            418.66289300000017,\n",
            "            646.0699311999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"c73cb5d9dc355215c7df2c742d6c06c0\",\n",
            "    \"text\": \"63.9\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            439.79105200000015,\n",
            "            646.0699311999999\n",
            "          ],\n",
            "          [\n",
            "            439.79105200000015,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            454.6104020000002,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            454.6104020000002,\n",
            "            646.0699311999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"349d5830083c52f2e022ef9572f77a8c\",\n",
            "    \"text\": \"51.0\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            475.7385610000002,\n",
            "            646.0699311999999\n",
            "          ],\n",
            "          [\n",
            "            475.7385610000002,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            490.5579110000002,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            490.5579110000002,\n",
            "            646.0699311999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"e4cfa78e74e08ab87de711c67c176fb4\",\n",
            "    \"text\": \"Table 1: Evaluations of all language models in the GPT4All ecosystem as of August 1, 2023. Code models are not included. OpenAI\\u2019s text-davinci-003 is included as a point of comparison. The best overall performing model in the GPT4All ecosystem, Nous-Hermes2, achieves over 92% of the average performance of text-davinci-003. Models marked with an asterisk were available in the ecosystem as of the release of GPT4All-Snoozy. Note that at release, GPT4All-Snoozy had the best average performance of any model in the ecosystem. Bolded numbers indicate the best performing model as of August 1, 2023.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.557,\n",
            "            668.5213216\n",
            "          ],\n",
            "          [\n",
            "            70.557,\n",
            "            738.2599216\n",
            "          ],\n",
            "          [\n",
            "            525.6547547729999,\n",
            "            738.2599216\n",
            "          ],\n",
            "          [\n",
            "            525.6547547729999,\n",
            "            668.5213216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"c0c82e3e53fb3495e4493442d86113aa\",\n",
            "    \"text\": \"58.2 57.8 58.6 58.1 58.1 60.3 65.3 65.2 68.8 70.0 69.9 60.1 58.4 62.5 62.8 58.4 61.0 63.0 56.9 58.9 53.7 61.0 63.1 65.0 51.3 46.1 62.0 61.0 64.8 65.6 64.9 61.7 59.8 62.5 63.2 65.2 62.5\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            507.7219004,\n",
            "            327.2679312\n",
            "          ],\n",
            "          [\n",
            "            507.7219004,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            522.5435200000001,\n",
            "            640.5931312000002\n",
            "          ],\n",
            "          [\n",
            "            522.5435200000001,\n",
            "            327.2679312\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"0955591427ee44e2be8e6cd3b9d8d95b\",\n",
            "    \"text\": \"75.7\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            507.7229524000002,\n",
            "            646.0699311999999\n",
            "          ],\n",
            "          [\n",
            "            507.7229524000002,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            522.5423024000003,\n",
            "            654.5381312\n",
            "          ],\n",
            "          [\n",
            "            522.5423024000003,\n",
            "            646.0699311999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"5b851cfc3a92040f34538dabb304f77b\",\n",
            "    \"text\": \"Figure 2: Comparison of the github start growth of GPT4All, Meta\\u2019s LLaMA, and Stanford\\u2019s Alpaca. We conjecture that GPT4All achieved and maintains faster ecosystem growth due to the focus on access, which allows more users to meaningfully participate.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            285.4943215999999\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            319.36792160000005\n",
            "          ],\n",
            "          [\n",
            "            524.4125679919997,\n",
            "            319.36792160000005\n",
            "          ],\n",
            "          [\n",
            "            524.4125679919997,\n",
            "            285.4943215999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"d19fcb87b6dfe6f1efe8ff69aedf0a8a\",\n",
            "    \"text\": \"provides compressed versions of open source models for use on commodity hardware, stable and simple high level model APIs, and a GUI for no code model ex- perimentation. The project continues to increase in popularity, and as of August 1 2023, has garnered over 50000 GitHub stars and over 5000 forks.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            343.8763216\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            413.61492159999995\n",
            "          ],\n",
            "          [\n",
            "            290.7888009840001,\n",
            "            413.61492159999995\n",
            "          ],\n",
            "          [\n",
            "            290.7888009840001,\n",
            "            343.8763216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"6fdeb55e51d9b4b32895af473bd3970f\",\n",
            "    \"text\": \"\\u201cjust work\\\" on any machine, whether it comes equipped with Apple Metal silicon, NVIDIA, AMD, or other edge- accelerated hardware. Overall, we envision a world where anyone, anywhere, with any machine, can access and contribute to the cutting edge of AI.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            304.817,\n",
            "            343.8763216\n",
            "          ],\n",
            "          [\n",
            "            304.817,\n",
            "            401.65992159999996\n",
            "          ],\n",
            "          [\n",
            "            526.0636575760001,\n",
            "            401.65992159999996\n",
            "          ],\n",
            "          [\n",
            "            526.0636575760001,\n",
            "            343.8763216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"b19cd88bad15dbd896f39128b97e30bc\",\n",
            "    \"text\": \"GPT4All currently provides native support and benchmark data for over 35 models (see Figure 1), and includes several models co-developed with industry part- ners such as Replit and Hugging Face. GPT4All also provides high level model APIs in languages includ- ing Python, Typescript, Go, C#, and Java, among oth- ers. Furthermore, the GPT4All no code GUI currently supports the workflows of over 50000 monthly active users, with over 25% of users coming back to the tool every day of the week. (Note that all GPT4All user data is collected on an opt in basis.) GPT4All has be- come the top language model integration in the popular open source AI orchestration library LangChain (Chase, 2022), and powers many popular open source projects such as PrivateGPT (imartinez, 2023), Quiver (StanGi- rard, 2023), and MindsDB (MindsDB, 2023), among others. GPT4All is the 3rd fastest growing GitHub repository of all time (Leo, 2023), and is the 185th most popular repository on the platform, by star count.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            416.6453216\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            641.8009216\n",
            "          ],\n",
            "          [\n",
            "            290.78880098400003,\n",
            "            641.8009216\n",
            "          ],\n",
            "          [\n",
            "            290.78880098400003,\n",
            "            416.6453216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"1\",\n",
            "          \"url\": \"table.caption.2\",\n",
            "          \"start_index\": 92\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Chase\",\n",
            "          \"url\": \"cite.langchain\",\n",
            "          \"start_index\": 679\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2022\",\n",
            "          \"url\": \"cite.langchain\",\n",
            "          \"start_index\": 686\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"imartinez\",\n",
            "          \"url\": \"cite.privategpt\",\n",
            "          \"start_index\": 758\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.privategpt\",\n",
            "          \"start_index\": 769\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"StanGi -\",\n",
            "          \"url\": \"cite.stangirard2023quivr\",\n",
            "          \"start_index\": 784\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"rard\",\n",
            "          \"url\": \"cite.stangirard2023quivr\",\n",
            "          \"start_index\": 792\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.stangirard2023quivr\",\n",
            "          \"start_index\": 798\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"MindsDB\",\n",
            "          \"url\": \"cite.mindsdb\",\n",
            "          \"start_index\": 818\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.mindsdb\",\n",
            "          \"start_index\": 827\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Leo\",\n",
            "          \"url\": \"cite.leo_github_fastest\",\n",
            "          \"start_index\": 914\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2023\",\n",
            "          \"url\": \"cite.leo_github_fastest\",\n",
            "          \"start_index\": 919\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"3f00aa2abb4dd52de08c458e081837e2\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"5dc00f8cd1386b82aa9564922875f55b\",\n",
            "    \"text\": \"4 The Future of GPT4All\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            656.7605159\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            668.7156159\n",
            "          ],\n",
            "          [\n",
            "            208.469201,\n",
            "            668.7156159\n",
            "          ],\n",
            "          [\n",
            "            208.469201,\n",
            "            656.7605159\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 4,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"8715e02bb2e5b4d7758a80a9775e8168\",\n",
            "    \"text\": \"In the future, we will continue to grow GPT4All, sup- porting it as the de facto solution for LLM accessibil- ity. Concretely, this means continuing to compress and distribute important open-source language models de- veloped by the community, as well as compressing and distributing increasingly multimodal AI models. Fur- thermore, we will expand the set of hardware devices that GPT4All models run on, so that GPT4All models\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.617,\n",
            "            679.5273216\n",
            "          ],\n",
            "          [\n",
            "            70.617,\n",
            "            773.1759216\n",
            "          ],\n",
            "          [\n",
            "            290.78880098400015,\n",
            "            773.1759216\n",
            "          ],\n",
            "          [\n",
            "            290.78880098400015,\n",
            "            679.5273216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"5dc00f8cd1386b82aa9564922875f55b\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"5836f81609c7a1fa8322f250c3a6cd75\",\n",
            "    \"text\": \"Limitations\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            416.61951589999995\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            428.57461589999997\n",
            "          ],\n",
            "          [\n",
            "            365.2599695,\n",
            "            428.57461589999997\n",
            "          ],\n",
            "          [\n",
            "            365.2599695,\n",
            "            416.61951589999995\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 4,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"f07b7060b90e509a5831047a04041324\",\n",
            "    \"text\": \"By enabling access to large language models, the GPT4All project also inherits many of the ethical con- cerns associated with generative models. Principal among these is the concern that unfiltered language models like GPT4All enable malicious users to generate content that could be harmful and dangerous (e.g., in- structions on building bioweapons). While we recognize this risk, we also acknowledge the risk of concentrating this technology in the hands of a limited number of in- creasingly secretive research groups. We believe that the risk of focusing on the benefits of language model technology significantly outweighs the risk of misuse, and hence we prefer to make the technology as widely available as possible.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            439.3863216\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            604.7649216\n",
            "          ],\n",
            "          [\n",
            "            526.064800984,\n",
            "            604.7649216\n",
            "          ],\n",
            "          [\n",
            "            526.064800984,\n",
            "            439.3863216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"5836f81609c7a1fa8322f250c3a6cd75\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"037ae7c81d992d8bc0727fa73e581faf\",\n",
            "    \"text\": \"Finally, we realize the challenge in assigning credit for large-scale open source initiatives. We make a first attempt at fair credit assignment by explicitly includ- ing the GPT4All open source developers as authors on this work, but recognize that this is insufficient fully characterize everyone involved in the GPT4All effort. Furthermore, we acknowledge the difficulty in citing open source works that do not necessarily have standard- ized citations, and do our best in this paper to provide URLs to projects whenever possible. We encourage further research in the area of open source credit as- signment, and hope to be able to support some of this research ourselves in the future.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            607.7963216\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            761.2209216\n",
            "          ],\n",
            "          [\n",
            "            526.1562576520002,\n",
            "            761.2209216\n",
            "          ],\n",
            "          [\n",
            "            526.1562576520002,\n",
            "            607.7963216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"5836f81609c7a1fa8322f250c3a6cd75\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"d3f115969fa159c8ae83287b2de7a62e\",\n",
            "    \"text\": \"References\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            72.36851589999992\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            84.32361589999994\n",
            "          ],\n",
            "          [\n",
            "            126.4093946,\n",
            "            84.32361589999994\n",
            "          ],\n",
            "          [\n",
            "            126.4093946,\n",
            "            72.36851589999992\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"bcaadbd4f55e020f081dd1ef9a5c2e17\",\n",
            "    \"text\": \"Nomic AI. 2023. Atlas. https://atlas.nomic.ai/.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            92.14289239999994\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            102.5239216\n",
            "          ],\n",
            "          [\n",
            "            286.13765,\n",
            "            102.5239216\n",
            "          ],\n",
            "          [\n",
            "            286.13765,\n",
            "            92.14289239999994\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Atlas\",\n",
            "          \"url\": \"https://atlas.nomic.ai/\",\n",
            "          \"start_index\": 16\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"https :// atlas . nomic . ai /.\",\n",
            "          \"url\": \"https://atlas.nomic.ai/\",\n",
            "          \"start_index\": 23\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"c786e482f15da16d5c8387f40291180e\",\n",
            "    \"text\": \"Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Al- shamsi, Alessandro Cappelli, Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Hes- low, Julien Launay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. 2023. Falcon-40B: an open large language model with state-of-the-art performance.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            112.95932159999995\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            188.67592160000004\n",
            "          ],\n",
            "          [\n",
            "            290.8761733600001,\n",
            "            188.67592160000004\n",
            "          ],\n",
            "          [\n",
            "            290.8761733600001,\n",
            "            112.95932159999995\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"bcaadbd4f55e020f081dd1ef9a5c2e17\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"ff41e3dc2250ba1bdf97a74f6b347927\",\n",
            "    \"text\": \"Yuvanesh Anand, Zach Nussbaum, Brandon Duder- stadt, Benjamin Schmidt, and Andriy Mulyar. 2023. Gpt4all: Training an assistant-style chatbot with large scale data distillation from gpt-3.5-turbo. https://github.com/nomic-ai/gpt4all.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            199.1103215999999\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            252.90892159999999\n",
            "          ],\n",
            "          [\n",
            "            290.88095540800003,\n",
            "            252.90892159999999\n",
            "          ],\n",
            "          [\n",
            "            290.88095540800003,\n",
            "            199.1103215999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"https :// github . com / nomic - ai / gpt4all\",\n",
            "          \"url\": \"https://github.com/nomic-ai/gpt4all\",\n",
            "          \"start_index\": 196\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"bcaadbd4f55e020f081dd1ef9a5c2e17\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"6b1e1363d133a804d6a87d3d9ea1bc5e\",\n",
            "    \"text\": \"BBC News. 2023. Chatgpt banned in italy over privacy\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            263.34432159999994\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            273.3069216\n",
            "          ],\n",
            "          [\n",
            "            289.4846169432001,\n",
            "            273.3069216\n",
            "          ],\n",
            "          [\n",
            "            289.4846169432001,\n",
            "            263.34432159999994\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Chatgpt banned in italy over privacy\",\n",
            "          \"url\": \"https://www.bbc.com/news/technology-65139406\",\n",
            "          \"start_index\": 16\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"bcaadbd4f55e020f081dd1ef9a5c2e17\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"8f4f477e26112f0d2d24d57229527002\",\n",
            "    \"text\": \"concerns. BBC News.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            85.81,\n",
            "            274.0741818\n",
            "          ],\n",
            "          [\n",
            "            85.81,\n",
            "            284.26592160000007\n",
            "          ],\n",
            "          [\n",
            "            172.53465,\n",
            "            284.26592160000007\n",
            "          ],\n",
            "          [\n",
            "            172.53465,\n",
            "            274.0741818\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"concerns\",\n",
            "          \"url\": \"https://www.bbc.com/news/technology-65139406\",\n",
            "          \"start_index\": 0\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"9ecc6cb3f818c8971fbbebf3ada09d7b\",\n",
            "    \"text\": \"Stella Biderman, Hailey Schoelkopf, Quentin An- thony, Herbie Bradley, Kyle O\\u2019Brien, Eric Hal- lahan, Mohammad Aflah Khan, Shivanshu Puro- hit, USVSN Sai Prashanth, Edward Raff, Aviya Skowron, Lintang Sutawika, and Oskar van der Wal. 2023. Pythia: A suite for analyzing large language models across training and scaling.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            294.7013215999999\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            370.41692159999997\n",
            "          ],\n",
            "          [\n",
            "            290.8793613920001,\n",
            "            370.41692159999997\n",
            "          ],\n",
            "          [\n",
            "            290.8793613920001,\n",
            "            294.7013215999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Pythia : A suite for analyzing large language\",\n",
            "          \"url\": \"http://arxiv.org/abs/2304.01373\",\n",
            "          \"start_index\": 239\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"models across training and scaling\",\n",
            "          \"url\": \"http://arxiv.org/abs/2304.01373\",\n",
            "          \"start_index\": 284\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"8f4f477e26112f0d2d24d57229527002\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"16f9306e183f011f9a89e80c8b1d4f1c\",\n",
            "    \"text\": \"Harrison Chase. 2022.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            380.8523216\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            390.8149216\n",
            "          ],\n",
            "          [\n",
            "            163.318529496,\n",
            "            390.8149216\n",
            "          ],\n",
            "          [\n",
            "            163.318529496,\n",
            "            380.8523216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"27d06343168776257e5cdc6d77525580\",\n",
            "    \"text\": \"langchain. https://github.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            169.58839218000003,\n",
            "            380.4338924\n",
            "          ],\n",
            "          [\n",
            "            169.58839218000003,\n",
            "            390.8149216\n",
            "          ],\n",
            "          [\n",
            "            292.6205,\n",
            "            390.8149216\n",
            "          ],\n",
            "          [\n",
            "            292.6205,\n",
            "            380.4338924\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"https :// github .\",\n",
            "          \"url\": \"https://github.com/langchain-ai/langchain\",\n",
            "          \"start_index\": 11\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"bd3395bd02b99d5150d9ae2cd196e9a4\",\n",
            "    \"text\": \"com/langchain-ai/langchain.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            85.81,\n",
            "            391.3928924\n",
            "          ],\n",
            "          [\n",
            "            85.81,\n",
            "            401.7739216\n",
            "          ],\n",
            "          [\n",
            "            218.31365,\n",
            "            401.7739216\n",
            "          ],\n",
            "          [\n",
            "            218.31365,\n",
            "            391.3928924\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"com / langchain - ai / langchain\",\n",
            "          \"url\": \"https://github.com/langchain-ai/langchain\",\n",
            "          \"start_index\": 0\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"3a06407710f1e1db5c1e2561578c6241\",\n",
            "    \"text\": \"Mike Conover, Matt Hayes, Ankit Mathur, Xiangrui Meng, Jianwei Xie, Jun Wan, Ali Ghodsi, Patrick Wendell, and Matei Zaharia. 2023a. Hello dolly: Democratizing the magic of chatgpt with open mod- els.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            412.20932159999995\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            466.00692159999994\n",
            "          ],\n",
            "          [\n",
            "            290.79149126000016,\n",
            "            466.00692159999994\n",
            "          ],\n",
            "          [\n",
            "            290.79149126000016,\n",
            "            412.20932159999995\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Hello dolly :\",\n",
            "          \"url\": \"https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html\",\n",
            "          \"start_index\": 132\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Democratizing the magic of chatgpt with open mod -\",\n",
            "          \"url\": \"https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html\",\n",
            "          \"start_index\": 145\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"els\",\n",
            "          \"url\": \"https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html\",\n",
            "          \"start_index\": 195\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"bd3395bd02b99d5150d9ae2cd196e9a4\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"e4992de073d64de58bd155d44d670bad\",\n",
            "    \"text\": \"Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin. 2023b. Free dolly: Introducing the world\\u2019s first truly open instruction- tuned llm.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            476.4423216\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            530.2409216\n",
            "          ],\n",
            "          [\n",
            "            290.78760584600013,\n",
            "            530.2409216\n",
            "          ],\n",
            "          [\n",
            "            290.78760584600013,\n",
            "            476.4423216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Free dolly :\",\n",
            "          \"url\": \"https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm\",\n",
            "          \"start_index\": 140\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Introducing the world \\u2019 s first truly open instruction -\",\n",
            "          \"url\": \"https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm\",\n",
            "          \"start_index\": 152\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"tuned llm\",\n",
            "          \"url\": \"https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm\",\n",
            "          \"start_index\": 205\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"bd3395bd02b99d5150d9ae2cd196e9a4\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"056cbfffc020bf8a655a5197701034c3\",\n",
            "    \"text\": \"Xinyang Geng, Arnav Gudibande, Hao Liu, Eric Wal- lace, Pieter Abbeel, Sergey Levine, and Dawn Song. 2023. Koala: A dialogue model for academic re- search. Blog post.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            540.6763215999999\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            583.5149216\n",
            "          ],\n",
            "          [\n",
            "            290.8736030092001,\n",
            "            583.5149216\n",
            "          ],\n",
            "          [\n",
            "            290.8736030092001,\n",
            "            540.6763215999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Koala : A dialogue model for academic re -\",\n",
            "          \"url\": \"https://bair.berkeley.edu/blog/2023/04/03/koala/\",\n",
            "          \"start_index\": 107\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"search\",\n",
            "          \"url\": \"https://bair.berkeley.edu/blog/2023/04/03/koala/\",\n",
            "          \"start_index\": 148\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"bd3395bd02b99d5150d9ae2cd196e9a4\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"e21f882269851b2f6a4a5411c7f2e8fc\",\n",
            "    \"text\": \"Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of large language models.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            593.9503216\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            636.7899216\n",
            "          ],\n",
            "          [\n",
            "            289.13354754680006,\n",
            "            636.7899216\n",
            "          ],\n",
            "          [\n",
            "            289.13354754680006,\n",
            "            593.9503216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Lora : Low - rank adaptation of\",\n",
            "          \"url\": \"http://arxiv.org/abs/2106.09685\",\n",
            "          \"start_index\": 117\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"large language models\",\n",
            "          \"url\": \"http://arxiv.org/abs/2106.09685\",\n",
            "          \"start_index\": 146\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"bd3395bd02b99d5150d9ae2cd196e9a4\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"3ea6c2ee4f5b756e77b23cdcbaf6d74c\",\n",
            "    \"text\": \"imartinez. 2023. privategpt. https://github.com/\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            646.8068923999999\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            657.1879216\n",
            "          ],\n",
            "          [\n",
            "            290.1297,\n",
            "            657.1879216\n",
            "          ],\n",
            "          [\n",
            "            290.1297,\n",
            "            646.8068923999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"https :// github . com /\",\n",
            "          \"url\": \"https://github.com/imartinez/privateGPT\",\n",
            "          \"start_index\": 29\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"0d84c182bf003f976d44d475b40751e3\",\n",
            "    \"text\": \"imartinez/privateGPT.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            85.81000000000002,\n",
            "            657.7658924\n",
            "          ],\n",
            "          [\n",
            "            85.81000000000002,\n",
            "            668.1469216\n",
            "          ],\n",
            "          [\n",
            "            187.92665000000002,\n",
            "            668.1469216\n",
            "          ],\n",
            "          [\n",
            "            187.92665000000002,\n",
            "            657.7658924\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"imartinez / privateGPT\",\n",
            "          \"url\": \"https://github.com/imartinez/privateGPT\",\n",
            "          \"start_index\": 0\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"113ed8473136e587a63ff658d9685446\",\n",
            "    \"text\": \"Oscar Leo. 2023. GitHub: The Fastest Growing Repos-\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            678.5823216\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            688.5449216\n",
            "          ],\n",
            "          [\n",
            "            290.7856627650001,\n",
            "            688.5449216\n",
            "          ],\n",
            "          [\n",
            "            290.7856627650001,\n",
            "            678.5823216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"GitHub : The Fastest Growing Repos -\",\n",
            "          \"url\": \"https://levelup.gitconnected.com/github-the-fastest-growing-repositories-of-all-time-f9884eb79e9\",\n",
            "          \"start_index\": 17\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"bfac0e2a1a1b97d79ec43a400d81572e\",\n",
            "    \"text\": \"itories of All Time.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            85.81,\n",
            "            689.5403216\n",
            "          ],\n",
            "          [\n",
            "            85.81,\n",
            "            699.5029216\n",
            "          ],\n",
            "          [\n",
            "            162.39250619999999,\n",
            "            699.5029216\n",
            "          ],\n",
            "          [\n",
            "            162.39250619999999,\n",
            "            689.5403216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"itories of All Time\",\n",
            "          \"url\": \"https://levelup.gitconnected.com/github-the-fastest-growing-repositories-of-all-time-f9884eb79e9\",\n",
            "          \"start_index\": 0\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"23ac2d2fe4e15d8b26e950649c9ae26c\",\n",
            "    \"text\": \"Robert McMillan. 2023. A meta platforms leak put powerful ai in the hands of everyone. The Wall Street Journal.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            709.9383216\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            741.8189216\n",
            "          ],\n",
            "          [\n",
            "            289.138158692,\n",
            "            741.8189216\n",
            "          ],\n",
            "          [\n",
            "            289.138158692,\n",
            "            709.9383216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"A meta platforms leak put\",\n",
            "          \"url\": \"https://www.wsj.com/articles/a-meta-platforms-leak-put-powerful-ai-in-the-hands-of-everyone-8b9f875a\",\n",
            "          \"start_index\": 23\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"powerful ai in the hands of everyone\",\n",
            "          \"url\": \"https://www.wsj.com/articles/a-meta-platforms-leak-put-powerful-ai-in-the-hands-of-everyone-8b9f875a\",\n",
            "          \"start_index\": 49\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"bfac0e2a1a1b97d79ec43a400d81572e\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"afc0a061d59bc2dd31c7c5ce76ee55e4\",\n",
            "    \"text\": \"MindsDB. 2023. Mindsdb. https://github.com/\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            751.8358923999999\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            762.2169216\n",
            "          ],\n",
            "          [\n",
            "            290.1297,\n",
            "            762.2169216\n",
            "          ],\n",
            "          [\n",
            "            290.1297,\n",
            "            751.8358923999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"https :// github . com /\",\n",
            "          \"url\": \"https://github.com/mindsdb/mindsdb\",\n",
            "          \"start_index\": 24\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"eb547b2c0d2a1977932d2e99c28c07ea\",\n",
            "    \"text\": \"mindsdb/mindsdb. GitHub repository.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            85.81000000000002,\n",
            "            762.7948924\n",
            "          ],\n",
            "          [\n",
            "            85.81000000000002,\n",
            "            773.1759216\n",
            "          ],\n",
            "          [\n",
            "            241.22706000000002,\n",
            "            773.1759216\n",
            "          ],\n",
            "          [\n",
            "            241.22706000000002,\n",
            "            762.7948924\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"ec3f3280237ca8fe7a71d94be4c52569\",\n",
            "    \"text\": \"MosaicML-Team. 2023. Introducing mpt-7b: A new standard for open-source, commercially usable llms. Accessed: 2023-08-07.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            74.0143215999999\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            105.89492159999998\n",
            "          ],\n",
            "          [\n",
            "            526.1496030092002,\n",
            "            105.89492159999998\n",
            "          ],\n",
            "          [\n",
            "            526.1496030092002,\n",
            "            74.0143215999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Introducing mpt - 7b : A new\",\n",
            "          \"url\": null,\n",
            "          \"start_index\": 21\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"standard for open - source , commercially usable llms\",\n",
            "          \"url\": null,\n",
            "          \"start_index\": 47\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"eb547b2c0d2a1977932d2e99c28c07ea\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"691d7fdf7080b720f8a8071e195b16ae\",\n",
            "    \"text\": \"Nous-Research.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            116.8363215999999\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            126.79892159999997\n",
            "          ],\n",
            "          [\n",
            "            370.76121686799996,\n",
            "            126.79892159999997\n",
            "          ],\n",
            "          [\n",
            "            370.76121686799996,\n",
            "            116.8363215999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"f827e63fb077c922bdb201badf9538dc\",\n",
            "    \"text\": \"2023a.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            383.768387428,\n",
            "            116.8363215999999\n",
            "          ],\n",
            "          [\n",
            "            383.768387428,\n",
            "            126.79892159999997\n",
            "          ],\n",
            "          [\n",
            "            411.144416716,\n",
            "            126.79892159999997\n",
            "          ],\n",
            "          [\n",
            "            411.144416716,\n",
            "            116.8363215999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"691d7fdf7080b720f8a8071e195b16ae\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"836334aabadbdf6ca8aceb81f73d1164\",\n",
            "    \"text\": \"gpt4-x-vicuna-13b.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            448.37744244400005,\n",
            "            116.8363215999999\n",
            "          ],\n",
            "          [\n",
            "            448.37744244400005,\n",
            "            126.79892159999997\n",
            "          ],\n",
            "          [\n",
            "            526.1562576520001,\n",
            "            126.79892159999997\n",
            "          ],\n",
            "          [\n",
            "            526.1562576520001,\n",
            "            116.8363215999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"7d1236630fbec2f7f81c116ade9d829d\",\n",
            "    \"text\": \"https://huggingface.co/NousResearch/ gpt4-x-vicuna-13b. Model on Hugging Face.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            321.086,\n",
            "            127.37689239999997\n",
            "          ],\n",
            "          [\n",
            "            321.086,\n",
            "            148.7159216\n",
            "          ],\n",
            "          [\n",
            "            512.8067844000001,\n",
            "            148.7159216\n",
            "          ],\n",
            "          [\n",
            "            512.8067844000001,\n",
            "            127.37689239999997\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"https :// huggingface . co / NousResearch / gpt4 - x - vicuna - 13b . Model on Hugging Face .\",\n",
            "          \"url\": \"https://huggingface.co/NousResearch/gpt4-x-vicuna-13b\",\n",
            "          \"start_index\": 0\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"ad50d6c212c9ead7c7d08664b1f0a368\",\n",
            "    \"text\": \"Nous-Research.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            159.65732159999993\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            169.6199216\n",
            "          ],\n",
            "          [\n",
            "            370.76121686799996,\n",
            "            169.6199216\n",
            "          ],\n",
            "          [\n",
            "            370.76121686799996,\n",
            "            159.65732159999993\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"8f1a2b95024fc5a8a5b3a5142706fb6f\",\n",
            "    \"text\": \"2023b.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            384.306965584,\n",
            "            159.65732159999993\n",
            "          ],\n",
            "          [\n",
            "            384.306965584,\n",
            "            169.6199216\n",
            "          ],\n",
            "          [\n",
            "            412.252058584,\n",
            "            169.6199216\n",
            "          ],\n",
            "          [\n",
            "            412.252058584,\n",
            "            159.65732159999993\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"ad50d6c212c9ead7c7d08664b1f0a368\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"9bb17e6c8fda36fc71499b4fe0441a98\",\n",
            "    \"text\": \"Nous-hermes-13b.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            451.20243730000004,\n",
            "            159.65732159999993\n",
            "          ],\n",
            "          [\n",
            "            451.20243730000004,\n",
            "            169.6199216\n",
            "          ],\n",
            "          [\n",
            "            526.1562576520001,\n",
            "            169.6199216\n",
            "          ],\n",
            "          [\n",
            "            526.1562576520001,\n",
            "            159.65732159999993\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"fe871a36f9b133dd10e75d7e9343bd26\",\n",
            "    \"text\": \"https://huggingface.co/NousResearch/ Nous-Hermes-13b. Model on Hugging Face.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            321.086,\n",
            "            170.1978924\n",
            "          ],\n",
            "          [\n",
            "            321.086,\n",
            "            191.5379216\n",
            "          ],\n",
            "          [\n",
            "            502.34578440000007,\n",
            "            191.5379216\n",
            "          ],\n",
            "          [\n",
            "            502.34578440000007,\n",
            "            170.1978924\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"2c04966d0258539a0b71703eea37b41f\",\n",
            "    \"text\": \"Nous-Research. 2023c.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            202.47832159999996\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            212.44092160000002\n",
            "          ],\n",
            "          [\n",
            "            404.823744772,\n",
            "            212.44092160000002\n",
            "          ],\n",
            "          [\n",
            "            404.823744772,\n",
            "            202.47832159999996\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"8328bea0ed9a308f513b89b4809d19f0\",\n",
            "    \"text\": \"Nous-hermes-llama-2-7b.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            421.855008724,\n",
            "            202.47832159999996\n",
            "          ],\n",
            "          [\n",
            "            421.855008724,\n",
            "            212.44092160000002\n",
            "          ],\n",
            "          [\n",
            "            526.1562576520001,\n",
            "            212.44092160000002\n",
            "          ],\n",
            "          [\n",
            "            526.1562576520001,\n",
            "            202.47832159999996\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"81055478269ce81b5561884c98424677\",\n",
            "    \"text\": \"https://huggingface.co/NousResearch/ Nous-Hermes-llama-2-7b. Model on Hugging Face.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            321.086,\n",
            "            213.0188923999999\n",
            "          ],\n",
            "          [\n",
            "            321.086,\n",
            "            245.31792159999998\n",
            "          ],\n",
            "          [\n",
            "            524.408199856,\n",
            "            245.31792159999998\n",
            "          ],\n",
            "          [\n",
            "            524.408199856,\n",
            "            213.0188923999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"https :// huggingface . co / NousResearch / Nous - Hermes - llama - 2 - 7b . Model on Hugging\",\n",
            "          \"url\": \"https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b\",\n",
            "          \"start_index\": 0\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Nous - Hermes - llama - 2 - 7b\",\n",
            "          \"url\": \"https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b\",\n",
            "          \"start_index\": 37\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"95738f8b6f648f2d97a991304ccb420e\",\n",
            "    \"text\": \"Nous-Research.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            256.2593215999999\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            266.2219216\n",
            "          ],\n",
            "          [\n",
            "            370.76121686799996,\n",
            "            266.2219216\n",
            "          ],\n",
            "          [\n",
            "            370.76121686799996,\n",
            "            256.2593215999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"2484431e07b97b4f98a6ac8d59303d97\",\n",
            "    \"text\": \"2023d.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            381.268571836,\n",
            "            256.2593215999999\n",
            "          ],\n",
            "          [\n",
            "            381.268571836,\n",
            "            266.2219216\n",
            "          ],\n",
            "          [\n",
            "            409.213664836,\n",
            "            266.2219216\n",
            "          ],\n",
            "          [\n",
            "            409.213664836,\n",
            "            256.2593215999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"95738f8b6f648f2d97a991304ccb420e\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"0d0a73807f488d425d129e474ce8114a\",\n",
            "    \"text\": \"Redmond-puffin-13b.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            438.459474892,\n",
            "            256.2593215999999\n",
            "          ],\n",
            "          [\n",
            "            438.459474892,\n",
            "            266.2219216\n",
            "          ],\n",
            "          [\n",
            "            526.1562576520001,\n",
            "            266.2219216\n",
            "          ],\n",
            "          [\n",
            "            526.1562576520001,\n",
            "            256.2593215999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"c3c419152e30de95467de68011b36673\",\n",
            "    \"text\": \"https://huggingface.co/NousResearch/ Redmond-Puffin-13B. Model on Hugging Face.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            321.086,\n",
            "            266.7988924\n",
            "          ],\n",
            "          [\n",
            "            321.086,\n",
            "            288.1389216\n",
            "          ],\n",
            "          [\n",
            "            517.2897843999999,\n",
            "            288.1389216\n",
            "          ],\n",
            "          [\n",
            "            517.2897843999999,\n",
            "            266.7988924\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"https :// huggingface . co / NousResearch / Redmond - Puffin - 13B . Model on Hugging Face .\",\n",
            "          \"url\": \"https://huggingface.co/NousResearch/Redmond-Puffin-13B\",\n",
            "          \"start_index\": 0\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"f4154c37f41040e7f7b5dd83d6bb9f7d\",\n",
            "    \"text\": \"OpenAI. 2023. Gpt-4 technical report.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            299.08032159999993\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            309.0429216\n",
            "          ],\n",
            "          [\n",
            "            459.6855912000001,\n",
            "            309.0429216\n",
            "          ],\n",
            "          [\n",
            "            459.6855912000001,\n",
            "            299.08032159999993\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Gpt - 4 technical report\",\n",
            "          \"url\": \"http://arxiv.org/abs/2303.08774\",\n",
            "          \"start_index\": 14\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"0a537655c8ca57a623a7fa87b3193a18\",\n",
            "    \"text\": \"Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Ab- heesht Sharma, Andrea Santilli, Thibault Fevry, Ja- son Alan Fries, Ryan Teehan, Stella Biderman, Leo Gao, Tali Bers, Thomas Wolf, and Alexander M. Rush. 2021. Multitask prompted training enables zero-shot task generalization.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            319.98332159999995\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            483.3709216\n",
            "          ],\n",
            "          [\n",
            "            526.1562576520001,\n",
            "            483.3709216\n",
            "          ],\n",
            "          [\n",
            "            526.1562576520001,\n",
            "            319.98332159999995\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Multitask prompted training enables\",\n",
            "          \"url\": \"http://arxiv.org/abs/2110.08207\",\n",
            "          \"start_index\": 631\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"zero - shot task generalization\",\n",
            "          \"url\": \"http://arxiv.org/abs/2110.08207\",\n",
            "          \"start_index\": 667\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"f4154c37f41040e7f7b5dd83d6bb9f7d\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"886a7f467ba741ee5d07336e15bca148\",\n",
            "    \"text\": \"Stability-AI. 2023. Stablelm. https://github.com/ Stability-AI/StableLM. GitHub repository.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            493.89389239999997\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            515.2339216\n",
            "          ],\n",
            "          [\n",
            "            525.4057,\n",
            "            515.2339216\n",
            "          ],\n",
            "          [\n",
            "            525.4057,\n",
            "            493.89389239999997\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"https :// github . com /\",\n",
            "          \"url\": \"https://github.com/Stability-AI/StableLM\",\n",
            "          \"start_index\": 30\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Stability - AI / StableLM\",\n",
            "          \"url\": \"https://github.com/Stability-AI/StableLM\",\n",
            "          \"start_index\": 50\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"6161d90c7111121c9df590576b63d8d2\",\n",
            "    \"text\": \"https://github.com/\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            430.761,\n",
            "            525.7558924\n",
            "          ],\n",
            "          [\n",
            "            430.761,\n",
            "            535.7184924000001\n",
            "          ],\n",
            "          [\n",
            "            525.4057,\n",
            "            535.7184924000001\n",
            "          ],\n",
            "          [\n",
            "            525.4057,\n",
            "            525.7558924\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"14880807bec39d9525429193f10ca671\",\n",
            "    \"text\": \"StanGirard. 2023.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            526.1743216\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            536.1369216\n",
            "          ],\n",
            "          [\n",
            "            381.563265544,\n",
            "            536.1369216\n",
            "          ],\n",
            "          [\n",
            "            381.563265544,\n",
            "            526.1743216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
            "    \"text\": \"quivr. StanGirard/quivr. GitHub repository.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            321.086,\n",
            "            526.1743216\n",
            "          ],\n",
            "          [\n",
            "            321.086,\n",
            "            547.0959216\n",
            "          ],\n",
            "          [\n",
            "            481.48406000000006,\n",
            "            547.0959216\n",
            "          ],\n",
            "          [\n",
            "            481.48406000000006,\n",
            "            526.1743216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"page_number\": 5,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"f9127289b648f97d5468d9c534385556\",\n",
            "    \"text\": \"Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. Stanford alpaca: An instruction-following llama model. https:// github.com/tatsu-lab/stanford_alpaca.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            558.0373216\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            611.8349216\n",
            "          ],\n",
            "          [\n",
            "            525.7912084368,\n",
            "            611.8349216\n",
            "          ],\n",
            "          [\n",
            "            525.7912084368,\n",
            "            558.0373216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"https ://\",\n",
            "          \"url\": \"https://github.com/tatsu-lab/stanford_alpaca\",\n",
            "          \"start_index\": 189\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"github . com / tatsu - lab / stanford _ alpaca\",\n",
            "          \"url\": \"https://github.com/tatsu-lab/stanford_alpaca\",\n",
            "          \"start_index\": 198\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"1e03777b59eb46b371e2c0ec4e04c04c\",\n",
            "    \"text\": \"Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\\u00e9e Lacroix, Baptiste Rozi\\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023. Llama: Open and efficient foundation language models.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            622.7763216\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            698.4919216\n",
            "          ],\n",
            "          [\n",
            "            526.1521733600001,\n",
            "            698.4919216\n",
            "          ],\n",
            "          [\n",
            "            526.1521733600001,\n",
            "            622.7763216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Llama : Open and efficient foundation language\",\n",
            "          \"url\": \"http://arxiv.org/abs/2302.13971\",\n",
            "          \"start_index\": 238\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"models\",\n",
            "          \"url\": \"http://arxiv.org/abs/2302.13971\",\n",
            "          \"start_index\": 283\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"cb3d4cb151a83b755fbb5d192919a87a\",\n",
            "    \"text\": \"The Verge. 2023. Meta\\u2019s powerful ai language model has leaked online \\u2014 what happens now? The Verge.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            709.4333216\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            730.3549216\n",
            "          ],\n",
            "          [\n",
            "            526.15332765,\n",
            "            730.3549216\n",
            "          ],\n",
            "          [\n",
            "            526.15332765,\n",
            "            709.4333216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Meta \\u2019 s powerful ai language model\",\n",
            "          \"url\": \"https://www.theverge.com/2023/3/8/23629362/meta-ai-language-model-llama-leak-online-misuse\",\n",
            "          \"start_index\": 17\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"has leaked online \\u2014 what happens now ?\",\n",
            "          \"url\": \"https://www.theverge.com/2023/3/8/23629362/meta-ai-language-model-llama-leak-online-misuse\",\n",
            "          \"start_index\": 51\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"e3c968af341f5c57d0f600fc18d74a87\",\n",
            "    \"text\": \"James Vincent. 2023. As an ai generated language model: The phrase that shows how ai is polluting the web. The Verge.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.142,\n",
            "            741.2953216\n",
            "          ],\n",
            "          [\n",
            "            306.142,\n",
            "            773.1759216\n",
            "          ],\n",
            "          [\n",
            "            524.4084191080001,\n",
            "            773.1759216\n",
            "          ],\n",
            "          [\n",
            "            524.4084191080001,\n",
            "            741.2953216\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"As an ai generated language\",\n",
            "          \"url\": \"https://www.theverge.com/2023/4/25/23697218/ai-generated-spam-fake-user-reviews-as-an-ai-language-model\",\n",
            "          \"start_index\": 21\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"model : The phrase that shows how ai is polluting\",\n",
            "          \"url\": \"https://www.theverge.com/2023/4/25/23697218/ai-generated-spam-fake-user-reviews-as-an-ai-language-model\",\n",
            "          \"start_index\": 49\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"the web\",\n",
            "          \"url\": \"https://www.theverge.com/2023/4/25/23697218/ai-generated-spam-fake-user-reviews-as-an-ai-language-model\",\n",
            "          \"start_index\": 98\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"056688ab6012c536a7138e0807ad0938\",\n",
            "    \"text\": \"Ben Wang and Aran Komatsuzaki. 2021. GPT-J-6B: A 6 Billion Parameter Autoregressive Language https://github.com/kingoflolz/ Model. mesh-transformer-jax.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            74.0143215999999\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            116.85392159999992\n",
            "          ],\n",
            "          [\n",
            "            290.5144309800001,\n",
            "            116.85392159999992\n",
            "          ],\n",
            "          [\n",
            "            290.5144309800001,\n",
            "            74.0143215999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"https :// github . com / kingoflolz /\",\n",
            "          \"url\": \"https://github.com/kingoflolz/mesh-transformer-jax\",\n",
            "          \"start_index\": 93\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"mesh - transformer - jax\",\n",
            "          \"url\": \"https://github.com/kingoflolz/mesh-transformer-jax\",\n",
            "          \"start_index\": 131\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 6,\n",
            "      \"parent_id\": \"819962e277b97813ce073fd44e85f56f\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"363eb135576e9f6c12c1dd7f912c5941\",\n",
            "    \"text\": \"Eric J. Wang. 2023. alpaca-lora. https://github. com/tloen/alpaca-lora. GitHub repository.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            125.40089239999998\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            146.74092159999998\n",
            "          ],\n",
            "          [\n",
            "            292.6205,\n",
            "            146.74092159999998\n",
            "          ],\n",
            "          [\n",
            "            292.6205,\n",
            "            125.40089239999998\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"https :// github .\",\n",
            "          \"url\": \"https://github.com/tloen/alpaca-lora\",\n",
            "          \"start_index\": 33\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"com / tloen / alpaca - lora\",\n",
            "          \"url\": \"https://github.com/tloen/alpaca-lora\",\n",
            "          \"start_index\": 49\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 6,\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"9e1872a7627d65000001f6a1a6cdd620\",\n",
            "    \"text\": \"Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Han- naneh Hajishirzi. 2023. Self-instruct: Aligning lan- guage models with self-generated instructions.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            155.7063215999999\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            198.54592160000004\n",
            "          ],\n",
            "          [\n",
            "            290.784716692,\n",
            "            198.54592160000004\n",
            "          ],\n",
            "          [\n",
            "            290.784716692,\n",
            "            155.7063215999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Self - instruct : Aligning lan -\",\n",
            "          \"url\": \"http://arxiv.org/abs/2212.10560\",\n",
            "          \"start_index\": 121\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"guage models with self - generated instructions\",\n",
            "          \"url\": \"http://arxiv.org/abs/2212.10560\",\n",
            "          \"start_index\": 150\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 6,\n",
            "      \"parent_id\": \"363eb135576e9f6c12c1dd7f912c5941\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"1d4f3165609e78d1d6fb3065ae898420\",\n",
            "    \"text\": \"Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023. Wizardlm: Empowering large language models to follow complex instructions.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            207.51132159999997\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            250.3509216\n",
            "          ],\n",
            "          [\n",
            "            290.3823269040001,\n",
            "            250.3509216\n",
            "          ],\n",
            "          [\n",
            "            290.3823269040001,\n",
            "            207.51132159999997\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Wizardlm : Empowering large language\",\n",
            "          \"url\": \"http://arxiv.org/abs/2304.12244\",\n",
            "          \"start_index\": 106\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"models to follow complex instructions\",\n",
            "          \"url\": \"http://arxiv.org/abs/2304.12244\",\n",
            "          \"start_index\": 142\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 6,\n",
            "      \"parent_id\": \"363eb135576e9f6c12c1dd7f912c5941\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"7ef5091817209ce37c6cfb895b7c8acd\",\n",
            "    \"text\": \"Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            70.866,\n",
            "            259.3163215999999\n",
            "          ],\n",
            "          [\n",
            "            70.866,\n",
            "            313.1139216\n",
            "          ],\n",
            "          [\n",
            "            290.37824261200007,\n",
            "            313.1139216\n",
            "          ],\n",
            "          [\n",
            "            290.37824261200007,\n",
            "            259.3163215999999\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 595.276,\n",
            "        \"layout_height\": 841.89\n",
            "      },\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"gpt4all.pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:16\",\n",
            "      \"links\": [\n",
            "        {\n",
            "          \"text\": \"Judging\",\n",
            "          \"url\": \"http://arxiv.org/abs/2306.05685\",\n",
            "          \"start_index\": 186\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"llm - as - a - judge with mt - bench and chatbot arena\",\n",
            "          \"url\": \"http://arxiv.org/abs/2306.05685\",\n",
            "          \"start_index\": 194\n",
            "        }\n",
            "      ],\n",
            "      \"page_number\": 6,\n",
            "      \"parent_id\": \"363eb135576e9f6c12c1dd7f912c5941\",\n",
            "      \"filetype\": \"application/pdf\"\n",
            "    }\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_types = set()\n",
        "\n",
        "for item in element_dict:\n",
        "    unique_types.add(item['type'])\n",
        "\n",
        "print(unique_types)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95XhrjVX5iSv",
        "outputId": "83dc50de-e5cd-42b5-d024-45d786aaa557"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'NarrativeText', 'UncategorizedText', 'Title'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured.partition.pdf import partition_pdf\n",
        "\n",
        "# Specify the path to your PDF file\n",
        "filename = \"/content/scanned_gpt4all.pdf\"\n",
        "\n",
        "# Call the partition_pdf function\n",
        "# Returns a List[Element] present in the pages of the parsed pdf document\n",
        "elements = partition_pdf(filename)\n",
        "\n",
        "# Now, elements is a list of all elements present in the pages of the parsed pdf document"
      ],
      "metadata": {
        "id": "y6-ribup5iVM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elements"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cBcSJy95iXs",
        "outputId": "30821f26-7ba7-4128-9bc0-016a8783d973"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<unstructured.documents.elements.Text at 0x7a0e7463b160>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7463be20>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72716890>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72715ab0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72717100>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72715270>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e727141f0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e727150c0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e72715bd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e72716ad0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72716140>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e72714d90>,\n",
              " <unstructured.documents.elements.ListItem at 0x7a0e7275d240>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275dff0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275fbb0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275d2a0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275fa60>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275ea70>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275d540>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275ead0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275e020>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275ce80>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275d300>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275eb00>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275ce50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275dfc0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275eaa0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275cf40>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275cee0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275e8c0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275d720>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275d690>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275d270>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275e4d0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275d6f0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275f160>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74638c40>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275d150>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275d210>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275e140>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74638040>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275c5b0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275dc90>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275fa90>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275f370>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275c250>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275f430>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275e620>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275e650>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275d750>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275f340>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275d330>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275d990>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275d3f0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275e5f0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275eef0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275efb0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275fc10>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275c370>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275f2b0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275feb0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275c130>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275d1b0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275ff10>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275c100>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275fee0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275c820>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275c0d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275f550>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275d660>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275c790>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275e5c0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275d7b0>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275d5d0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275f4f0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275f610>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275cc70>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275caf0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275d7e0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275cb80>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275ca30>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275cb50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275c8b0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275e0b0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275f6a0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275fdc0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275f4c0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275e380>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275ee00>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275edd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275e770>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275eda0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275dc30>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275f0d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275c430>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275e7d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275dcf0>]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(elements)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoNYmI6x6pjj",
        "outputId": "78cabdc1-674d-4fd7-ad90-9da06b358233"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "element_dict = [el.to_dict() for el in elements]\n",
        "output = json.dumps(element_dict, indent=2)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAXMp1Ku6pmb",
        "outputId": "141995c0-49e4-4778-df8c-0f9a8a2b71c2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
            "    \"text\": \"2311.04931v1 [cs.CL] 6 Nov 2023\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            187.0,\n",
            "            718.0\n",
            "          ],\n",
            "          [\n",
            "            187.0,\n",
            "            1404.0\n",
            "          ],\n",
            "          [\n",
            "            230.0,\n",
            "            1404.0\n",
            "          ],\n",
            "          [\n",
            "            230.0,\n",
            "            718.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"e4fe3bbb0809b51d59fa5c6d32240053\",\n",
            "    \"text\": \"arXiv\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            187.0,\n",
            "            1422.0\n",
            "          ],\n",
            "          [\n",
            "            187.0,\n",
            "            1526.0\n",
            "          ],\n",
            "          [\n",
            "            220.0,\n",
            "            1526.0\n",
            "          ],\n",
            "          [\n",
            "            220.0,\n",
            "            1422.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"aa5e7c4eb5afd8a6a701200d14d0c5c1\",\n",
            "    \"text\": \"GPT4AIl: An Ecosystem of Open Source Compressed Language Models\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            330.0,\n",
            "            275.0\n",
            "          ],\n",
            "          [\n",
            "            330.0,\n",
            "            313.0\n",
            "          ],\n",
            "          [\n",
            "            1368.0,\n",
            "            313.0\n",
            "          ],\n",
            "          [\n",
            "            1368.0,\n",
            "            275.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"3b6229680e5b76a64d828388fc9558af\",\n",
            "    \"text\": \"Yuvanesh Anand Nomic AI yuvanesh@nomic.ai\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            310.0,\n",
            "            351.0\n",
            "          ],\n",
            "          [\n",
            "            310.0,\n",
            "            444.0\n",
            "          ],\n",
            "          [\n",
            "            548.0,\n",
            "            444.0\n",
            "          ],\n",
            "          [\n",
            "            548.0,\n",
            "            351.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"2b31179eb0e5f5f7d85c9fb0cb5b961e\",\n",
            "    \"text\": \"Zach Nussbaum Nomic AI zach@nomic. ai\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            613.0,\n",
            "            355.0\n",
            "          ],\n",
            "          [\n",
            "            613.0,\n",
            "            445.0\n",
            "          ],\n",
            "          [\n",
            "            806.0,\n",
            "            445.0\n",
            "          ],\n",
            "          [\n",
            "            806.0,\n",
            "            355.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"e99ec24d75fca645414a8eeba5922394\",\n",
            "    \"text\": \"Aaron Miller Nomic AI aaron@nomic.ai\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            1174.0,\n",
            "            357.0\n",
            "          ],\n",
            "          [\n",
            "            1174.0,\n",
            "            446.0\n",
            "          ],\n",
            "          [\n",
            "            1367.0,\n",
            "            446.0\n",
            "          ],\n",
            "          [\n",
            "            1367.0,\n",
            "            357.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"aa73c787d2d21bd8961c36711722db1d\",\n",
            "    \"text\": \"Adam Treat Nomic AI adam@nomic. ai\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            900.0,\n",
            "            357.0\n",
            "          ],\n",
            "          [\n",
            "            900.0,\n",
            "            446.0\n",
            "          ],\n",
            "          [\n",
            "            1079.0,\n",
            "            446.0\n",
            "          ],\n",
            "          [\n",
            "            1079.0,\n",
            "            357.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"f49db26031127120e27a8fb9be080262\",\n",
            "    \"text\": \"Richard Guo Ben Schmidt GPT4AIl Community Nomic AI Nomic AI Planet Earth richard@nomic. ai ben@nomic. ai Brandon Duderstadt* Andriy Mulyar* Nomic AI Nomic AI brandon@nomic. ai andriy@nomic.ai Abstract variety of queries, responding only with the now infa-\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            387.0,\n",
            "            503.0\n",
            "          ],\n",
            "          [\n",
            "            387.0,\n",
            "            847.0\n",
            "          ],\n",
            "          [\n",
            "            1384.0,\n",
            "            847.0\n",
            "          ],\n",
            "          [\n",
            "            1384.0,\n",
            "            503.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"aa73c787d2d21bd8961c36711722db1d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"7ca0f2ae4307b5e65fbbf275bd57f0d8\",\n",
            "    \"text\": \"Large language models (LLMs) have recently achieved human-level performance on a range of professional and academic benchmarks. The accessibility of these models has lagged behind their performance. State-of-the-art LLMs re- quire costly infrastructure; are only accessible via rate-limited, geo-locked, and censored web interfaces; and lack publicly available code and technical reports.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            356.0,\n",
            "            879.0\n",
            "          ],\n",
            "          [\n",
            "            356.0,\n",
            "            1127.0\n",
            "          ],\n",
            "          [\n",
            "            793.0,\n",
            "            1127.0\n",
            "          ],\n",
            "          [\n",
            "            793.0,\n",
            "            879.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"aa73c787d2d21bd8961c36711722db1d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"1078dd84576df5d9cd18dc21562c4667\",\n",
            "    \"text\": \"In this paper, we tell the story of GPT4All, a popular open source repository that aims to democratize access to LLMs. We outline the technical details of the original GPT4AII mode] family, as well as the evolution of the GPT4Al] project from a single model into a fully fledged open source ecosystem. It is our hope that this paper acts as both a technical overview of the original GPT4Al models as well as a case study on the subsequent growth of the GPT4AI] open source ecosystem.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            354.0,\n",
            "            1147.0\n",
            "          ],\n",
            "          [\n",
            "            354.0,\n",
            "            1454.0\n",
            "          ],\n",
            "          [\n",
            "            792.0,\n",
            "            1454.0\n",
            "          ],\n",
            "          [\n",
            "            792.0,\n",
            "            1147.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"aa73c787d2d21bd8961c36711722db1d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"8eb8570a7799605f1511b7abb329cd3d\",\n",
            "    \"text\": \"1 Introduction\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            314.0,\n",
            "            1493.0\n",
            "          ],\n",
            "          [\n",
            "            314.0,\n",
            "            1515.0\n",
            "          ],\n",
            "          [\n",
            "            509.0,\n",
            "            1515.0\n",
            "          ],\n",
            "          [\n",
            "            509.0,\n",
            "            1493.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"cc800a372051047b2ffd4c3251d06344\",\n",
            "    \"text\": \"On March 14 2023, OpenAI released GPT-4, a large language model capable of achieving human level per- formance on a yariety of professional and academic benchmarks. Despite the popularity of the release, the GPT-4 technical report (OpenAl, 2023) contained virtually no details regarding the architecture, hard- ware, training compute, dataset construction, or training method used to create the model, Moreover, users could only access the model through the internet interface at chat.openai.com, which was severely rate limited and unavailable in several locales (e.g. Italy) (BBC News, 2023). Additionally, GPT-4 refused to answer a wide\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            310.0,\n",
            "            1542.0\n",
            "          ],\n",
            "          [\n",
            "            310.0,\n",
            "            1884.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            1884.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            1542.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"8eb8570a7799605f1511b7abb329cd3d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"2dbce9fa5c8141f6497bfb64323e1a9a\",\n",
            "    \"text\": \"Shared Senior Authorship\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            347.0,\n",
            "            1915.0\n",
            "          ],\n",
            "          [\n",
            "            347.0,\n",
            "            1933.0\n",
            "          ],\n",
            "          [\n",
            "            562.0,\n",
            "            1933.0\n",
            "          ],\n",
            "          [\n",
            "            562.0,\n",
            "            1915.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"8eb8570a7799605f1511b7abb329cd3d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"83802e9c42af8178ba8f1fdca43809eb\",\n",
            "    \"text\": \"mous \\\"As an AI Language Model, I cannot...\\\" prefix (Vincent, 2023). These transparency and accessibility concerns spurred several developers to begin creating open source large language model (LLM) alternatives. Several grassroots efforts focused on fine tuning Meta\\u2019s open code LLaMA model (Touvron et al., 2023; McMil- lan, 2023), whose weights were leaked on BitTorrent less than_a week prior to the release of GPT-4 (Verge, 2023). GIJT4All started as one of these variants.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            870.0,\n",
            "            850.0\n",
            "          ],\n",
            "          [\n",
            "            870.0,\n",
            "            1095.0\n",
            "          ],\n",
            "          [\n",
            "            1384.0,\n",
            "            1095.0\n",
            "          ],\n",
            "          [\n",
            "            1384.0,\n",
            "            850.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"8eb8570a7799605f1511b7abb329cd3d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"07c98444db3b8431997668695e65e450\",\n",
            "    \"text\": \"In thiASaper, we tell the story of GPT4AlI. We com- ment on the technical details of the original GPT4Al model (Anand et al., 2023), as well as the evolution of GPT4AIl from a single model to an ecosystem of several models. We remark on the impact that the project has had on the open source community, and discuss future directions. It is our hope that this paper acts as both a technical overview of the original GPT4Al] models as well as a case study on the subsequent growth of the GPT4All open source ecosystem.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            871.0,\n",
            "            1104.0\n",
            "          ],\n",
            "          [\n",
            "            871.0,\n",
            "            1380.0\n",
            "          ],\n",
            "          [\n",
            "            1385.0,\n",
            "            1380.0\n",
            "          ],\n",
            "          [\n",
            "            1385.0,\n",
            "            1104.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"8eb8570a7799605f1511b7abb329cd3d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"733695a3173f6e088d89321305d070f1\",\n",
            "    \"text\": \"2 The Original GPT4AII Model\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            871.0,\n",
            "            1413.0\n",
            "          ],\n",
            "          [\n",
            "            871.0,\n",
            "            1440.0\n",
            "          ],\n",
            "          [\n",
            "            1266.0,\n",
            "            1440.0\n",
            "          ],\n",
            "          [\n",
            "            1266.0,\n",
            "            1413.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"27a88b704141fe0da95e8e02e515b79d\",\n",
            "    \"text\": \"2.1 Data Collection and Curation\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            871.0,\n",
            "            1465.0\n",
            "          ],\n",
            "          [\n",
            "            871.0,\n",
            "            1482.0\n",
            "          ],\n",
            "          [\n",
            "            1219.0,\n",
            "            1482.0\n",
            "          ],\n",
            "          [\n",
            "            1219.0,\n",
            "            1465.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"6ec13ad59960463ba50e9b6bc7fcec29\",\n",
            "    \"text\": \"To train the original GPT4All model, we collected roughly one million prompt-response pairs using the GPT-3,5-Turbo OpenAI API between March 20, 2023 and March 26th, 2023, In particular, we gathered GPT- 3.5-Turbo responses to prompts of three publicly avail- able datasets: the unified chip2 subset of LAION OIG, a random sub-sample of Stackoverflow Questions, and a sub-sample of Bigscience/P3 (Sanh et al., 2021). Fol- lowing the approach in Stanford Alpaca (Taori et al., 2023), an open source LLaMA variant that came just be- fore GPT4AIl, we focused substantial effort on dataset curation,\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            869.0,\n",
            "            1503.0\n",
            "          ],\n",
            "          [\n",
            "            869.0,\n",
            "            1838.0\n",
            "          ],\n",
            "          [\n",
            "            1389.0,\n",
            "            1838.0\n",
            "          ],\n",
            "          [\n",
            "            1389.0,\n",
            "            1503.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"27a88b704141fe0da95e8e02e515b79d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"c9462cb1f13d8c4b319e4228c23948b8\",\n",
            "    \"text\": \"The collected dataset was loaded into Atlas (Al, 2023)\\u2014a visual interface for exploring and tagging mas\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            872.0,\n",
            "            1851.0\n",
            "          ],\n",
            "          [\n",
            "            872.0,\n",
            "            1902.0\n",
            "          ],\n",
            "          [\n",
            "            1389.0,\n",
            "            1902.0\n",
            "          ],\n",
            "          [\n",
            "            1389.0,\n",
            "            1851.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"27a88b704141fe0da95e8e02e515b79d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"4864442e74fdf0e16c3fe0e80d73e48b\",\n",
            "    \"text\": \"sive unstructured datasets \\u2014for data curation, Using At\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            860.0,\n",
            "            1905.0\n",
            "          ],\n",
            "          [\n",
            "            860.0,\n",
            "            1935.0\n",
            "          ],\n",
            "          [\n",
            "            1382.0,\n",
            "            1935.0\n",
            "          ],\n",
            "          [\n",
            "            1382.0,\n",
            "            1905.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"27a88b704141fe0da95e8e02e515b79d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"9f9c38708322ca2ad595d06e8dce7f36\",\n",
            "    \"text\": \"las, we identified and removed subsets of the data where GPT-3.5-Turbo refused to respond, had malformed out- put, or produced a very short response. This resulted in the removal of the entire Bigscience/P3 subset of our data, as many P3 prompts induced responses that were simply one word. After curation, we were left with a set of 437,605 prompt-response pairs, which we visualize in Figure 1a.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            322.0,\n",
            "            259.0\n",
            "          ],\n",
            "          [\n",
            "            322.0,\n",
            "            484.0\n",
            "          ],\n",
            "          [\n",
            "            838.0,\n",
            "            484.0\n",
            "          ],\n",
            "          [\n",
            "            838.0,\n",
            "            259.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"27a88b704141fe0da95e8e02e515b79d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"9d7097ade60591eb70584599d4462684\",\n",
            "    \"text\": \"2.2. Model Training\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            324.0,\n",
            "            510.0\n",
            "          ],\n",
            "          [\n",
            "            324.0,\n",
            "            535.0\n",
            "          ],\n",
            "          [\n",
            "            532.0,\n",
            "            535.0\n",
            "          ],\n",
            "          [\n",
            "            532.0,\n",
            "            510.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"bd02232e727d1cbf75106ef8544d1230\",\n",
            "    \"text\": \"The original GPT4AI1 model was a fine tuned variant of LLaMA 7B. In order to train it more efficiently, we froze the base weights of LLaMA, and only trained a small set of LoRA (Hu et al., 2021) weights during the fine tuning process. Detailed model hyper-parameters and training code can be found in our associated code\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            323.0,\n",
            "            549.0\n",
            "          ],\n",
            "          [\n",
            "            323.0,\n",
            "            713.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            713.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            549.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"9d7097ade60591eb70584599d4462684\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"b7c98178067be445b1d32a7f7b7de4c7\",\n",
            "    \"text\": \"repository\\u2019. 2.3. Model Access\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            324.0,\n",
            "            717.0\n",
            "          ],\n",
            "          [\n",
            "            324.0,\n",
            "            787.0\n",
            "          ],\n",
            "          [\n",
            "            512.0,\n",
            "            787.0\n",
            "          ],\n",
            "          [\n",
            "            512.0,\n",
            "            717.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"a0aa7d4d319c6bc0314ea8ef359c88cf\",\n",
            "    \"text\": \"We publicly released all data, training code, and model weights for the community to build upon. Further, we provided a 4-bit quantized version of the model, which enabled users to run it on their own commodity hard- ware without transferring data to a 3rd party service.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            323.0,\n",
            "            806.0\n",
            "          ],\n",
            "          [\n",
            "            323.0,\n",
            "            945.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            945.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            806.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"b7c98178067be445b1d32a7f7b7de4c7\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"9bcea687b18e61c18e3d1e774e3afee1\",\n",
            "    \"text\": \"Our research and development costs were dominated by ~$800 in GPU spend (rented from Lambda Labs and Paperspace) and ~$500 in OpenAl API spend. Our final GPT4AII model could be trained in about eight hours ona Lambda Labs DGX A100 8x 80GB for a total cost of ~$100.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            325.0,\n",
            "            948.0\n",
            "          ],\n",
            "          [\n",
            "            325.0,\n",
            "            1107.0\n",
            "          ],\n",
            "          [\n",
            "            832.0,\n",
            "            1107.0\n",
            "          ],\n",
            "          [\n",
            "            832.0,\n",
            "            948.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"b7c98178067be445b1d32a7f7b7de4c7\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"cbfb9aa9127dfca004d2dd75155a629c\",\n",
            "    \"text\": \"2.4 Model Evaluation\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            324.0,\n",
            "            1137.0\n",
            "          ],\n",
            "          [\n",
            "            324.0,\n",
            "            1155.0\n",
            "          ],\n",
            "          [\n",
            "            553.0,\n",
            "            1155.0\n",
            "          ],\n",
            "          [\n",
            "            553.0,\n",
            "            1137.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"c18a56b66088be9d58c065a4a8bc27d3\",\n",
            "    \"text\": \"We performed a preliminary evaluation of our model using the human evaluation data from the Self Instruct paper (Wang et al., 2023). We reported the ground truth perplexity of our model against what was, to our knowl- edge, the best openly available alpaca-lora model at the time, provided by user chainyo on HuggingFace. Both models had very large perplexities on a small number of tasks, so we reported perplexities clipped to a maximum of 100, We found that GPT4All produces stochastically lower ground truth perplexitics than alpaca-lora (Anand et al., 2023).\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            322.0,\n",
            "            1175.0\n",
            "          ],\n",
            "          [\n",
            "            322.0,\n",
            "            1477.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            1477.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            1175.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"cbfb9aa9127dfca004d2dd75155a629c\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"0f2ac1ad48e313fde439d850f90442c6\",\n",
            "    \"text\": \"3 From a Model to an Ecosystem\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            322.0,\n",
            "            1508.0\n",
            "          ],\n",
            "          [\n",
            "            322.0,\n",
            "            1536.0\n",
            "          ],\n",
            "          [\n",
            "            731.0,\n",
            "            1536.0\n",
            "          ],\n",
            "          [\n",
            "            731.0,\n",
            "            1508.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"f4f0c6e1d309c744fc08d0eafe010419\",\n",
            "    \"text\": \"3.1 GPT4AII-J: Repository Growth and the implications of the LLaMA License\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            322.0,\n",
            "            1557.0\n",
            "          ],\n",
            "          [\n",
            "            322.0,\n",
            "            1606.0\n",
            "          ],\n",
            "          [\n",
            "            765.0,\n",
            "            1606.0\n",
            "          ],\n",
            "          [\n",
            "            765.0,\n",
            "            1557.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"b803be6270bdf862ec03af9cdc88342b\",\n",
            "    \"text\": \"The GPT4AIl repository grew rapidly after its release, gaining over 20000 GitHub stars in just one week, as shown in Figure 2. This growth was supported by an in-person hackathon hosted in New York City three days after the model release, which attracted several hundred participants, As the Nomic discord, the home of online discussion about GPT4AII, ballooned to over 10000 people, one thing became very clear - there was massive demand for a model that could be used commercially\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            319.0,\n",
            "            1623.0\n",
            "          ],\n",
            "          [\n",
            "            319.0,\n",
            "            1874.0\n",
            "          ],\n",
            "          [\n",
            "            830.0,\n",
            "            1874.0\n",
            "          ],\n",
            "          [\n",
            "            830.0,\n",
            "            1623.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"f4f0c6e1d309c744fc08d0eafe010419\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"e115fbaefce694ef2d4b4941e494ab65\",\n",
            "    \"text\": \"hups://github.com/nomic-ai/gpttall\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            353.0,\n",
            "            1898.0\n",
            "          ],\n",
            "          [\n",
            "            353.0,\n",
            "            1916.0\n",
            "          ],\n",
            "          [\n",
            "            625.0,\n",
            "            1916.0\n",
            "          ],\n",
            "          [\n",
            "            625.0,\n",
            "            1898.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"b19971570fdcd00590a97c87963c5da7\",\n",
            "    \"text\": \"The LLaMA model that GPT4AII was based on was licensed for research only, which severely limited the set of domains that GPT4AII could be applied in. As a response to this, the Nomic team repeated the model training procedure of the original GPT4AII model, but based on the already open source and commercially li- censed GPT-J model (Wang and Komatsuzaki, 2021). GPT4AII-J also had an augmented training set, which contained multi-tum QA examples and creative writing such as poetry, rap, and short stories. The creative writ- ing prompts were generated by filling in schemas such as \\\"Write a [CREATIVE STORY TYPE] about [NOUN] in the style of [PERSON].\\\" We again employed Atlas to curate the prompt-response pairs in this data set.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            874.0,\n",
            "            265.0\n",
            "          ],\n",
            "          [\n",
            "            874.0,\n",
            "            662.0\n",
            "          ],\n",
            "          [\n",
            "            1390.0,\n",
            "            662.0\n",
            "          ],\n",
            "          [\n",
            "            1390.0,\n",
            "            265.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"e115fbaefce694ef2d4b4941e494ab65\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"2c3d8b98ff7a64d7349e31a728a61e4c\",\n",
            "    \"text\": \"Our evaluation methodology also evolved as the project grew. In particular, we began evaluating GPT4All models using a suite of seven reasoning tasks that were used for evaluation of the Databricks Dolly (Conover et al., 2023b) model, which was re- leased on April 12, 2023. Unfortunately, GPT4AII-J did not outperform other prominent open source models on this evaluation. As a result, we endeavoured to create a model that did,\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            873.0,\n",
            "            668.0\n",
            "          ],\n",
            "          [\n",
            "            873.0,\n",
            "            913.0\n",
            "          ],\n",
            "          [\n",
            "            1385.0,\n",
            "            913.0\n",
            "          ],\n",
            "          [\n",
            "            1385.0,\n",
            "            668.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"e115fbaefce694ef2d4b4941e494ab65\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"c9b9905ddf0ee056022c2b4502277815\",\n",
            "    \"text\": \"3.2. GPT4All-Snoozy: the Emergence of the GPT4All Ecosystem\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            873.0,\n",
            "            946.0\n",
            "          ],\n",
            "          [\n",
            "            873.0,\n",
            "            998.0\n",
            "          ],\n",
            "          [\n",
            "            1315.0,\n",
            "            998.0\n",
            "          ],\n",
            "          [\n",
            "            1315.0,\n",
            "            946.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"c2a47150e4e2c19fff008eb99ca36972\",\n",
            "    \"text\": \"GPT4All-Snoozy was developed using roughly the same procedure as the previous GPT4AIl models, but with a few key modifications. First, GPT4All-Snoozy used the LLaMA-13B base mcs due to its superior base metrics when compared to orf Next, GPT4All-Snoozy incor- porated the Dolly\\u2019s traifing data into its train mix. After data curation and deduplication with Atlas, this yielded a training set of 739,259 total prompt-response pairs. We dubbed the model that resulted from training on this improved dataset GPT4AIl-Snoozy. As shown in Figure 1, GPT4All-Snoozy had the best average score on our evaluation benchmark of any model in the ecosystem at the time of its release.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            869.0,\n",
            "            1015.0\n",
            "          ],\n",
            "          [\n",
            "            869.0,\n",
            "            1370.0\n",
            "          ],\n",
            "          [\n",
            "            1382.0,\n",
            "            1370.0\n",
            "          ],\n",
            "          [\n",
            "            1382.0,\n",
            "            1015.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"c9b9905ddf0ee056022c2b4502277815\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"8b2f032983b9c4cbc99d5681e64b22d7\",\n",
            "    \"text\": \"Concurrently with the development of GPT4AI, sev- eral organizations such as LMSys, Stability Al, BAIR, and Databricks built and deployed open source language models, We heard increasingly from the community that they wanted quantized versions of these models for local use. As we realized that organizations with ever more resources were developing source language models, we decided to pivot our effort away from training increas: ingly capable models and towards providing easy access to the plethora of models being produced by the open source community. Practically, this meant spending our time compressing open source models for use on com- modity hardware, providing stable and simple high level model APIs, and supporting a GUI for no code model experimentation\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            867.0,\n",
            "            1381.0\n",
            "          ],\n",
            "          [\n",
            "            867.0,\n",
            "            1799.0\n",
            "          ],\n",
            "          [\n",
            "            1380.0,\n",
            "            1799.0\n",
            "          ],\n",
            "          [\n",
            "            1380.0,\n",
            "            1381.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"c9b9905ddf0ee056022c2b4502277815\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"ca08f896cbd9782d95d05bb0d1a3f3a0\",\n",
            "    \"text\": \"33\\u00b0 The Current State of GPT4AlL\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            867.0,\n",
            "            1829.0\n",
            "          ],\n",
            "          [\n",
            "            867.0,\n",
            "            1851.0\n",
            "          ],\n",
            "          [\n",
            "            1219.0,\n",
            "            1851.0\n",
            "          ],\n",
            "          [\n",
            "            1219.0,\n",
            "            1829.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"c05fce8c12177e8db3c3961df671f496\",\n",
            "    \"text\": \"Today, GPT4AI1 is focused on improving the accessi bility of open source language models. The repository\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            867.0,\n",
            "            1870.0\n",
            "          ],\n",
            "          [\n",
            "            867.0,\n",
            "            1926.0\n",
            "          ],\n",
            "          [\n",
            "            1372.0,\n",
            "            1926.0\n",
            "          ],\n",
            "          [\n",
            "            1372.0,\n",
            "            1870.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"ca08f896cbd9782d95d05bb0d1a3f3a0\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"583893028def4f6b9b760a521a2d550d\",\n",
            "    \"text\": \"@) (b) (\\u00a9) (d)\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            435.0,\n",
            "            520.0\n",
            "          ],\n",
            "          [\n",
            "            435.0,\n",
            "            553.0\n",
            "          ],\n",
            "          [\n",
            "            1245.0,\n",
            "            553.0\n",
            "          ],\n",
            "          [\n",
            "            1245.0,\n",
            "            520.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"ca08f896cbd9782d95d05bb0d1a3f3a0\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"e134e4782987530cad118447d806ce4a\",\n",
            "    \"text\": \"Figure 1: TSNE visualizations showing the progression of the GPT4AII train set. Panel (a) shows the original uncurated data, The red arrow denotes a region of highly homogeneous prompt-response pairs. The coloring denotes which open dataset contributed the prompt. Panel (b) shows the original GPT4AlI data after curation. This panel, as well as panels (c) and (d) are 10 colored by topic, which Atlas automatically extracts. Notice that the large homogeneous prompt-response blobs no longer appearl. Panel (c) shows the GPT4AlIlI-J dataset. The \\\"starburst\\\" clusters introduced on the right side of the panel correspond to the newly added creative data. Panel (d) shows the final GPT4All-snoozy dataset. All datasets have been released to the public, and can be interactively explored online. In the web version of this article, you can click on a panel to be taken to its interactive visualization.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            316.0,\n",
            "            572.0\n",
            "          ],\n",
            "          [\n",
            "            316.0,\n",
            "            796.0\n",
            "          ],\n",
            "          [\n",
            "            1385.0,\n",
            "            796.0\n",
            "          ],\n",
            "          [\n",
            "            1385.0,\n",
            "            572.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"ca08f896cbd9782d95d05bb0d1a3f3a0\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"8ad44ca09461bffe5911992317f925f7\",\n",
            "    \"text\": \"Model BoolQ PIQA HellaSwag WinoG. ARC-c ARC-c OBQA Avg. GPT4AII-J 6B v1.0* 73.4 74.8 634 64.7 54.9 36 40.2 58.2 GPT4AII-J v1.1-breezy* 74 75.1 63.2 63.6 55.4 34.9 38.4 57.8 GPT4AIIL-J v1.2-jazzy* 74.8 74.9 63.6 638 56.6 35.3 41 58.6 GPT4AII-J v1.3-groovy* 73.6 74.3 63.8 63.5 57.7 35 38.8 \\u00a9 58.1 GPT4AII-J Lora 6B* 68.6 75.8 66.2 63.5 56.4 35.7 402 58.1 GPT4All LLaMa Lora 7B* 73.1 77.6 721 67.8 SIE 40.4 40.2 60.3 GPT4All 13B snoozy* 83.3 79.2 75 71.3 60.9 44.2 43.4 65.3 GPT4AIl Falcon 71.6 79.8 749 70.1 67.9 4B4 42.6 65.2 Nous-Hermes (Nous-Research, 2023b) 79.5 78.9 80 19 74.2 50.9 64 68.3 Nous-Hermes2 (Nous-Research, 2023c) 83.9 80.7 80.1 71.3 75.7 52.1 46.2 70.0 Nous-Puffin (Nous-Research, 2023d) 815 80.7 80.4 72.5 771.6 50.7 45.6 69.9 Dolly 6B* (Conover et al., 2023a) 68.8 71.3 67.6 63.9 62.9 38.7 412 1 Dolly 12B* (Conover et al., 2023) 56.7 75.4 1 62.2 64.6 38.5 404 584 Alpaca 7B* (Taori et al. , 2023) 73.9 TT 73.9 66.1 59.8 43.3 434 62.5 Alpaca Lora 7B* Wang. 2023) 94325793 74 68.8 56.6 43.9 426 628 GPT-J* 6.7B (Wang and Komatsuzaki, 2021) 654 76.2 66.2 64.1 62.2 36.6 38.2 58.4 LLama 7B* (Touvron et al., 2023) 73.1 714 13 66.9 52.5 414 42.4 61.0 LLama 13B* (Touvron et al_, 2023) 68.5 79.1 76.2 70.1 60 44.6 422 63.0 Pythia 6.7B* (Biderman et al., 2023) 63.5 76.3 64 61.1 61.3 35.2 37.2 56.9 Pythia 12B* (Biderman et al., 2023) 67.7 16.6 67.3 63.8 63.9 34.8 38 58.9 Fastchat TS* (Zheng et al., 2023) 815 64.6 46.3 618 49.3 (33.2. 39.4 53.7 Fastchat Vicufia* 7B (Zheng et al., 2023) 76.6 77.2 70.7 67.3 53.5 41.2 40.8 61.0 Fastchat Vicufia 13B* (Zheng et al., 2023) 815 76.8 73.3 66.7 57.4 42.7 3.6 63.1 Stable Vicufia RLHF* (Stability-Al, 2023) 82.3 78.6 74.1 70.9 61 43.5 444 65.0 StableLM Tuned* (Stability-Al, 2023) 625 71.2 53.6 54.8 52.4 31 33.4 SUS StableLM Base* (Stability-Al, 2023) 60.1 67.4 412 50.1 44.9 27 32 46.1 Koala 13B* (Geng et al., 2023) 765 71.9 72.6 68.8 54.3 4l 42.8 62.0 Open Assistant Pythia 12B* 67.9 3 68.1 65 64.2 40.4 43.2 61.0 Mosaic MPT7B (MosaicML-Team, 2023) 748 193 76.3 68.6 70 42.2 42.6 64.8 Mosaic mpt-instruct (MosaicML-Team, 2023) 743 80.4 77.2. 678 72.2 44.6 43 65.6 Mosaic mpt-chat (MosaicML-Team, 2023) 771 78.2 74.5 67.5 69.4 43.3 44.2 9 Wizard 7B xu et al., 2023) 74 772 69.9 66,5 56.8 40.5 42.6 61,7 Wizard 7B Uncensored (Xu et al., 2023) 717 74.2 68 65.2 53.5 38,7 416 59.8 Wizard 13B Uncensored (Xu et al,, 2023) 784 15.5 21 69.5 57.5 40.4 44 62.5 GPT4-x-Vicuna-13b (Nous-Research, 2023a) 813 75 75.2 65 58.7 43,9 43.6 63,2 Falcon 7b (Almazrouei et al., 2023) 7236 80.7 16.3 67,3 1 43.3 444 65.2 Falcon 7b instruct (Almazrouei et al., 2023) 9 78.6 69.8 66.7 619) 4a 4 OS text-davinci-003 88.1 83.8 834 75.8 83.9 63.9 SLO 2\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            315.0,\n",
            "            833.0\n",
            "          ],\n",
            "          [\n",
            "            315.0,\n",
            "            1652.0\n",
            "          ],\n",
            "          [\n",
            "            1376.0,\n",
            "            1652.0\n",
            "          ],\n",
            "          [\n",
            "            1376.0,\n",
            "            833.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"ca08f896cbd9782d95d05bb0d1a3f3a0\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"57f7ed876c54c522595f29bfa50ae0ed\",\n",
            "    \"text\": \"Table 1: Evaluations of all language models in the GPT4AIl ecosystem as of August 1, 2023, Code models are not included. OpenAI\\u2019s text-davinci-003 is included as a point of comparison. The best overall performing model in the GPT4AIl ecosystem, Nous-Hermes?, achieves over 92% of the average performance of text-davinci-003, Models marked with an asterisk were available in the ecosystem as of the release of GPT4All-Snoozy. Note that at release, GPT4AII-Snoozy had the best average performance of any model in the ecosystem. Bolded numbers indicate the best performing model as of August 1, 2023\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            308.0,\n",
            "            1677.0\n",
            "          ],\n",
            "          [\n",
            "            308.0,\n",
            "            1850.0\n",
            "          ],\n",
            "          [\n",
            "            1378.0,\n",
            "            1850.0\n",
            "          ],\n",
            "          [\n",
            "            1378.0,\n",
            "            1677.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"ca08f896cbd9782d95d05bb0d1a3f3a0\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"fae05d8e02ce0c387969c227af5f183a\",\n",
            "    \"text\": \"Github Repo Growth\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            776.0,\n",
            "            294.0\n",
            "          ],\n",
            "          [\n",
            "            776.0,\n",
            "            313.0\n",
            "          ],\n",
            "          [\n",
            "            942.0,\n",
            "            313.0\n",
            "          ],\n",
            "          [\n",
            "            942.0,\n",
            "            294.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"7925282b336737d8ff77bf1c29aa7ee2\",\n",
            "    \"text\": \"\\u2014 GPT4All \\u2014- UaMA \\u2014 Apaca\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            624.0,\n",
            "            329.0\n",
            "          ],\n",
            "          [\n",
            "            624.0,\n",
            "            386.0\n",
            "          ],\n",
            "          [\n",
            "            715.0,\n",
            "            386.0\n",
            "          ],\n",
            "          [\n",
            "            715.0,\n",
            "            329.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"af345d782230a2d1faf3c81a360e7e00\",\n",
            "    \"text\": \"50000\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            558.0,\n",
            "            331.0\n",
            "          ],\n",
            "          [\n",
            "            558.0,\n",
            "            342.0\n",
            "          ],\n",
            "          [\n",
            "            600.0,\n",
            "            342.0\n",
            "          ],\n",
            "          [\n",
            "            600.0,\n",
            "            331.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"7925282b336737d8ff77bf1c29aa7ee2\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"b1a2bb160ab31d838d73def9fae6cf64\",\n",
            "    \"text\": \"40000\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            559.0,\n",
            "            398.0\n",
            "          ],\n",
            "          [\n",
            "            559.0,\n",
            "            409.0\n",
            "          ],\n",
            "          [\n",
            "            601.0,\n",
            "            409.0\n",
            "          ],\n",
            "          [\n",
            "            601.0,\n",
            "            398.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"7925282b336737d8ff77bf1c29aa7ee2\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"604cb1546e239c9c8a5937711c3680f6\",\n",
            "    \"text\": \"30000\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            560.0,\n",
            "            467.0\n",
            "          ],\n",
            "          [\n",
            "            560.0,\n",
            "            477.0\n",
            "          ],\n",
            "          [\n",
            "            601.0,\n",
            "            477.0\n",
            "          ],\n",
            "          [\n",
            "            601.0,\n",
            "            467.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"7925282b336737d8ff77bf1c29aa7ee2\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"e774b0ef0faa4dcd59db34da68b2a8c4\",\n",
            "    \"text\": \"Github Stars\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            538.0,\n",
            "            461.0\n",
            "          ],\n",
            "          [\n",
            "            538.0,\n",
            "            548.0\n",
            "          ],\n",
            "          [\n",
            "            550.0,\n",
            "            548.0\n",
            "          ],\n",
            "          [\n",
            "            550.0,\n",
            "            461.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"8e87bb21077b390100c48a1a71584b0c\",\n",
            "    \"text\": \"i\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            560.0,\n",
            "            534.0\n",
            "          ],\n",
            "          [\n",
            "            560.0,\n",
            "            545.0\n",
            "          ],\n",
            "          [\n",
            "            602.0,\n",
            "            545.0\n",
            "          ],\n",
            "          [\n",
            "            602.0,\n",
            "            534.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"c343d14141cec8eba388dd7afe3656f3\",\n",
            "    \"text\": \"10000\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            562.0,\n",
            "            601.0\n",
            "          ],\n",
            "          [\n",
            "            562.0,\n",
            "            612.0\n",
            "          ],\n",
            "          [\n",
            "            602.0,\n",
            "            612.0\n",
            "          ],\n",
            "          [\n",
            "            602.0,\n",
            "            601.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"8e87bb21077b390100c48a1a71584b0c\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"88492d084aef06b761dc6a31264e7bbb\",\n",
            "    \"text\": \"0 20 40 60\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            633.0,\n",
            "            694.0\n",
            "          ],\n",
            "          [\n",
            "            633.0,\n",
            "            722.0\n",
            "          ],\n",
            "          [\n",
            "            832.0,\n",
            "            722.0\n",
            "          ],\n",
            "          [\n",
            "            832.0,\n",
            "            694.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"8e87bb21077b390100c48a1a71584b0c\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"5d2f9d059fb7f8422b8a379fc4f19f02\",\n",
            "    \"text\": \"80 100-120 140\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            877.0,\n",
            "            702.0\n",
            "          ],\n",
            "          [\n",
            "            877.0,\n",
            "            713.0\n",
            "          ],\n",
            "          [\n",
            "            1084.0,\n",
            "            713.0\n",
            "          ],\n",
            "          [\n",
            "            1084.0,\n",
            "            702.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"8e87bb21077b390100c48a1a71584b0c\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"166007c1bd4d25db96d5153c1d2c7ee9\",\n",
            "    \"text\": \"Days Since Launch\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            796.0,\n",
            "            721.0\n",
            "          ],\n",
            "          [\n",
            "            796.0,\n",
            "            735.0\n",
            "          ],\n",
            "          [\n",
            "            924.0,\n",
            "            735.0\n",
            "          ],\n",
            "          [\n",
            "            924.0,\n",
            "            721.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"f58ffd0577b70d0bb6041d445e5c1f36\",\n",
            "    \"text\": \"Figure 2: Comparison of the github start growth of GPT4All, Meta\\u2019s LLaMA, and Stanford\\u2019s Alpaca. We conjecture that GPT4AIl achieved and maintains faster ecosystem growth due to the focus on access, which allows more users\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            319.0,\n",
            "            769.0\n",
            "          ],\n",
            "          [\n",
            "            319.0,\n",
            "            822.0\n",
            "          ],\n",
            "          [\n",
            "            1383.0,\n",
            "            822.0\n",
            "          ],\n",
            "          [\n",
            "            1383.0,\n",
            "            769.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"166007c1bd4d25db96d5153c1d2c7ee9\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"a8256c49504c5a402e34150cc681af19\",\n",
            "    \"text\": \"to meaningfully participate.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            319.0,\n",
            "            826.0\n",
            "          ],\n",
            "          [\n",
            "            319.0,\n",
            "            849.0\n",
            "          ],\n",
            "          [\n",
            "            579.0,\n",
            "            849.0\n",
            "          ],\n",
            "          [\n",
            "            579.0,\n",
            "            826.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"166007c1bd4d25db96d5153c1d2c7ee9\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"be94bab4d071a81feb41305425beb04c\",\n",
            "    \"text\": \"provides compressed versions of open source models for use on commodity hardware, stable and simple high level model APIs, and a GUI for no code model ex- perimentation. The project continues to increase in popularity, and as of August 1 2023, has garnered over 50000 GitHub stars and over 5000 forks.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            319.0,\n",
            "            907.0\n",
            "          ],\n",
            "          [\n",
            "            319.0,\n",
            "            1067.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1067.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            907.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"166007c1bd4d25db96d5153c1d2c7ee9\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"4684c7bc87da1a1efdd95d4e71b24361\",\n",
            "    \"text\": \"GPT4All currently provides native support and benchmark data for over 35 models (see Figure 1), and includes several models co-developed with industry part- ners such as Replit and Hugging Face. GPT4AII also provides high level model APIs in languages includ- ing Python, Typescript, Go, C#, and Java, among oth- ers. Furthermore, the GPT4All no code GUI currently supports the workflows of over 50000 monthly active users, with over 25% of users coming back to the tool every day of the week. (Note that all GPT4AII user data is collected on an opt in basis.) GPT4AIl has be- come the top language model integration in the popular open source AI orchestration library LangChain (Chase, 2022), and powers many popular open source projects such as PrivateGPT (imartinez, 2023), Quiver (StanGi- rard, 2023), and MindsDB (MindsDB, 2023), among others, GPT4AII is the 3rd fastest growing GitHub repository of all time (Leo, 2023), and is the 185th most popular repository on the platform, by star count.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            317.0,\n",
            "            1081.0\n",
            "          ],\n",
            "          [\n",
            "            317.0,\n",
            "            1616.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1616.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1081.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"166007c1bd4d25db96d5153c1d2c7ee9\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"05be8dc08339fdfc4f315798acfed76d\",\n",
            "    \"text\": \"4 The Future of GPT4AIl\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            316.0,\n",
            "            1652.0\n",
            "          ],\n",
            "          [\n",
            "            316.0,\n",
            "            1674.0\n",
            "          ],\n",
            "          [\n",
            "            642.0,\n",
            "            1674.0\n",
            "          ],\n",
            "          [\n",
            "            642.0,\n",
            "            1652.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"e8512e6f05426a74cf623ebba360a1db\",\n",
            "    \"text\": \"In the future, we will continue to grow GPT4AN, sup- porting it as the de facto solution for LLM accessibil- ity. Concretely, this means continuing to compress and distribute important open-source language models de- veloped by the community, as well as compressing and distributing increasingly multimodal AI models, Fur- thermore, we will expand the set of hardware devices that GPT4AII models run on, so that GPT4AIl models\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            316.0,\n",
            "            1706.0\n",
            "          ],\n",
            "          [\n",
            "            316.0,\n",
            "            1929.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1929.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1706.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"05be8dc08339fdfc4f315798acfed76d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"324215bfc9e5fbb868729bec0ce86025\",\n",
            "    \"text\": \"\\u201cjust work\\\" on any machine, whether it comes equipped with Apple Metal silicon, NVIDIA, AMD, or other edge- accelerated hardware, Overall, we envision a world where anyone, anywhere, with any machine, can access and contribute to the cutting edge of AI.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            870.0,\n",
            "            909.0\n",
            "          ],\n",
            "          [\n",
            "            870.0,\n",
            "            1045.0\n",
            "          ],\n",
            "          [\n",
            "            1386.0,\n",
            "            1045.0\n",
            "          ],\n",
            "          [\n",
            "            1386.0,\n",
            "            909.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"05be8dc08339fdfc4f315798acfed76d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"ac9490538379563bc0cb472ec0ea8eb3\",\n",
            "    \"text\": \"Limitations\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            873.0,\n",
            "            1081.0\n",
            "          ],\n",
            "          [\n",
            "            873.0,\n",
            "            1103.0\n",
            "          ],\n",
            "          [\n",
            "            1010.0,\n",
            "            1103.0\n",
            "          ],\n",
            "          [\n",
            "            1010.0,\n",
            "            1081.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"a3b34f4453e2127d454483237ce16028\",\n",
            "    \"text\": \"By enabling uk large language models, the GPT4AII project also inherits many of the ethical con- cems associated with generative models. Principal among these is the concern that unfiltered language models like GPT4All enable malicious users to generate content that could be harmful and dangerous (e.g., in- structions on building bioweapons), While we recognize this risk, we also acknowledge the risk of concentrating this technology in the hands of a limited number of in- creasingly secretive research groups, We believe that the risk of focusing on the benefits of language model technology significantly outweighs the risk of misuse, and hence we prefer to make the technology as widely available as possible.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            873.0,\n",
            "            1099.0\n",
            "          ],\n",
            "          [\n",
            "            873.0,\n",
            "            1526.0\n",
            "          ],\n",
            "          [\n",
            "            1388.0,\n",
            "            1526.0\n",
            "          ],\n",
            "          [\n",
            "            1388.0,\n",
            "            1099.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"ac9490538379563bc0cb472ec0ea8eb3\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"a63d1437913b6339c815061a953ab135\",\n",
            "    \"text\": \"Finally, we realize the challenge in assigning credit for large-scale open source initiatives. We make a first attempt at fair credit assignment by explicitly includ- ing the GPT4AII open source developers as authors on this work, but recognize that this is insufficient fully characterize everyone involved in the GPT4AII effort. Furthermore, we acknowledge the difficulty in citing open source works that do not necessarily have standard- ized citations, and do our best in this paper to provide URLs to projects whenever possible. We encourage further research in the area of open source credit as signment, and hope to be able to support some of this research ourselves in the future\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            875.0,\n",
            "            1534.0\n",
            "          ],\n",
            "          [\n",
            "            875.0,\n",
            "            1899.0\n",
            "          ],\n",
            "          [\n",
            "            1391.0,\n",
            "            1899.0\n",
            "          ],\n",
            "          [\n",
            "            1391.0,\n",
            "            1534.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"ac9490538379563bc0cb472ec0ea8eb3\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"ec65b806683166bd41616ed4affd398b\",\n",
            "    \"text\": \"References Nomic AT. 2023. Atlas. https://atlas.nomic.ai/.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            325.0,\n",
            "            260.0\n",
            "          ],\n",
            "          [\n",
            "            325.0,\n",
            "            329.0\n",
            "          ],\n",
            "          [\n",
            "            830.0,\n",
            "            329.0\n",
            "          ],\n",
            "          [\n",
            "            830.0,\n",
            "            260.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"ff447f96b6bf72627398a07e3eaad24a\",\n",
            "    \"text\": \"Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Al- shamsi, Alessandro Cappelli, Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Hes- low, Julien Launay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. 2023. Falcon-40B: an open large language model with state-of-the-art performance.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            325.0,\n",
            "            356.0\n",
            "          ],\n",
            "          [\n",
            "            325.0,\n",
            "            536.0\n",
            "          ],\n",
            "          [\n",
            "            841.0,\n",
            "            536.0\n",
            "          ],\n",
            "          [\n",
            "            841.0,\n",
            "            356.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"ec65b806683166bd41616ed4affd398b\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"031b146d5d2e60a822477f2e7e168ec3\",\n",
            "    \"text\": \"Yuvanesh Anand, Zach Nussbaum, Brandon Duder- stadt, Benjamin Schmidt, and Andriy Mulyar. 2023. Gpt4all: Training an assistant-style chatbot with large scale data distillation from gpt-3.5-turbo. https: //github.com/nomic-ai/gpt4all.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            326.0,\n",
            "            562.0\n",
            "          ],\n",
            "          [\n",
            "            326.0,\n",
            "            691.0\n",
            "          ],\n",
            "          [\n",
            "            841.0,\n",
            "            691.0\n",
            "          ],\n",
            "          [\n",
            "            841.0,\n",
            "            562.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"ec65b806683166bd41616ed4affd398b\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"96b99fb92c077a36f47b747d61206825\",\n",
            "    \"text\": \"BBC News. 2023. Chatgpt banned in italy over privacy concerns. BBC News.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            326.0,\n",
            "            714.0\n",
            "          ],\n",
            "          [\n",
            "            326.0,\n",
            "            766.0\n",
            "          ],\n",
            "          [\n",
            "            837.0,\n",
            "            766.0\n",
            "          ],\n",
            "          [\n",
            "            837.0,\n",
            "            714.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"ec65b806683166bd41616ed4affd398b\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"9d2b6c54458ad97d68464d08a873abd9\",\n",
            "    \"text\": \"Stella Biderman, Hailey Schoelkopf, Quentin An- thony, Herbie Bradley, Kyle O\\u2019Brien, Eric Hal- lahan, Mohammad Aflah Khan, Shivanshu Puro- hit, USVSN Sai Prashanth, Edward Raff, Aviya Skowron, Lintang Sutawika, and Oskar van der Wal. 2023. Pythia: A suite for analyzing large language models across training and scaling.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            325.0,\n",
            "            788.0\n",
            "          ],\n",
            "          [\n",
            "            325.0,\n",
            "            964.0\n",
            "          ],\n",
            "          [\n",
            "            841.0,\n",
            "            964.0\n",
            "          ],\n",
            "          [\n",
            "            841.0,\n",
            "            788.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"ec65b806683166bd41616ed4affd398b\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"886ea7ec0218a995d8711dd9a96ae3d7\",\n",
            "    \"text\": \"Harrison Chase. 2022. langchain. https://github. com/langchain-ai/langchain.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            325.0,\n",
            "            990.0\n",
            "          ],\n",
            "          [\n",
            "            325.0,\n",
            "            1038.0\n",
            "          ],\n",
            "          [\n",
            "            840.0,\n",
            "            1038.0\n",
            "          ],\n",
            "          [\n",
            "            840.0,\n",
            "            990.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"2829deeb1aef68b7dd984491582b736d\",\n",
            "    \"text\": \"Mike Conover, Matt Hayes, Ankit Mathur, Xiangrui Meng, Jianwei Xie, Jun Wan, Ali Ghodsi, Patrick Wendell, and Matei Zaharia. 2023a. Hello dolly: Democratizing the magic of chatgpt with open mod- els.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            324.0,\n",
            "            1063.0\n",
            "          ],\n",
            "          [\n",
            "            324.0,\n",
            "            1185.0\n",
            "          ],\n",
            "          [\n",
            "            839.0,\n",
            "            1185.0\n",
            "          ],\n",
            "          [\n",
            "            839.0,\n",
            "            1063.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"886ea7ec0218a995d8711dd9a96ae3d7\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"e815f282e0d35e8bb03aa8bba15b9157\",\n",
            "    \"text\": \"Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin. 2023b. Free dolly: Introducing the world\\u2019s first truly open instruction- tuned Im.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            323.0,\n",
            "            1214.0\n",
            "          ],\n",
            "          [\n",
            "            323.0,\n",
            "            1338.0\n",
            "          ],\n",
            "          [\n",
            "            839.0,\n",
            "            1338.0\n",
            "          ],\n",
            "          [\n",
            "            839.0,\n",
            "            1214.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"886ea7ec0218a995d8711dd9a96ae3d7\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"ecbe83b2f160b4993aa56eaf343dff0a\",\n",
            "    \"text\": \"Xinyang Geng, Arnav Gudibande, Hao Liu, Eric Wal- Jace, Pieter Abbeel, Sergey Levine, and Dawn Song. 2023. Koala: A dialogue model for academic re- search. Blog post.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            322.0,\n",
            "            1366.0\n",
            "          ],\n",
            "          [\n",
            "            322.0,\n",
            "            1469.0\n",
            "          ],\n",
            "          [\n",
            "            839.0,\n",
            "            1469.0\n",
            "          ],\n",
            "          [\n",
            "            839.0,\n",
            "            1366.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"886ea7ec0218a995d8711dd9a96ae3d7\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"17a83aeba87bb3814fcba759836f2ca6\",\n",
            "    \"text\": \"Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen, 2021, Lora: Low-rank adaptation of large language models,\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            320.0,\n",
            "            1493.0\n",
            "          ],\n",
            "          [\n",
            "            320.0,\n",
            "            1598.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1598.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1493.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"886ea7ec0218a995d8711dd9a96ae3d7\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "    \"text\": \"imartinez. 2023. privategpt, https://github.com/ imartinez/privateGPT.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            319.0,\n",
            "            1621.0\n",
            "          ],\n",
            "          [\n",
            "            319.0,\n",
            "            1672.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1672.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1621.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"a7349787d70d9c2093d459fe3ca5c693\",\n",
            "    \"text\": \"Oscar Leo, 2023. GitHub: The Fastest Growing Repos- itories of AJ] Time.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            318.0,\n",
            "            1696.0\n",
            "          ],\n",
            "          [\n",
            "            318.0,\n",
            "            1743.0\n",
            "          ],\n",
            "          [\n",
            "            837.0,\n",
            "            1743.0\n",
            "          ],\n",
            "          [\n",
            "            837.0,\n",
            "            1696.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"65931a58c527e7b109596a20f87f1355\",\n",
            "    \"text\": \"Robert McMillan, 2023. A meta platforms leak put powerful ai in the hands of everyone. The Wall Street Journal\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            318.0,\n",
            "            1772.0\n",
            "          ],\n",
            "          [\n",
            "            318.0,\n",
            "            1845.0\n",
            "          ],\n",
            "          [\n",
            "            833.0,\n",
            "            1845.0\n",
            "          ],\n",
            "          [\n",
            "            833.0,\n",
            "            1772.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"b27fe1d4f2a4bc3baac99787a4a12392\",\n",
            "    \"text\": \"MindsDB, 2023, Mindsdb. https://github.com/ mindsdb/mindsdb, GitHub repository\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            318.0,\n",
            "            1876.0\n",
            "          ],\n",
            "          [\n",
            "            318.0,\n",
            "            1925.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            1925.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            1876.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"63979de6e1701724f4278ac34ba9bfd0\",\n",
            "    \"text\": \"MosaicML-Team. 2023. Introducing mpt-7b: A new standard for open-source, commercially usable lms. Accessed: 2023-08-07.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            879.0,\n",
            "            265.0\n",
            "          ],\n",
            "          [\n",
            "            879.0,\n",
            "            335.0\n",
            "          ],\n",
            "          [\n",
            "            1390.0,\n",
            "            335.0\n",
            "          ],\n",
            "          [\n",
            "            1390.0,\n",
            "            265.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"d3246b135b36ddd7688886a776431694\",\n",
            "    \"text\": \"Nous-Research. 2023a. gpt4-x-vicuna-13b. https: //huggingface.co/NousResearch/ gpt4-x-vicuna-13b. Model on Hugging Face.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            879.0,\n",
            "            366.0\n",
            "          ],\n",
            "          [\n",
            "            879.0,\n",
            "            441.0\n",
            "          ],\n",
            "          [\n",
            "            1390.0,\n",
            "            441.0\n",
            "          ],\n",
            "          [\n",
            "            1390.0,\n",
            "            366.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"3acfe7080f896bca5aab8e68438eac41\",\n",
            "    \"text\": \"Nous-Research. 2023b. Nous-hermes-13b. https: //huggingface.co/NousResearch/ Nous-Hermes-13b. Model on Hugging Face.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            879.0,\n",
            "            468.0\n",
            "          ],\n",
            "          [\n",
            "            879.0,\n",
            "            542.0\n",
            "          ],\n",
            "          [\n",
            "            1389.0,\n",
            "            542.0\n",
            "          ],\n",
            "          [\n",
            "            1389.0,\n",
            "            468.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"4290a971cb2ea24b7ca96ebd85f6a7ea\",\n",
            "    \"text\": \"Nous-Research. 2023c. Nous-hermes-Ilama-2-7b. https: //huggingface.co/NousResearch/ Nous-Hermes-llama-2-7b. Model on Hugging Face.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            879.0,\n",
            "            569.0\n",
            "          ],\n",
            "          [\n",
            "            879.0,\n",
            "            665.0\n",
            "          ],\n",
            "          [\n",
            "            1389.0,\n",
            "            665.0\n",
            "          ],\n",
            "          [\n",
            "            1389.0,\n",
            "            569.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"5fa14f83af115bdda91a6ea497ee24f5\",\n",
            "    \"text\": \"Nous-Research. 2023d. Redmond-puffin-13b. https: //huggingface.co/NousResearch/ Redmond-Puf fin-13B. Model on Hugging Face.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            878.0,\n",
            "            696.0\n",
            "          ],\n",
            "          [\n",
            "            878.0,\n",
            "            770.0\n",
            "          ],\n",
            "          [\n",
            "            1388.0,\n",
            "            770.0\n",
            "          ],\n",
            "          [\n",
            "            1388.0,\n",
            "            696.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"ad8404b5ba525ba55c88db3507afea61\",\n",
            "    \"text\": \"OpenAI. 2023. Gpt-4 technical report.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            878.0,\n",
            "            797.0\n",
            "          ],\n",
            "          [\n",
            "            878.0,\n",
            "            819.0\n",
            "          ],\n",
            "          [\n",
            "            1232.0,\n",
            "            819.0\n",
            "          ],\n",
            "          [\n",
            "            1232.0,\n",
            "            797.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"5155c4ea4ec7b469b74b73f0770aeb0c\",\n",
            "    \"text\": \"Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szezechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Teshala Neeraj, Jos Rozen, Ab- heesht Sharma, Ar}irea Santilli, Thibault Fevry, Ja- son Alan Fries, RxAn Teehan, Stella Biderman, Leo Gao, Tali Bers, Thomas Wolf, and Alexander M. Rush. 2021. Multitask prompted training enables zero-shot task generalization,\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            878.0,\n",
            "            845.0\n",
            "          ],\n",
            "          [\n",
            "            878.0,\n",
            "            1228.0\n",
            "          ],\n",
            "          [\n",
            "            1387.0,\n",
            "            1228.0\n",
            "          ],\n",
            "          [\n",
            "            1387.0,\n",
            "            845.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"ad8404b5ba525ba55c88db3507afea61\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"035581f765a747731186ed3a649ed409\",\n",
            "    \"text\": \"Stability-AL. 2023. Stablelm. https: //github.com/ Stability-AI/StableLM. GitHub repository.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            877.0,\n",
            "            1251.0\n",
            "          ],\n",
            "          [\n",
            "            877.0,\n",
            "            1303.0\n",
            "          ],\n",
            "          [\n",
            "            1386.0,\n",
            "            1303.0\n",
            "          ],\n",
            "          [\n",
            "            1386.0,\n",
            "            1251.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"3a8e10295cb9afdbfe72280310d957ad\",\n",
            "    \"text\": \"StanGirard. 2023. quivr. https://github.com/ StanGirard/quivr, GitHub repository.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            876.0,\n",
            "            1331.0\n",
            "          ],\n",
            "          [\n",
            "            876.0,\n",
            "            1379.0\n",
            "          ],\n",
            "          [\n",
            "            1386.0,\n",
            "            1379.0\n",
            "          ],\n",
            "          [\n",
            "            1386.0,\n",
            "            1331.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"5d1bc696851ef79af9375f55b5b41cf3\",\n",
            "    \"text\": \"Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B, Hashimoto. 2023. Stanford alpaca: An instruction-following llama model, https: // github. com/tatsu-lab/stanford_alpaca.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            877.0,\n",
            "            1405.0\n",
            "          ],\n",
            "          [\n",
            "            877.0,\n",
            "            1537.0\n",
            "          ],\n",
            "          [\n",
            "            1388.0,\n",
            "            1537.0\n",
            "          ],\n",
            "          [\n",
            "            1388.0,\n",
            "            1405.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"3a8e10295cb9afdbfe72280310d957ad\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"171ccc2dc868ac8356c784d33399c9e7\",\n",
            "    \"text\": \"Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\\u00e9e Lacroix, Baptiste Rozi\\u00e9re, Naman Goyal, Bric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample, 2023, Llama: Open and efficient foundation language models,\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            876.0,\n",
            "            1561.0\n",
            "          ],\n",
            "          [\n",
            "            876.0,\n",
            "            1736.0\n",
            "          ],\n",
            "          [\n",
            "            1390.0,\n",
            "            1736.0\n",
            "          ],\n",
            "          [\n",
            "            1390.0,\n",
            "            1561.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"3a8e10295cb9afdbfe72280310d957ad\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"96193587a3ec137f8f1402f5ba65703e\",\n",
            "    \"text\": \"The Verge. 2023, Meta\\u2019s powerful ai language model has leaked online \\u2014 what happens now? The Verge\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            874.0,\n",
            "            1769.0\n",
            "          ],\n",
            "          [\n",
            "            874.0,\n",
            "            1818.0\n",
            "          ],\n",
            "          [\n",
            "            1388.0,\n",
            "            1818.0\n",
            "          ],\n",
            "          [\n",
            "            1388.0,\n",
            "            1769.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"3a8e10295cb9afdbfe72280310d957ad\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"fc824dd6182933738198e6c1d09a9799\",\n",
            "    \"text\": \"James Vincent. 2023. As an ai generated language model; The phrase that shows how ai is polluting the web. The Verge.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            875.0,\n",
            "            1847.0\n",
            "          ],\n",
            "          [\n",
            "            875.0,\n",
            "            1921.0\n",
            "          ],\n",
            "          [\n",
            "            1387.0,\n",
            "            1921.0\n",
            "          ],\n",
            "          [\n",
            "            1387.0,\n",
            "            1847.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"3a8e10295cb9afdbfe72280310d957ad\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"40cd518728254214751a03711f485660\",\n",
            "    \"text\": \"| fren\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            147.0,\n",
            "            2063.0\n",
            "          ],\n",
            "          [\n",
            "            147.0,\n",
            "            2112.0\n",
            "          ],\n",
            "          [\n",
            "            1556.0,\n",
            "            2112.0\n",
            "          ],\n",
            "          [\n",
            "            1556.0,\n",
            "            2063.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"04c3ff73bf077e14ea3e3fe8d73d17ef\",\n",
            "    \"text\": \"Ben Wang and Aran Komatsuzaki. 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https: //github.com/kingoflolz/ mesh-transformer-jax.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            319.0,\n",
            "            273.0\n",
            "          ],\n",
            "          [\n",
            "            319.0,\n",
            "            376.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            376.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            273.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 6,\n",
            "      \"parent_id\": \"40cd518728254214751a03711f485660\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"9bf04982948259cfa12c2444f16697e3\",\n",
            "    \"text\": \"Enc J. Wang. 2023. alpaca-lora. https://github. com/tloen/alpaca-lora. GitHub repository.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            320.0,\n",
            "            397.0\n",
            "          ],\n",
            "          [\n",
            "            320.0,\n",
            "            450.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            450.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            397.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 6,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"55b51cf7becc1a40a4f665cb04af4e0d\",\n",
            "    \"text\": \"Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Han- nanch Hajishirzi. 2023. Self-instruct: Aligning lan- guage models with self-generated instructions.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            321.0,\n",
            "            468.0\n",
            "          ],\n",
            "          [\n",
            "            321.0,\n",
            "            571.0\n",
            "          ],\n",
            "          [\n",
            "            837.0,\n",
            "            571.0\n",
            "          ],\n",
            "          [\n",
            "            837.0,\n",
            "            468.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 6,\n",
            "      \"parent_id\": \"9bf04982948259cfa12c2444f16697e3\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"b7ef3aaaa4297d57b181319cc7d5bd15\",\n",
            "    \"text\": \"Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023. Wizardlm: Empowering large language models to follow complex instructions.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            322.0,\n",
            "            591.0\n",
            "          ],\n",
            "          [\n",
            "            322.0,\n",
            "            693.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            693.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            591.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 6,\n",
            "      \"parent_id\": \"9bf04982948259cfa12c2444f16697e3\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"571342fd70ea71de51f9f7281fad43c0\",\n",
            "    \"text\": \"Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging Ilm-as-a-judge with mt-bench and chatbot arena.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            323.0,\n",
            "            714.0\n",
            "          ],\n",
            "          [\n",
            "            323.0,\n",
            "            841.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            841.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            714.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 6,\n",
            "      \"parent_id\": \"9bf04982948259cfa12c2444f16697e3\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "elements"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ52vfNY6poy",
        "outputId": "faee3f8a-584f-4e93-8cc2-f0b8cd6cfc9b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<unstructured.documents.elements.Text at 0x7a0e7463b160>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7463be20>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72716890>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72715ab0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72717100>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72715270>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e727141f0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e727150c0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e72715bd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e72716ad0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e72716140>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e72714d90>,\n",
              " <unstructured.documents.elements.ListItem at 0x7a0e7275d240>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275dff0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275fbb0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275d2a0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275fa60>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275ea70>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275d540>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275ead0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275e020>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275ce80>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275d300>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275eb00>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275ce50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275dfc0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275eaa0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275cf40>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275cee0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275e8c0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275d720>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275d690>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275d270>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275e4d0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275d6f0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275f160>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74638c40>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275d150>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275d210>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275e140>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e74638040>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275c5b0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275dc90>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275fa90>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275f370>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275c250>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275f430>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275e620>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275e650>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275d750>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275f340>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275d330>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275d990>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275d3f0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275e5f0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275eef0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275efb0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275fc10>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275c370>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275f2b0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275feb0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275c130>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275d1b0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275ff10>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275c100>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275fee0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275c820>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275c0d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275f550>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275d660>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275c790>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275e5c0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275d7b0>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275d5d0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275f4f0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275f610>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275cc70>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275caf0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275d7e0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275cb80>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275ca30>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275cb50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275c8b0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275e0b0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275f6a0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275fdc0>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275f4c0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275e380>,\n",
              " <unstructured.documents.elements.Text at 0x7a0e7275ee00>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275edd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275e770>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275eda0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275dc30>,\n",
              " <unstructured.documents.elements.Title at 0x7a0e7275f0d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275c430>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275e7d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7a0e7275dcf0>]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(elements)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4_ab1L-6prC",
        "outputId": "b3f33855-e5c5-439a-a3b4-bf8ba279e5b9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "element_dict = [el.to_dict() for el in elements]\n",
        "output = json.dumps(element_dict, indent=2)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEoNtR9z6pt4",
        "outputId": "b75e095a-3754-4043-d610-d18c00897a75"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
            "    \"text\": \"2311.04931v1 [cs.CL] 6 Nov 2023\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            187.0,\n",
            "            718.0\n",
            "          ],\n",
            "          [\n",
            "            187.0,\n",
            "            1404.0\n",
            "          ],\n",
            "          [\n",
            "            230.0,\n",
            "            1404.0\n",
            "          ],\n",
            "          [\n",
            "            230.0,\n",
            "            718.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"e4fe3bbb0809b51d59fa5c6d32240053\",\n",
            "    \"text\": \"arXiv\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            187.0,\n",
            "            1422.0\n",
            "          ],\n",
            "          [\n",
            "            187.0,\n",
            "            1526.0\n",
            "          ],\n",
            "          [\n",
            "            220.0,\n",
            "            1526.0\n",
            "          ],\n",
            "          [\n",
            "            220.0,\n",
            "            1422.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"aa5e7c4eb5afd8a6a701200d14d0c5c1\",\n",
            "    \"text\": \"GPT4AIl: An Ecosystem of Open Source Compressed Language Models\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            330.0,\n",
            "            275.0\n",
            "          ],\n",
            "          [\n",
            "            330.0,\n",
            "            313.0\n",
            "          ],\n",
            "          [\n",
            "            1368.0,\n",
            "            313.0\n",
            "          ],\n",
            "          [\n",
            "            1368.0,\n",
            "            275.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"3b6229680e5b76a64d828388fc9558af\",\n",
            "    \"text\": \"Yuvanesh Anand Nomic AI yuvanesh@nomic.ai\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            310.0,\n",
            "            351.0\n",
            "          ],\n",
            "          [\n",
            "            310.0,\n",
            "            444.0\n",
            "          ],\n",
            "          [\n",
            "            548.0,\n",
            "            444.0\n",
            "          ],\n",
            "          [\n",
            "            548.0,\n",
            "            351.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"2b31179eb0e5f5f7d85c9fb0cb5b961e\",\n",
            "    \"text\": \"Zach Nussbaum Nomic AI zach@nomic. ai\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            613.0,\n",
            "            355.0\n",
            "          ],\n",
            "          [\n",
            "            613.0,\n",
            "            445.0\n",
            "          ],\n",
            "          [\n",
            "            806.0,\n",
            "            445.0\n",
            "          ],\n",
            "          [\n",
            "            806.0,\n",
            "            355.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"e99ec24d75fca645414a8eeba5922394\",\n",
            "    \"text\": \"Aaron Miller Nomic AI aaron@nomic.ai\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            1174.0,\n",
            "            357.0\n",
            "          ],\n",
            "          [\n",
            "            1174.0,\n",
            "            446.0\n",
            "          ],\n",
            "          [\n",
            "            1367.0,\n",
            "            446.0\n",
            "          ],\n",
            "          [\n",
            "            1367.0,\n",
            "            357.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"aa73c787d2d21bd8961c36711722db1d\",\n",
            "    \"text\": \"Adam Treat Nomic AI adam@nomic. ai\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            900.0,\n",
            "            357.0\n",
            "          ],\n",
            "          [\n",
            "            900.0,\n",
            "            446.0\n",
            "          ],\n",
            "          [\n",
            "            1079.0,\n",
            "            446.0\n",
            "          ],\n",
            "          [\n",
            "            1079.0,\n",
            "            357.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"f49db26031127120e27a8fb9be080262\",\n",
            "    \"text\": \"Richard Guo Ben Schmidt GPT4AIl Community Nomic AI Nomic AI Planet Earth richard@nomic. ai ben@nomic. ai Brandon Duderstadt* Andriy Mulyar* Nomic AI Nomic AI brandon@nomic. ai andriy@nomic.ai Abstract variety of queries, responding only with the now infa-\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            387.0,\n",
            "            503.0\n",
            "          ],\n",
            "          [\n",
            "            387.0,\n",
            "            847.0\n",
            "          ],\n",
            "          [\n",
            "            1384.0,\n",
            "            847.0\n",
            "          ],\n",
            "          [\n",
            "            1384.0,\n",
            "            503.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"aa73c787d2d21bd8961c36711722db1d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"7ca0f2ae4307b5e65fbbf275bd57f0d8\",\n",
            "    \"text\": \"Large language models (LLMs) have recently achieved human-level performance on a range of professional and academic benchmarks. The accessibility of these models has lagged behind their performance. State-of-the-art LLMs re- quire costly infrastructure; are only accessible via rate-limited, geo-locked, and censored web interfaces; and lack publicly available code and technical reports.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            356.0,\n",
            "            879.0\n",
            "          ],\n",
            "          [\n",
            "            356.0,\n",
            "            1127.0\n",
            "          ],\n",
            "          [\n",
            "            793.0,\n",
            "            1127.0\n",
            "          ],\n",
            "          [\n",
            "            793.0,\n",
            "            879.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"aa73c787d2d21bd8961c36711722db1d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"1078dd84576df5d9cd18dc21562c4667\",\n",
            "    \"text\": \"In this paper, we tell the story of GPT4All, a popular open source repository that aims to democratize access to LLMs. We outline the technical details of the original GPT4AII mode] family, as well as the evolution of the GPT4Al] project from a single model into a fully fledged open source ecosystem. It is our hope that this paper acts as both a technical overview of the original GPT4Al models as well as a case study on the subsequent growth of the GPT4AI] open source ecosystem.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            354.0,\n",
            "            1147.0\n",
            "          ],\n",
            "          [\n",
            "            354.0,\n",
            "            1454.0\n",
            "          ],\n",
            "          [\n",
            "            792.0,\n",
            "            1454.0\n",
            "          ],\n",
            "          [\n",
            "            792.0,\n",
            "            1147.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"aa73c787d2d21bd8961c36711722db1d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"8eb8570a7799605f1511b7abb329cd3d\",\n",
            "    \"text\": \"1 Introduction\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            314.0,\n",
            "            1493.0\n",
            "          ],\n",
            "          [\n",
            "            314.0,\n",
            "            1515.0\n",
            "          ],\n",
            "          [\n",
            "            509.0,\n",
            "            1515.0\n",
            "          ],\n",
            "          [\n",
            "            509.0,\n",
            "            1493.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"cc800a372051047b2ffd4c3251d06344\",\n",
            "    \"text\": \"On March 14 2023, OpenAI released GPT-4, a large language model capable of achieving human level per- formance on a yariety of professional and academic benchmarks. Despite the popularity of the release, the GPT-4 technical report (OpenAl, 2023) contained virtually no details regarding the architecture, hard- ware, training compute, dataset construction, or training method used to create the model, Moreover, users could only access the model through the internet interface at chat.openai.com, which was severely rate limited and unavailable in several locales (e.g. Italy) (BBC News, 2023). Additionally, GPT-4 refused to answer a wide\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            310.0,\n",
            "            1542.0\n",
            "          ],\n",
            "          [\n",
            "            310.0,\n",
            "            1884.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            1884.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            1542.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"8eb8570a7799605f1511b7abb329cd3d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"2dbce9fa5c8141f6497bfb64323e1a9a\",\n",
            "    \"text\": \"Shared Senior Authorship\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            347.0,\n",
            "            1915.0\n",
            "          ],\n",
            "          [\n",
            "            347.0,\n",
            "            1933.0\n",
            "          ],\n",
            "          [\n",
            "            562.0,\n",
            "            1933.0\n",
            "          ],\n",
            "          [\n",
            "            562.0,\n",
            "            1915.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"8eb8570a7799605f1511b7abb329cd3d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"83802e9c42af8178ba8f1fdca43809eb\",\n",
            "    \"text\": \"mous \\\"As an AI Language Model, I cannot...\\\" prefix (Vincent, 2023). These transparency and accessibility concerns spurred several developers to begin creating open source large language model (LLM) alternatives. Several grassroots efforts focused on fine tuning Meta\\u2019s open code LLaMA model (Touvron et al., 2023; McMil- lan, 2023), whose weights were leaked on BitTorrent less than_a week prior to the release of GPT-4 (Verge, 2023). GIJT4All started as one of these variants.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            870.0,\n",
            "            850.0\n",
            "          ],\n",
            "          [\n",
            "            870.0,\n",
            "            1095.0\n",
            "          ],\n",
            "          [\n",
            "            1384.0,\n",
            "            1095.0\n",
            "          ],\n",
            "          [\n",
            "            1384.0,\n",
            "            850.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"8eb8570a7799605f1511b7abb329cd3d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"07c98444db3b8431997668695e65e450\",\n",
            "    \"text\": \"In thiASaper, we tell the story of GPT4AlI. We com- ment on the technical details of the original GPT4Al model (Anand et al., 2023), as well as the evolution of GPT4AIl from a single model to an ecosystem of several models. We remark on the impact that the project has had on the open source community, and discuss future directions. It is our hope that this paper acts as both a technical overview of the original GPT4Al] models as well as a case study on the subsequent growth of the GPT4All open source ecosystem.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            871.0,\n",
            "            1104.0\n",
            "          ],\n",
            "          [\n",
            "            871.0,\n",
            "            1380.0\n",
            "          ],\n",
            "          [\n",
            "            1385.0,\n",
            "            1380.0\n",
            "          ],\n",
            "          [\n",
            "            1385.0,\n",
            "            1104.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"8eb8570a7799605f1511b7abb329cd3d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"733695a3173f6e088d89321305d070f1\",\n",
            "    \"text\": \"2 The Original GPT4AII Model\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            871.0,\n",
            "            1413.0\n",
            "          ],\n",
            "          [\n",
            "            871.0,\n",
            "            1440.0\n",
            "          ],\n",
            "          [\n",
            "            1266.0,\n",
            "            1440.0\n",
            "          ],\n",
            "          [\n",
            "            1266.0,\n",
            "            1413.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"27a88b704141fe0da95e8e02e515b79d\",\n",
            "    \"text\": \"2.1 Data Collection and Curation\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            871.0,\n",
            "            1465.0\n",
            "          ],\n",
            "          [\n",
            "            871.0,\n",
            "            1482.0\n",
            "          ],\n",
            "          [\n",
            "            1219.0,\n",
            "            1482.0\n",
            "          ],\n",
            "          [\n",
            "            1219.0,\n",
            "            1465.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"6ec13ad59960463ba50e9b6bc7fcec29\",\n",
            "    \"text\": \"To train the original GPT4All model, we collected roughly one million prompt-response pairs using the GPT-3,5-Turbo OpenAI API between March 20, 2023 and March 26th, 2023, In particular, we gathered GPT- 3.5-Turbo responses to prompts of three publicly avail- able datasets: the unified chip2 subset of LAION OIG, a random sub-sample of Stackoverflow Questions, and a sub-sample of Bigscience/P3 (Sanh et al., 2021). Fol- lowing the approach in Stanford Alpaca (Taori et al., 2023), an open source LLaMA variant that came just be- fore GPT4AIl, we focused substantial effort on dataset curation,\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            869.0,\n",
            "            1503.0\n",
            "          ],\n",
            "          [\n",
            "            869.0,\n",
            "            1838.0\n",
            "          ],\n",
            "          [\n",
            "            1389.0,\n",
            "            1838.0\n",
            "          ],\n",
            "          [\n",
            "            1389.0,\n",
            "            1503.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"27a88b704141fe0da95e8e02e515b79d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"c9462cb1f13d8c4b319e4228c23948b8\",\n",
            "    \"text\": \"The collected dataset was loaded into Atlas (Al, 2023)\\u2014a visual interface for exploring and tagging mas\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            872.0,\n",
            "            1851.0\n",
            "          ],\n",
            "          [\n",
            "            872.0,\n",
            "            1902.0\n",
            "          ],\n",
            "          [\n",
            "            1389.0,\n",
            "            1902.0\n",
            "          ],\n",
            "          [\n",
            "            1389.0,\n",
            "            1851.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"27a88b704141fe0da95e8e02e515b79d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"4864442e74fdf0e16c3fe0e80d73e48b\",\n",
            "    \"text\": \"sive unstructured datasets \\u2014for data curation, Using At\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            860.0,\n",
            "            1905.0\n",
            "          ],\n",
            "          [\n",
            "            860.0,\n",
            "            1935.0\n",
            "          ],\n",
            "          [\n",
            "            1382.0,\n",
            "            1935.0\n",
            "          ],\n",
            "          [\n",
            "            1382.0,\n",
            "            1905.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"27a88b704141fe0da95e8e02e515b79d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"9f9c38708322ca2ad595d06e8dce7f36\",\n",
            "    \"text\": \"las, we identified and removed subsets of the data where GPT-3.5-Turbo refused to respond, had malformed out- put, or produced a very short response. This resulted in the removal of the entire Bigscience/P3 subset of our data, as many P3 prompts induced responses that were simply one word. After curation, we were left with a set of 437,605 prompt-response pairs, which we visualize in Figure 1a.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            322.0,\n",
            "            259.0\n",
            "          ],\n",
            "          [\n",
            "            322.0,\n",
            "            484.0\n",
            "          ],\n",
            "          [\n",
            "            838.0,\n",
            "            484.0\n",
            "          ],\n",
            "          [\n",
            "            838.0,\n",
            "            259.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"27a88b704141fe0da95e8e02e515b79d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"9d7097ade60591eb70584599d4462684\",\n",
            "    \"text\": \"2.2. Model Training\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            324.0,\n",
            "            510.0\n",
            "          ],\n",
            "          [\n",
            "            324.0,\n",
            "            535.0\n",
            "          ],\n",
            "          [\n",
            "            532.0,\n",
            "            535.0\n",
            "          ],\n",
            "          [\n",
            "            532.0,\n",
            "            510.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"bd02232e727d1cbf75106ef8544d1230\",\n",
            "    \"text\": \"The original GPT4AI1 model was a fine tuned variant of LLaMA 7B. In order to train it more efficiently, we froze the base weights of LLaMA, and only trained a small set of LoRA (Hu et al., 2021) weights during the fine tuning process. Detailed model hyper-parameters and training code can be found in our associated code\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            323.0,\n",
            "            549.0\n",
            "          ],\n",
            "          [\n",
            "            323.0,\n",
            "            713.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            713.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            549.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"9d7097ade60591eb70584599d4462684\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"b7c98178067be445b1d32a7f7b7de4c7\",\n",
            "    \"text\": \"repository\\u2019. 2.3. Model Access\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            324.0,\n",
            "            717.0\n",
            "          ],\n",
            "          [\n",
            "            324.0,\n",
            "            787.0\n",
            "          ],\n",
            "          [\n",
            "            512.0,\n",
            "            787.0\n",
            "          ],\n",
            "          [\n",
            "            512.0,\n",
            "            717.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"a0aa7d4d319c6bc0314ea8ef359c88cf\",\n",
            "    \"text\": \"We publicly released all data, training code, and model weights for the community to build upon. Further, we provided a 4-bit quantized version of the model, which enabled users to run it on their own commodity hard- ware without transferring data to a 3rd party service.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            323.0,\n",
            "            806.0\n",
            "          ],\n",
            "          [\n",
            "            323.0,\n",
            "            945.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            945.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            806.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"b7c98178067be445b1d32a7f7b7de4c7\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"9bcea687b18e61c18e3d1e774e3afee1\",\n",
            "    \"text\": \"Our research and development costs were dominated by ~$800 in GPU spend (rented from Lambda Labs and Paperspace) and ~$500 in OpenAl API spend. Our final GPT4AII model could be trained in about eight hours ona Lambda Labs DGX A100 8x 80GB for a total cost of ~$100.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            325.0,\n",
            "            948.0\n",
            "          ],\n",
            "          [\n",
            "            325.0,\n",
            "            1107.0\n",
            "          ],\n",
            "          [\n",
            "            832.0,\n",
            "            1107.0\n",
            "          ],\n",
            "          [\n",
            "            832.0,\n",
            "            948.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"b7c98178067be445b1d32a7f7b7de4c7\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"cbfb9aa9127dfca004d2dd75155a629c\",\n",
            "    \"text\": \"2.4 Model Evaluation\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            324.0,\n",
            "            1137.0\n",
            "          ],\n",
            "          [\n",
            "            324.0,\n",
            "            1155.0\n",
            "          ],\n",
            "          [\n",
            "            553.0,\n",
            "            1155.0\n",
            "          ],\n",
            "          [\n",
            "            553.0,\n",
            "            1137.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"c18a56b66088be9d58c065a4a8bc27d3\",\n",
            "    \"text\": \"We performed a preliminary evaluation of our model using the human evaluation data from the Self Instruct paper (Wang et al., 2023). We reported the ground truth perplexity of our model against what was, to our knowl- edge, the best openly available alpaca-lora model at the time, provided by user chainyo on HuggingFace. Both models had very large perplexities on a small number of tasks, so we reported perplexities clipped to a maximum of 100, We found that GPT4All produces stochastically lower ground truth perplexitics than alpaca-lora (Anand et al., 2023).\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            322.0,\n",
            "            1175.0\n",
            "          ],\n",
            "          [\n",
            "            322.0,\n",
            "            1477.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            1477.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            1175.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"cbfb9aa9127dfca004d2dd75155a629c\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"0f2ac1ad48e313fde439d850f90442c6\",\n",
            "    \"text\": \"3 From a Model to an Ecosystem\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            322.0,\n",
            "            1508.0\n",
            "          ],\n",
            "          [\n",
            "            322.0,\n",
            "            1536.0\n",
            "          ],\n",
            "          [\n",
            "            731.0,\n",
            "            1536.0\n",
            "          ],\n",
            "          [\n",
            "            731.0,\n",
            "            1508.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"f4f0c6e1d309c744fc08d0eafe010419\",\n",
            "    \"text\": \"3.1 GPT4AII-J: Repository Growth and the implications of the LLaMA License\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            322.0,\n",
            "            1557.0\n",
            "          ],\n",
            "          [\n",
            "            322.0,\n",
            "            1606.0\n",
            "          ],\n",
            "          [\n",
            "            765.0,\n",
            "            1606.0\n",
            "          ],\n",
            "          [\n",
            "            765.0,\n",
            "            1557.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"b803be6270bdf862ec03af9cdc88342b\",\n",
            "    \"text\": \"The GPT4AIl repository grew rapidly after its release, gaining over 20000 GitHub stars in just one week, as shown in Figure 2. This growth was supported by an in-person hackathon hosted in New York City three days after the model release, which attracted several hundred participants, As the Nomic discord, the home of online discussion about GPT4AII, ballooned to over 10000 people, one thing became very clear - there was massive demand for a model that could be used commercially\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            319.0,\n",
            "            1623.0\n",
            "          ],\n",
            "          [\n",
            "            319.0,\n",
            "            1874.0\n",
            "          ],\n",
            "          [\n",
            "            830.0,\n",
            "            1874.0\n",
            "          ],\n",
            "          [\n",
            "            830.0,\n",
            "            1623.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"f4f0c6e1d309c744fc08d0eafe010419\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"e115fbaefce694ef2d4b4941e494ab65\",\n",
            "    \"text\": \"hups://github.com/nomic-ai/gpttall\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            353.0,\n",
            "            1898.0\n",
            "          ],\n",
            "          [\n",
            "            353.0,\n",
            "            1916.0\n",
            "          ],\n",
            "          [\n",
            "            625.0,\n",
            "            1916.0\n",
            "          ],\n",
            "          [\n",
            "            625.0,\n",
            "            1898.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"b19971570fdcd00590a97c87963c5da7\",\n",
            "    \"text\": \"The LLaMA model that GPT4AII was based on was licensed for research only, which severely limited the set of domains that GPT4AII could be applied in. As a response to this, the Nomic team repeated the model training procedure of the original GPT4AII model, but based on the already open source and commercially li- censed GPT-J model (Wang and Komatsuzaki, 2021). GPT4AII-J also had an augmented training set, which contained multi-tum QA examples and creative writing such as poetry, rap, and short stories. The creative writ- ing prompts were generated by filling in schemas such as \\\"Write a [CREATIVE STORY TYPE] about [NOUN] in the style of [PERSON].\\\" We again employed Atlas to curate the prompt-response pairs in this data set.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            874.0,\n",
            "            265.0\n",
            "          ],\n",
            "          [\n",
            "            874.0,\n",
            "            662.0\n",
            "          ],\n",
            "          [\n",
            "            1390.0,\n",
            "            662.0\n",
            "          ],\n",
            "          [\n",
            "            1390.0,\n",
            "            265.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"e115fbaefce694ef2d4b4941e494ab65\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"2c3d8b98ff7a64d7349e31a728a61e4c\",\n",
            "    \"text\": \"Our evaluation methodology also evolved as the project grew. In particular, we began evaluating GPT4All models using a suite of seven reasoning tasks that were used for evaluation of the Databricks Dolly (Conover et al., 2023b) model, which was re- leased on April 12, 2023. Unfortunately, GPT4AII-J did not outperform other prominent open source models on this evaluation. As a result, we endeavoured to create a model that did,\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            873.0,\n",
            "            668.0\n",
            "          ],\n",
            "          [\n",
            "            873.0,\n",
            "            913.0\n",
            "          ],\n",
            "          [\n",
            "            1385.0,\n",
            "            913.0\n",
            "          ],\n",
            "          [\n",
            "            1385.0,\n",
            "            668.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"e115fbaefce694ef2d4b4941e494ab65\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"c9b9905ddf0ee056022c2b4502277815\",\n",
            "    \"text\": \"3.2. GPT4All-Snoozy: the Emergence of the GPT4All Ecosystem\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            873.0,\n",
            "            946.0\n",
            "          ],\n",
            "          [\n",
            "            873.0,\n",
            "            998.0\n",
            "          ],\n",
            "          [\n",
            "            1315.0,\n",
            "            998.0\n",
            "          ],\n",
            "          [\n",
            "            1315.0,\n",
            "            946.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"c2a47150e4e2c19fff008eb99ca36972\",\n",
            "    \"text\": \"GPT4All-Snoozy was developed using roughly the same procedure as the previous GPT4AIl models, but with a few key modifications. First, GPT4All-Snoozy used the LLaMA-13B base mcs due to its superior base metrics when compared to orf Next, GPT4All-Snoozy incor- porated the Dolly\\u2019s traifing data into its train mix. After data curation and deduplication with Atlas, this yielded a training set of 739,259 total prompt-response pairs. We dubbed the model that resulted from training on this improved dataset GPT4AIl-Snoozy. As shown in Figure 1, GPT4All-Snoozy had the best average score on our evaluation benchmark of any model in the ecosystem at the time of its release.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            869.0,\n",
            "            1015.0\n",
            "          ],\n",
            "          [\n",
            "            869.0,\n",
            "            1370.0\n",
            "          ],\n",
            "          [\n",
            "            1382.0,\n",
            "            1370.0\n",
            "          ],\n",
            "          [\n",
            "            1382.0,\n",
            "            1015.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"c9b9905ddf0ee056022c2b4502277815\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"8b2f032983b9c4cbc99d5681e64b22d7\",\n",
            "    \"text\": \"Concurrently with the development of GPT4AI, sev- eral organizations such as LMSys, Stability Al, BAIR, and Databricks built and deployed open source language models, We heard increasingly from the community that they wanted quantized versions of these models for local use. As we realized that organizations with ever more resources were developing source language models, we decided to pivot our effort away from training increas: ingly capable models and towards providing easy access to the plethora of models being produced by the open source community. Practically, this meant spending our time compressing open source models for use on com- modity hardware, providing stable and simple high level model APIs, and supporting a GUI for no code model experimentation\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            867.0,\n",
            "            1381.0\n",
            "          ],\n",
            "          [\n",
            "            867.0,\n",
            "            1799.0\n",
            "          ],\n",
            "          [\n",
            "            1380.0,\n",
            "            1799.0\n",
            "          ],\n",
            "          [\n",
            "            1380.0,\n",
            "            1381.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"c9b9905ddf0ee056022c2b4502277815\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"ca08f896cbd9782d95d05bb0d1a3f3a0\",\n",
            "    \"text\": \"33\\u00b0 The Current State of GPT4AlL\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            867.0,\n",
            "            1829.0\n",
            "          ],\n",
            "          [\n",
            "            867.0,\n",
            "            1851.0\n",
            "          ],\n",
            "          [\n",
            "            1219.0,\n",
            "            1851.0\n",
            "          ],\n",
            "          [\n",
            "            1219.0,\n",
            "            1829.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"c05fce8c12177e8db3c3961df671f496\",\n",
            "    \"text\": \"Today, GPT4AI1 is focused on improving the accessi bility of open source language models. The repository\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            867.0,\n",
            "            1870.0\n",
            "          ],\n",
            "          [\n",
            "            867.0,\n",
            "            1926.0\n",
            "          ],\n",
            "          [\n",
            "            1372.0,\n",
            "            1926.0\n",
            "          ],\n",
            "          [\n",
            "            1372.0,\n",
            "            1870.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"ca08f896cbd9782d95d05bb0d1a3f3a0\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"583893028def4f6b9b760a521a2d550d\",\n",
            "    \"text\": \"@) (b) (\\u00a9) (d)\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            435.0,\n",
            "            520.0\n",
            "          ],\n",
            "          [\n",
            "            435.0,\n",
            "            553.0\n",
            "          ],\n",
            "          [\n",
            "            1245.0,\n",
            "            553.0\n",
            "          ],\n",
            "          [\n",
            "            1245.0,\n",
            "            520.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"ca08f896cbd9782d95d05bb0d1a3f3a0\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"e134e4782987530cad118447d806ce4a\",\n",
            "    \"text\": \"Figure 1: TSNE visualizations showing the progression of the GPT4AII train set. Panel (a) shows the original uncurated data, The red arrow denotes a region of highly homogeneous prompt-response pairs. The coloring denotes which open dataset contributed the prompt. Panel (b) shows the original GPT4AlI data after curation. This panel, as well as panels (c) and (d) are 10 colored by topic, which Atlas automatically extracts. Notice that the large homogeneous prompt-response blobs no longer appearl. Panel (c) shows the GPT4AlIlI-J dataset. The \\\"starburst\\\" clusters introduced on the right side of the panel correspond to the newly added creative data. Panel (d) shows the final GPT4All-snoozy dataset. All datasets have been released to the public, and can be interactively explored online. In the web version of this article, you can click on a panel to be taken to its interactive visualization.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            316.0,\n",
            "            572.0\n",
            "          ],\n",
            "          [\n",
            "            316.0,\n",
            "            796.0\n",
            "          ],\n",
            "          [\n",
            "            1385.0,\n",
            "            796.0\n",
            "          ],\n",
            "          [\n",
            "            1385.0,\n",
            "            572.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"ca08f896cbd9782d95d05bb0d1a3f3a0\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"8ad44ca09461bffe5911992317f925f7\",\n",
            "    \"text\": \"Model BoolQ PIQA HellaSwag WinoG. ARC-c ARC-c OBQA Avg. GPT4AII-J 6B v1.0* 73.4 74.8 634 64.7 54.9 36 40.2 58.2 GPT4AII-J v1.1-breezy* 74 75.1 63.2 63.6 55.4 34.9 38.4 57.8 GPT4AIIL-J v1.2-jazzy* 74.8 74.9 63.6 638 56.6 35.3 41 58.6 GPT4AII-J v1.3-groovy* 73.6 74.3 63.8 63.5 57.7 35 38.8 \\u00a9 58.1 GPT4AII-J Lora 6B* 68.6 75.8 66.2 63.5 56.4 35.7 402 58.1 GPT4All LLaMa Lora 7B* 73.1 77.6 721 67.8 SIE 40.4 40.2 60.3 GPT4All 13B snoozy* 83.3 79.2 75 71.3 60.9 44.2 43.4 65.3 GPT4AIl Falcon 71.6 79.8 749 70.1 67.9 4B4 42.6 65.2 Nous-Hermes (Nous-Research, 2023b) 79.5 78.9 80 19 74.2 50.9 64 68.3 Nous-Hermes2 (Nous-Research, 2023c) 83.9 80.7 80.1 71.3 75.7 52.1 46.2 70.0 Nous-Puffin (Nous-Research, 2023d) 815 80.7 80.4 72.5 771.6 50.7 45.6 69.9 Dolly 6B* (Conover et al., 2023a) 68.8 71.3 67.6 63.9 62.9 38.7 412 1 Dolly 12B* (Conover et al., 2023) 56.7 75.4 1 62.2 64.6 38.5 404 584 Alpaca 7B* (Taori et al. , 2023) 73.9 TT 73.9 66.1 59.8 43.3 434 62.5 Alpaca Lora 7B* Wang. 2023) 94325793 74 68.8 56.6 43.9 426 628 GPT-J* 6.7B (Wang and Komatsuzaki, 2021) 654 76.2 66.2 64.1 62.2 36.6 38.2 58.4 LLama 7B* (Touvron et al., 2023) 73.1 714 13 66.9 52.5 414 42.4 61.0 LLama 13B* (Touvron et al_, 2023) 68.5 79.1 76.2 70.1 60 44.6 422 63.0 Pythia 6.7B* (Biderman et al., 2023) 63.5 76.3 64 61.1 61.3 35.2 37.2 56.9 Pythia 12B* (Biderman et al., 2023) 67.7 16.6 67.3 63.8 63.9 34.8 38 58.9 Fastchat TS* (Zheng et al., 2023) 815 64.6 46.3 618 49.3 (33.2. 39.4 53.7 Fastchat Vicufia* 7B (Zheng et al., 2023) 76.6 77.2 70.7 67.3 53.5 41.2 40.8 61.0 Fastchat Vicufia 13B* (Zheng et al., 2023) 815 76.8 73.3 66.7 57.4 42.7 3.6 63.1 Stable Vicufia RLHF* (Stability-Al, 2023) 82.3 78.6 74.1 70.9 61 43.5 444 65.0 StableLM Tuned* (Stability-Al, 2023) 625 71.2 53.6 54.8 52.4 31 33.4 SUS StableLM Base* (Stability-Al, 2023) 60.1 67.4 412 50.1 44.9 27 32 46.1 Koala 13B* (Geng et al., 2023) 765 71.9 72.6 68.8 54.3 4l 42.8 62.0 Open Assistant Pythia 12B* 67.9 3 68.1 65 64.2 40.4 43.2 61.0 Mosaic MPT7B (MosaicML-Team, 2023) 748 193 76.3 68.6 70 42.2 42.6 64.8 Mosaic mpt-instruct (MosaicML-Team, 2023) 743 80.4 77.2. 678 72.2 44.6 43 65.6 Mosaic mpt-chat (MosaicML-Team, 2023) 771 78.2 74.5 67.5 69.4 43.3 44.2 9 Wizard 7B xu et al., 2023) 74 772 69.9 66,5 56.8 40.5 42.6 61,7 Wizard 7B Uncensored (Xu et al., 2023) 717 74.2 68 65.2 53.5 38,7 416 59.8 Wizard 13B Uncensored (Xu et al,, 2023) 784 15.5 21 69.5 57.5 40.4 44 62.5 GPT4-x-Vicuna-13b (Nous-Research, 2023a) 813 75 75.2 65 58.7 43,9 43.6 63,2 Falcon 7b (Almazrouei et al., 2023) 7236 80.7 16.3 67,3 1 43.3 444 65.2 Falcon 7b instruct (Almazrouei et al., 2023) 9 78.6 69.8 66.7 619) 4a 4 OS text-davinci-003 88.1 83.8 834 75.8 83.9 63.9 SLO 2\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            315.0,\n",
            "            833.0\n",
            "          ],\n",
            "          [\n",
            "            315.0,\n",
            "            1652.0\n",
            "          ],\n",
            "          [\n",
            "            1376.0,\n",
            "            1652.0\n",
            "          ],\n",
            "          [\n",
            "            1376.0,\n",
            "            833.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"ca08f896cbd9782d95d05bb0d1a3f3a0\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"57f7ed876c54c522595f29bfa50ae0ed\",\n",
            "    \"text\": \"Table 1: Evaluations of all language models in the GPT4AIl ecosystem as of August 1, 2023, Code models are not included. OpenAI\\u2019s text-davinci-003 is included as a point of comparison. The best overall performing model in the GPT4AIl ecosystem, Nous-Hermes?, achieves over 92% of the average performance of text-davinci-003, Models marked with an asterisk were available in the ecosystem as of the release of GPT4All-Snoozy. Note that at release, GPT4AII-Snoozy had the best average performance of any model in the ecosystem. Bolded numbers indicate the best performing model as of August 1, 2023\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            308.0,\n",
            "            1677.0\n",
            "          ],\n",
            "          [\n",
            "            308.0,\n",
            "            1850.0\n",
            "          ],\n",
            "          [\n",
            "            1378.0,\n",
            "            1850.0\n",
            "          ],\n",
            "          [\n",
            "            1378.0,\n",
            "            1677.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 3,\n",
            "      \"parent_id\": \"ca08f896cbd9782d95d05bb0d1a3f3a0\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"fae05d8e02ce0c387969c227af5f183a\",\n",
            "    \"text\": \"Github Repo Growth\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            776.0,\n",
            "            294.0\n",
            "          ],\n",
            "          [\n",
            "            776.0,\n",
            "            313.0\n",
            "          ],\n",
            "          [\n",
            "            942.0,\n",
            "            313.0\n",
            "          ],\n",
            "          [\n",
            "            942.0,\n",
            "            294.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"7925282b336737d8ff77bf1c29aa7ee2\",\n",
            "    \"text\": \"\\u2014 GPT4All \\u2014- UaMA \\u2014 Apaca\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            624.0,\n",
            "            329.0\n",
            "          ],\n",
            "          [\n",
            "            624.0,\n",
            "            386.0\n",
            "          ],\n",
            "          [\n",
            "            715.0,\n",
            "            386.0\n",
            "          ],\n",
            "          [\n",
            "            715.0,\n",
            "            329.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"af345d782230a2d1faf3c81a360e7e00\",\n",
            "    \"text\": \"50000\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            558.0,\n",
            "            331.0\n",
            "          ],\n",
            "          [\n",
            "            558.0,\n",
            "            342.0\n",
            "          ],\n",
            "          [\n",
            "            600.0,\n",
            "            342.0\n",
            "          ],\n",
            "          [\n",
            "            600.0,\n",
            "            331.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"7925282b336737d8ff77bf1c29aa7ee2\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"b1a2bb160ab31d838d73def9fae6cf64\",\n",
            "    \"text\": \"40000\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            559.0,\n",
            "            398.0\n",
            "          ],\n",
            "          [\n",
            "            559.0,\n",
            "            409.0\n",
            "          ],\n",
            "          [\n",
            "            601.0,\n",
            "            409.0\n",
            "          ],\n",
            "          [\n",
            "            601.0,\n",
            "            398.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"7925282b336737d8ff77bf1c29aa7ee2\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"604cb1546e239c9c8a5937711c3680f6\",\n",
            "    \"text\": \"30000\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            560.0,\n",
            "            467.0\n",
            "          ],\n",
            "          [\n",
            "            560.0,\n",
            "            477.0\n",
            "          ],\n",
            "          [\n",
            "            601.0,\n",
            "            477.0\n",
            "          ],\n",
            "          [\n",
            "            601.0,\n",
            "            467.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"7925282b336737d8ff77bf1c29aa7ee2\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"e774b0ef0faa4dcd59db34da68b2a8c4\",\n",
            "    \"text\": \"Github Stars\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            538.0,\n",
            "            461.0\n",
            "          ],\n",
            "          [\n",
            "            538.0,\n",
            "            548.0\n",
            "          ],\n",
            "          [\n",
            "            550.0,\n",
            "            548.0\n",
            "          ],\n",
            "          [\n",
            "            550.0,\n",
            "            461.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"8e87bb21077b390100c48a1a71584b0c\",\n",
            "    \"text\": \"i\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            560.0,\n",
            "            534.0\n",
            "          ],\n",
            "          [\n",
            "            560.0,\n",
            "            545.0\n",
            "          ],\n",
            "          [\n",
            "            602.0,\n",
            "            545.0\n",
            "          ],\n",
            "          [\n",
            "            602.0,\n",
            "            534.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"c343d14141cec8eba388dd7afe3656f3\",\n",
            "    \"text\": \"10000\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            562.0,\n",
            "            601.0\n",
            "          ],\n",
            "          [\n",
            "            562.0,\n",
            "            612.0\n",
            "          ],\n",
            "          [\n",
            "            602.0,\n",
            "            612.0\n",
            "          ],\n",
            "          [\n",
            "            602.0,\n",
            "            601.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"8e87bb21077b390100c48a1a71584b0c\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"88492d084aef06b761dc6a31264e7bbb\",\n",
            "    \"text\": \"0 20 40 60\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            633.0,\n",
            "            694.0\n",
            "          ],\n",
            "          [\n",
            "            633.0,\n",
            "            722.0\n",
            "          ],\n",
            "          [\n",
            "            832.0,\n",
            "            722.0\n",
            "          ],\n",
            "          [\n",
            "            832.0,\n",
            "            694.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"8e87bb21077b390100c48a1a71584b0c\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"5d2f9d059fb7f8422b8a379fc4f19f02\",\n",
            "    \"text\": \"80 100-120 140\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            877.0,\n",
            "            702.0\n",
            "          ],\n",
            "          [\n",
            "            877.0,\n",
            "            713.0\n",
            "          ],\n",
            "          [\n",
            "            1084.0,\n",
            "            713.0\n",
            "          ],\n",
            "          [\n",
            "            1084.0,\n",
            "            702.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"8e87bb21077b390100c48a1a71584b0c\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"166007c1bd4d25db96d5153c1d2c7ee9\",\n",
            "    \"text\": \"Days Since Launch\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            796.0,\n",
            "            721.0\n",
            "          ],\n",
            "          [\n",
            "            796.0,\n",
            "            735.0\n",
            "          ],\n",
            "          [\n",
            "            924.0,\n",
            "            735.0\n",
            "          ],\n",
            "          [\n",
            "            924.0,\n",
            "            721.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"f58ffd0577b70d0bb6041d445e5c1f36\",\n",
            "    \"text\": \"Figure 2: Comparison of the github start growth of GPT4All, Meta\\u2019s LLaMA, and Stanford\\u2019s Alpaca. We conjecture that GPT4AIl achieved and maintains faster ecosystem growth due to the focus on access, which allows more users\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            319.0,\n",
            "            769.0\n",
            "          ],\n",
            "          [\n",
            "            319.0,\n",
            "            822.0\n",
            "          ],\n",
            "          [\n",
            "            1383.0,\n",
            "            822.0\n",
            "          ],\n",
            "          [\n",
            "            1383.0,\n",
            "            769.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"166007c1bd4d25db96d5153c1d2c7ee9\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"a8256c49504c5a402e34150cc681af19\",\n",
            "    \"text\": \"to meaningfully participate.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            319.0,\n",
            "            826.0\n",
            "          ],\n",
            "          [\n",
            "            319.0,\n",
            "            849.0\n",
            "          ],\n",
            "          [\n",
            "            579.0,\n",
            "            849.0\n",
            "          ],\n",
            "          [\n",
            "            579.0,\n",
            "            826.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"166007c1bd4d25db96d5153c1d2c7ee9\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"be94bab4d071a81feb41305425beb04c\",\n",
            "    \"text\": \"provides compressed versions of open source models for use on commodity hardware, stable and simple high level model APIs, and a GUI for no code model ex- perimentation. The project continues to increase in popularity, and as of August 1 2023, has garnered over 50000 GitHub stars and over 5000 forks.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            319.0,\n",
            "            907.0\n",
            "          ],\n",
            "          [\n",
            "            319.0,\n",
            "            1067.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1067.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            907.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"166007c1bd4d25db96d5153c1d2c7ee9\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"4684c7bc87da1a1efdd95d4e71b24361\",\n",
            "    \"text\": \"GPT4All currently provides native support and benchmark data for over 35 models (see Figure 1), and includes several models co-developed with industry part- ners such as Replit and Hugging Face. GPT4AII also provides high level model APIs in languages includ- ing Python, Typescript, Go, C#, and Java, among oth- ers. Furthermore, the GPT4All no code GUI currently supports the workflows of over 50000 monthly active users, with over 25% of users coming back to the tool every day of the week. (Note that all GPT4AII user data is collected on an opt in basis.) GPT4AIl has be- come the top language model integration in the popular open source AI orchestration library LangChain (Chase, 2022), and powers many popular open source projects such as PrivateGPT (imartinez, 2023), Quiver (StanGi- rard, 2023), and MindsDB (MindsDB, 2023), among others, GPT4AII is the 3rd fastest growing GitHub repository of all time (Leo, 2023), and is the 185th most popular repository on the platform, by star count.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            317.0,\n",
            "            1081.0\n",
            "          ],\n",
            "          [\n",
            "            317.0,\n",
            "            1616.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1616.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1081.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"166007c1bd4d25db96d5153c1d2c7ee9\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"05be8dc08339fdfc4f315798acfed76d\",\n",
            "    \"text\": \"4 The Future of GPT4AIl\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            316.0,\n",
            "            1652.0\n",
            "          ],\n",
            "          [\n",
            "            316.0,\n",
            "            1674.0\n",
            "          ],\n",
            "          [\n",
            "            642.0,\n",
            "            1674.0\n",
            "          ],\n",
            "          [\n",
            "            642.0,\n",
            "            1652.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"e8512e6f05426a74cf623ebba360a1db\",\n",
            "    \"text\": \"In the future, we will continue to grow GPT4AN, sup- porting it as the de facto solution for LLM accessibil- ity. Concretely, this means continuing to compress and distribute important open-source language models de- veloped by the community, as well as compressing and distributing increasingly multimodal AI models, Fur- thermore, we will expand the set of hardware devices that GPT4AII models run on, so that GPT4AIl models\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            316.0,\n",
            "            1706.0\n",
            "          ],\n",
            "          [\n",
            "            316.0,\n",
            "            1929.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1929.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1706.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"05be8dc08339fdfc4f315798acfed76d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"324215bfc9e5fbb868729bec0ce86025\",\n",
            "    \"text\": \"\\u201cjust work\\\" on any machine, whether it comes equipped with Apple Metal silicon, NVIDIA, AMD, or other edge- accelerated hardware, Overall, we envision a world where anyone, anywhere, with any machine, can access and contribute to the cutting edge of AI.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            870.0,\n",
            "            909.0\n",
            "          ],\n",
            "          [\n",
            "            870.0,\n",
            "            1045.0\n",
            "          ],\n",
            "          [\n",
            "            1386.0,\n",
            "            1045.0\n",
            "          ],\n",
            "          [\n",
            "            1386.0,\n",
            "            909.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"05be8dc08339fdfc4f315798acfed76d\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"ac9490538379563bc0cb472ec0ea8eb3\",\n",
            "    \"text\": \"Limitations\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            873.0,\n",
            "            1081.0\n",
            "          ],\n",
            "          [\n",
            "            873.0,\n",
            "            1103.0\n",
            "          ],\n",
            "          [\n",
            "            1010.0,\n",
            "            1103.0\n",
            "          ],\n",
            "          [\n",
            "            1010.0,\n",
            "            1081.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"a3b34f4453e2127d454483237ce16028\",\n",
            "    \"text\": \"By enabling uk large language models, the GPT4AII project also inherits many of the ethical con- cems associated with generative models. Principal among these is the concern that unfiltered language models like GPT4All enable malicious users to generate content that could be harmful and dangerous (e.g., in- structions on building bioweapons), While we recognize this risk, we also acknowledge the risk of concentrating this technology in the hands of a limited number of in- creasingly secretive research groups, We believe that the risk of focusing on the benefits of language model technology significantly outweighs the risk of misuse, and hence we prefer to make the technology as widely available as possible.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            873.0,\n",
            "            1099.0\n",
            "          ],\n",
            "          [\n",
            "            873.0,\n",
            "            1526.0\n",
            "          ],\n",
            "          [\n",
            "            1388.0,\n",
            "            1526.0\n",
            "          ],\n",
            "          [\n",
            "            1388.0,\n",
            "            1099.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"ac9490538379563bc0cb472ec0ea8eb3\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"a63d1437913b6339c815061a953ab135\",\n",
            "    \"text\": \"Finally, we realize the challenge in assigning credit for large-scale open source initiatives. We make a first attempt at fair credit assignment by explicitly includ- ing the GPT4AII open source developers as authors on this work, but recognize that this is insufficient fully characterize everyone involved in the GPT4AII effort. Furthermore, we acknowledge the difficulty in citing open source works that do not necessarily have standard- ized citations, and do our best in this paper to provide URLs to projects whenever possible. We encourage further research in the area of open source credit as signment, and hope to be able to support some of this research ourselves in the future\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            875.0,\n",
            "            1534.0\n",
            "          ],\n",
            "          [\n",
            "            875.0,\n",
            "            1899.0\n",
            "          ],\n",
            "          [\n",
            "            1391.0,\n",
            "            1899.0\n",
            "          ],\n",
            "          [\n",
            "            1391.0,\n",
            "            1534.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"ac9490538379563bc0cb472ec0ea8eb3\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"ec65b806683166bd41616ed4affd398b\",\n",
            "    \"text\": \"References Nomic AT. 2023. Atlas. https://atlas.nomic.ai/.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            325.0,\n",
            "            260.0\n",
            "          ],\n",
            "          [\n",
            "            325.0,\n",
            "            329.0\n",
            "          ],\n",
            "          [\n",
            "            830.0,\n",
            "            329.0\n",
            "          ],\n",
            "          [\n",
            "            830.0,\n",
            "            260.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"ff447f96b6bf72627398a07e3eaad24a\",\n",
            "    \"text\": \"Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Al- shamsi, Alessandro Cappelli, Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Hes- low, Julien Launay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. 2023. Falcon-40B: an open large language model with state-of-the-art performance.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            325.0,\n",
            "            356.0\n",
            "          ],\n",
            "          [\n",
            "            325.0,\n",
            "            536.0\n",
            "          ],\n",
            "          [\n",
            "            841.0,\n",
            "            536.0\n",
            "          ],\n",
            "          [\n",
            "            841.0,\n",
            "            356.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"ec65b806683166bd41616ed4affd398b\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"031b146d5d2e60a822477f2e7e168ec3\",\n",
            "    \"text\": \"Yuvanesh Anand, Zach Nussbaum, Brandon Duder- stadt, Benjamin Schmidt, and Andriy Mulyar. 2023. Gpt4all: Training an assistant-style chatbot with large scale data distillation from gpt-3.5-turbo. https: //github.com/nomic-ai/gpt4all.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            326.0,\n",
            "            562.0\n",
            "          ],\n",
            "          [\n",
            "            326.0,\n",
            "            691.0\n",
            "          ],\n",
            "          [\n",
            "            841.0,\n",
            "            691.0\n",
            "          ],\n",
            "          [\n",
            "            841.0,\n",
            "            562.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"ec65b806683166bd41616ed4affd398b\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"96b99fb92c077a36f47b747d61206825\",\n",
            "    \"text\": \"BBC News. 2023. Chatgpt banned in italy over privacy concerns. BBC News.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            326.0,\n",
            "            714.0\n",
            "          ],\n",
            "          [\n",
            "            326.0,\n",
            "            766.0\n",
            "          ],\n",
            "          [\n",
            "            837.0,\n",
            "            766.0\n",
            "          ],\n",
            "          [\n",
            "            837.0,\n",
            "            714.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"ec65b806683166bd41616ed4affd398b\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"9d2b6c54458ad97d68464d08a873abd9\",\n",
            "    \"text\": \"Stella Biderman, Hailey Schoelkopf, Quentin An- thony, Herbie Bradley, Kyle O\\u2019Brien, Eric Hal- lahan, Mohammad Aflah Khan, Shivanshu Puro- hit, USVSN Sai Prashanth, Edward Raff, Aviya Skowron, Lintang Sutawika, and Oskar van der Wal. 2023. Pythia: A suite for analyzing large language models across training and scaling.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            325.0,\n",
            "            788.0\n",
            "          ],\n",
            "          [\n",
            "            325.0,\n",
            "            964.0\n",
            "          ],\n",
            "          [\n",
            "            841.0,\n",
            "            964.0\n",
            "          ],\n",
            "          [\n",
            "            841.0,\n",
            "            788.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"ec65b806683166bd41616ed4affd398b\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"886ea7ec0218a995d8711dd9a96ae3d7\",\n",
            "    \"text\": \"Harrison Chase. 2022. langchain. https://github. com/langchain-ai/langchain.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            325.0,\n",
            "            990.0\n",
            "          ],\n",
            "          [\n",
            "            325.0,\n",
            "            1038.0\n",
            "          ],\n",
            "          [\n",
            "            840.0,\n",
            "            1038.0\n",
            "          ],\n",
            "          [\n",
            "            840.0,\n",
            "            990.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"2829deeb1aef68b7dd984491582b736d\",\n",
            "    \"text\": \"Mike Conover, Matt Hayes, Ankit Mathur, Xiangrui Meng, Jianwei Xie, Jun Wan, Ali Ghodsi, Patrick Wendell, and Matei Zaharia. 2023a. Hello dolly: Democratizing the magic of chatgpt with open mod- els.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            324.0,\n",
            "            1063.0\n",
            "          ],\n",
            "          [\n",
            "            324.0,\n",
            "            1185.0\n",
            "          ],\n",
            "          [\n",
            "            839.0,\n",
            "            1185.0\n",
            "          ],\n",
            "          [\n",
            "            839.0,\n",
            "            1063.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"886ea7ec0218a995d8711dd9a96ae3d7\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"e815f282e0d35e8bb03aa8bba15b9157\",\n",
            "    \"text\": \"Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin. 2023b. Free dolly: Introducing the world\\u2019s first truly open instruction- tuned Im.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            323.0,\n",
            "            1214.0\n",
            "          ],\n",
            "          [\n",
            "            323.0,\n",
            "            1338.0\n",
            "          ],\n",
            "          [\n",
            "            839.0,\n",
            "            1338.0\n",
            "          ],\n",
            "          [\n",
            "            839.0,\n",
            "            1214.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"886ea7ec0218a995d8711dd9a96ae3d7\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"ecbe83b2f160b4993aa56eaf343dff0a\",\n",
            "    \"text\": \"Xinyang Geng, Arnav Gudibande, Hao Liu, Eric Wal- Jace, Pieter Abbeel, Sergey Levine, and Dawn Song. 2023. Koala: A dialogue model for academic re- search. Blog post.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            322.0,\n",
            "            1366.0\n",
            "          ],\n",
            "          [\n",
            "            322.0,\n",
            "            1469.0\n",
            "          ],\n",
            "          [\n",
            "            839.0,\n",
            "            1469.0\n",
            "          ],\n",
            "          [\n",
            "            839.0,\n",
            "            1366.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"886ea7ec0218a995d8711dd9a96ae3d7\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"17a83aeba87bb3814fcba759836f2ca6\",\n",
            "    \"text\": \"Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen, 2021, Lora: Low-rank adaptation of large language models,\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            320.0,\n",
            "            1493.0\n",
            "          ],\n",
            "          [\n",
            "            320.0,\n",
            "            1598.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1598.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1493.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"886ea7ec0218a995d8711dd9a96ae3d7\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "    \"text\": \"imartinez. 2023. privategpt, https://github.com/ imartinez/privateGPT.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            319.0,\n",
            "            1621.0\n",
            "          ],\n",
            "          [\n",
            "            319.0,\n",
            "            1672.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1672.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            1621.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"a7349787d70d9c2093d459fe3ca5c693\",\n",
            "    \"text\": \"Oscar Leo, 2023. GitHub: The Fastest Growing Repos- itories of AJ] Time.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            318.0,\n",
            "            1696.0\n",
            "          ],\n",
            "          [\n",
            "            318.0,\n",
            "            1743.0\n",
            "          ],\n",
            "          [\n",
            "            837.0,\n",
            "            1743.0\n",
            "          ],\n",
            "          [\n",
            "            837.0,\n",
            "            1696.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"65931a58c527e7b109596a20f87f1355\",\n",
            "    \"text\": \"Robert McMillan, 2023. A meta platforms leak put powerful ai in the hands of everyone. The Wall Street Journal\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            318.0,\n",
            "            1772.0\n",
            "          ],\n",
            "          [\n",
            "            318.0,\n",
            "            1845.0\n",
            "          ],\n",
            "          [\n",
            "            833.0,\n",
            "            1845.0\n",
            "          ],\n",
            "          [\n",
            "            833.0,\n",
            "            1772.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"b27fe1d4f2a4bc3baac99787a4a12392\",\n",
            "    \"text\": \"MindsDB, 2023, Mindsdb. https://github.com/ mindsdb/mindsdb, GitHub repository\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            318.0,\n",
            "            1876.0\n",
            "          ],\n",
            "          [\n",
            "            318.0,\n",
            "            1925.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            1925.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            1876.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"63979de6e1701724f4278ac34ba9bfd0\",\n",
            "    \"text\": \"MosaicML-Team. 2023. Introducing mpt-7b: A new standard for open-source, commercially usable lms. Accessed: 2023-08-07.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            879.0,\n",
            "            265.0\n",
            "          ],\n",
            "          [\n",
            "            879.0,\n",
            "            335.0\n",
            "          ],\n",
            "          [\n",
            "            1390.0,\n",
            "            335.0\n",
            "          ],\n",
            "          [\n",
            "            1390.0,\n",
            "            265.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"d3246b135b36ddd7688886a776431694\",\n",
            "    \"text\": \"Nous-Research. 2023a. gpt4-x-vicuna-13b. https: //huggingface.co/NousResearch/ gpt4-x-vicuna-13b. Model on Hugging Face.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            879.0,\n",
            "            366.0\n",
            "          ],\n",
            "          [\n",
            "            879.0,\n",
            "            441.0\n",
            "          ],\n",
            "          [\n",
            "            1390.0,\n",
            "            441.0\n",
            "          ],\n",
            "          [\n",
            "            1390.0,\n",
            "            366.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"3acfe7080f896bca5aab8e68438eac41\",\n",
            "    \"text\": \"Nous-Research. 2023b. Nous-hermes-13b. https: //huggingface.co/NousResearch/ Nous-Hermes-13b. Model on Hugging Face.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            879.0,\n",
            "            468.0\n",
            "          ],\n",
            "          [\n",
            "            879.0,\n",
            "            542.0\n",
            "          ],\n",
            "          [\n",
            "            1389.0,\n",
            "            542.0\n",
            "          ],\n",
            "          [\n",
            "            1389.0,\n",
            "            468.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"4290a971cb2ea24b7ca96ebd85f6a7ea\",\n",
            "    \"text\": \"Nous-Research. 2023c. Nous-hermes-Ilama-2-7b. https: //huggingface.co/NousResearch/ Nous-Hermes-llama-2-7b. Model on Hugging Face.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            879.0,\n",
            "            569.0\n",
            "          ],\n",
            "          [\n",
            "            879.0,\n",
            "            665.0\n",
            "          ],\n",
            "          [\n",
            "            1389.0,\n",
            "            665.0\n",
            "          ],\n",
            "          [\n",
            "            1389.0,\n",
            "            569.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"5fa14f83af115bdda91a6ea497ee24f5\",\n",
            "    \"text\": \"Nous-Research. 2023d. Redmond-puffin-13b. https: //huggingface.co/NousResearch/ Redmond-Puf fin-13B. Model on Hugging Face.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            878.0,\n",
            "            696.0\n",
            "          ],\n",
            "          [\n",
            "            878.0,\n",
            "            770.0\n",
            "          ],\n",
            "          [\n",
            "            1388.0,\n",
            "            770.0\n",
            "          ],\n",
            "          [\n",
            "            1388.0,\n",
            "            696.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"7df837f03cd3e9af3927439979d32231\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"ad8404b5ba525ba55c88db3507afea61\",\n",
            "    \"text\": \"OpenAI. 2023. Gpt-4 technical report.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            878.0,\n",
            "            797.0\n",
            "          ],\n",
            "          [\n",
            "            878.0,\n",
            "            819.0\n",
            "          ],\n",
            "          [\n",
            "            1232.0,\n",
            "            819.0\n",
            "          ],\n",
            "          [\n",
            "            1232.0,\n",
            "            797.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"5155c4ea4ec7b469b74b73f0770aeb0c\",\n",
            "    \"text\": \"Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szezechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Teshala Neeraj, Jos Rozen, Ab- heesht Sharma, Ar}irea Santilli, Thibault Fevry, Ja- son Alan Fries, RxAn Teehan, Stella Biderman, Leo Gao, Tali Bers, Thomas Wolf, and Alexander M. Rush. 2021. Multitask prompted training enables zero-shot task generalization,\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            878.0,\n",
            "            845.0\n",
            "          ],\n",
            "          [\n",
            "            878.0,\n",
            "            1228.0\n",
            "          ],\n",
            "          [\n",
            "            1387.0,\n",
            "            1228.0\n",
            "          ],\n",
            "          [\n",
            "            1387.0,\n",
            "            845.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"ad8404b5ba525ba55c88db3507afea61\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"035581f765a747731186ed3a649ed409\",\n",
            "    \"text\": \"Stability-AL. 2023. Stablelm. https: //github.com/ Stability-AI/StableLM. GitHub repository.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            877.0,\n",
            "            1251.0\n",
            "          ],\n",
            "          [\n",
            "            877.0,\n",
            "            1303.0\n",
            "          ],\n",
            "          [\n",
            "            1386.0,\n",
            "            1303.0\n",
            "          ],\n",
            "          [\n",
            "            1386.0,\n",
            "            1251.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"3a8e10295cb9afdbfe72280310d957ad\",\n",
            "    \"text\": \"StanGirard. 2023. quivr. https://github.com/ StanGirard/quivr, GitHub repository.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            876.0,\n",
            "            1331.0\n",
            "          ],\n",
            "          [\n",
            "            876.0,\n",
            "            1379.0\n",
            "          ],\n",
            "          [\n",
            "            1386.0,\n",
            "            1379.0\n",
            "          ],\n",
            "          [\n",
            "            1386.0,\n",
            "            1331.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"5d1bc696851ef79af9375f55b5b41cf3\",\n",
            "    \"text\": \"Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B, Hashimoto. 2023. Stanford alpaca: An instruction-following llama model, https: // github. com/tatsu-lab/stanford_alpaca.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            877.0,\n",
            "            1405.0\n",
            "          ],\n",
            "          [\n",
            "            877.0,\n",
            "            1537.0\n",
            "          ],\n",
            "          [\n",
            "            1388.0,\n",
            "            1537.0\n",
            "          ],\n",
            "          [\n",
            "            1388.0,\n",
            "            1405.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"3a8e10295cb9afdbfe72280310d957ad\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"UncategorizedText\",\n",
            "    \"element_id\": \"171ccc2dc868ac8356c784d33399c9e7\",\n",
            "    \"text\": \"Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\\u00e9e Lacroix, Baptiste Rozi\\u00e9re, Naman Goyal, Bric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample, 2023, Llama: Open and efficient foundation language models,\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            876.0,\n",
            "            1561.0\n",
            "          ],\n",
            "          [\n",
            "            876.0,\n",
            "            1736.0\n",
            "          ],\n",
            "          [\n",
            "            1390.0,\n",
            "            1736.0\n",
            "          ],\n",
            "          [\n",
            "            1390.0,\n",
            "            1561.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"3a8e10295cb9afdbfe72280310d957ad\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"96193587a3ec137f8f1402f5ba65703e\",\n",
            "    \"text\": \"The Verge. 2023, Meta\\u2019s powerful ai language model has leaked online \\u2014 what happens now? The Verge\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            874.0,\n",
            "            1769.0\n",
            "          ],\n",
            "          [\n",
            "            874.0,\n",
            "            1818.0\n",
            "          ],\n",
            "          [\n",
            "            1388.0,\n",
            "            1818.0\n",
            "          ],\n",
            "          [\n",
            "            1388.0,\n",
            "            1769.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"3a8e10295cb9afdbfe72280310d957ad\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"fc824dd6182933738198e6c1d09a9799\",\n",
            "    \"text\": \"James Vincent. 2023. As an ai generated language model; The phrase that shows how ai is polluting the web. The Verge.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            875.0,\n",
            "            1847.0\n",
            "          ],\n",
            "          [\n",
            "            875.0,\n",
            "            1921.0\n",
            "          ],\n",
            "          [\n",
            "            1387.0,\n",
            "            1921.0\n",
            "          ],\n",
            "          [\n",
            "            1387.0,\n",
            "            1847.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"3a8e10295cb9afdbfe72280310d957ad\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"40cd518728254214751a03711f485660\",\n",
            "    \"text\": \"| fren\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            147.0,\n",
            "            2063.0\n",
            "          ],\n",
            "          [\n",
            "            147.0,\n",
            "            2112.0\n",
            "          ],\n",
            "          [\n",
            "            1556.0,\n",
            "            2112.0\n",
            "          ],\n",
            "          [\n",
            "            1556.0,\n",
            "            2063.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 5,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"04c3ff73bf077e14ea3e3fe8d73d17ef\",\n",
            "    \"text\": \"Ben Wang and Aran Komatsuzaki. 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https: //github.com/kingoflolz/ mesh-transformer-jax.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            319.0,\n",
            "            273.0\n",
            "          ],\n",
            "          [\n",
            "            319.0,\n",
            "            376.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            376.0\n",
            "          ],\n",
            "          [\n",
            "            834.0,\n",
            "            273.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 6,\n",
            "      \"parent_id\": \"40cd518728254214751a03711f485660\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"9bf04982948259cfa12c2444f16697e3\",\n",
            "    \"text\": \"Enc J. Wang. 2023. alpaca-lora. https://github. com/tloen/alpaca-lora. GitHub repository.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            320.0,\n",
            "            397.0\n",
            "          ],\n",
            "          [\n",
            "            320.0,\n",
            "            450.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            450.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            397.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 6,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"55b51cf7becc1a40a4f665cb04af4e0d\",\n",
            "    \"text\": \"Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Han- nanch Hajishirzi. 2023. Self-instruct: Aligning lan- guage models with self-generated instructions.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            321.0,\n",
            "            468.0\n",
            "          ],\n",
            "          [\n",
            "            321.0,\n",
            "            571.0\n",
            "          ],\n",
            "          [\n",
            "            837.0,\n",
            "            571.0\n",
            "          ],\n",
            "          [\n",
            "            837.0,\n",
            "            468.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 6,\n",
            "      \"parent_id\": \"9bf04982948259cfa12c2444f16697e3\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"b7ef3aaaa4297d57b181319cc7d5bd15\",\n",
            "    \"text\": \"Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023. Wizardlm: Empowering large language models to follow complex instructions.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            322.0,\n",
            "            591.0\n",
            "          ],\n",
            "          [\n",
            "            322.0,\n",
            "            693.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            693.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            591.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 6,\n",
            "      \"parent_id\": \"9bf04982948259cfa12c2444f16697e3\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"571342fd70ea71de51f9f7281fad43c0\",\n",
            "    \"text\": \"Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging Ilm-as-a-judge with mt-bench and chatbot arena.\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            323.0,\n",
            "            714.0\n",
            "          ],\n",
            "          [\n",
            "            323.0,\n",
            "            841.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            841.0\n",
            "          ],\n",
            "          [\n",
            "            836.0,\n",
            "            714.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"page_number\": 6,\n",
            "      \"parent_id\": \"9bf04982948259cfa12c2444f16697e3\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for extracting tables\n",
        "\n",
        "from unstructured.partition.pdf import partition_pdf\n",
        "\n",
        "elements = partition_pdf(filename=filename,\n",
        "                         infer_table_structure=True,\n",
        "                         strategy='hi_res', # table extraction parameter\n",
        "           )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214,
          "referenced_widgets": [
            "57005feab5c144d2a2520d7a072ec4b4",
            "1f859b3f9cae486ba47a86eaa41f6989",
            "e74a70ab920a46618d28848c1e5c6f7b",
            "d92777bd183a42d9b237752d1a4fda25",
            "2187893a050e42d9bd98b199ea454fd8",
            "48ba25f4cef641f49253f00f34a4957a",
            "cc67073998f242709244ebf163acf347",
            "669ff54985f741ad817391ea8f80d445",
            "f922c7dfba4446e5beccdca90513f54c",
            "6dd3c16930784fed850b2f168bd40137",
            "5182812aad1a4ac889e4f7a89c510752",
            "d8f86b6c93c949919535e477b64ae1ed",
            "f5591526650e451da4a852a3cfcc84b0",
            "52c9d779156d4890a77f6345eca40505",
            "e5a014f8457f4d51a452ee1e85dbf905",
            "4a31c2853aef44348e165621881ed43d",
            "5ccc75a8923d4080abf1ee76a481d282",
            "fa744d8af07f40e78d2e5e18ee94b256",
            "fb1babb721b84f9787a447d7ce87809a",
            "e3d2aa8ddc36422b808467787f3202c3",
            "6f043c38dc844e05bb315f6b456f8cc8",
            "b3d85469e340438aabafb1d842cffbb3",
            "aa454f8569f644a3862ff4f92f7711c5",
            "d5e774eaadab4e039022205e4ef5c22e",
            "2ed2dc4e545647df80779891efe42019",
            "4a5472e320cc4155a0f669ee8f4fa149",
            "895a73d8443348aeaa82f30454b3fd9f",
            "b187ab7d4d194bc9ac1127c3f0b0e280",
            "b8dd92320c46431a83f55fbb83f47a65",
            "711eb369f16146fba4cbd1ee57e4ac27",
            "c8e0839363f74df0a20a0945b3a1cb4e",
            "282591a7337c4869a75d9f585f018db9",
            "5c09134103dd4cceb0ac3bb3195f4ec6",
            "90d8adff903b47ccb9f8d057f38db5cc",
            "be949b9dbac64d1ca89783c3df32dc0e",
            "5e6051c5b169414d86c84ab14f04a7fa",
            "b9cb1f3585fa4829af35b847a7bf0c7d",
            "6db86b823d5945709f19652c02c24d5c",
            "32560d95ff17457aa62662719d9281f7",
            "4f95af22ced84f8a9ad9104ae01b41ef",
            "58afbfa917074b5bb08a8821ef4c276a",
            "93243101441e408e9791a830b4ec4a45",
            "cdc6dd5188054427b360cb93162835b0",
            "959059f4bb8b4adc8fcabbe6397397db",
            "ff7fdfc0519b474e8e31a926059bde02",
            "da0d1133dea048068754c5d50f57887a",
            "50e9cd71db554ee4b8ba4708726aed1b",
            "10c48c4d082349209e80550ae839d951",
            "7399e5f71ae0468b87807e54c08a3667",
            "b9c5eb1783c84a3aa2ad4998ea9a84d8",
            "b23fd39780da48e6918603333629a1cf",
            "a76575a27c7246328aaf14deaf86ef1f",
            "715b8dc5a61e41aea4799250add4aad0",
            "adfe3e2bb82741f588323a280dbe89db",
            "c979539f796941838bde7c4def0308a1"
          ]
        },
        "id": "ZA9NtvkU-wOd",
        "outputId": "fc4a4803-a84f-4b07-d484-cb50491da699"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "yolox_l0.05.onnx:   0%|          | 0.00/217M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57005feab5c144d2a2520d7a072ec4b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8f86b6c93c949919535e477b64ae1ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa454f8569f644a3862ff4f92f7711c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/115M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90d8adff903b47ccb9f8d057f38db5cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff7fdfc0519b474e8e31a926059bde02"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(elements)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XROWMCGB-wRk",
        "outputId": "ef7f05a6-19c1-4541-c64b-bb57dd594358"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "element_dict = [el.to_dict() for el in elements]\n",
        "output = json.dumps(element_dict, indent=2)\n",
        "print(output)\n",
        "\n",
        "unique_types = set()\n",
        "\n",
        "for item in element_dict:\n",
        "    unique_types.add(item['type'])\n",
        "\n",
        "print(unique_types)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0jUEtHc-wUE",
        "outputId": "428955da-cb64-47dc-b0a1-e2e3cd13ec8a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"type\": \"Header\",\n",
            "    \"element_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
            "    \"text\": \"2311.04931v1 [cs.CL] 6 Nov 2023\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.4232133626937866,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            184.92478942871094,\n",
            "            742.0810546875\n",
            "          ],\n",
            "          [\n",
            "            184.92478942871094,\n",
            "            1471.5084228515625\n",
            "          ],\n",
            "          [\n",
            "            232.85177612304688,\n",
            "            1471.5084228515625\n",
            "          ],\n",
            "          [\n",
            "            232.85177612304688,\n",
            "            742.0810546875\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"e4fe3bbb0809b51d59fa5c6d32240053\",\n",
            "    \"text\": \"arXiv\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            187.0,\n",
            "            1422.0\n",
            "          ],\n",
            "          [\n",
            "            187.0,\n",
            "            1526.0\n",
            "          ],\n",
            "          [\n",
            "            220.0,\n",
            "            1526.0\n",
            "          ],\n",
            "          [\n",
            "            220.0,\n",
            "            1422.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"aa5e7c4eb5afd8a6a701200d14d0c5c1\",\n",
            "    \"text\": \"GPT4AIl: An Ecosystem of Open Source Compressed Language Models\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.4024123251438141,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            330.05194091796875,\n",
            "            281.6643371582031\n",
            "          ],\n",
            "          [\n",
            "            330.05194091796875,\n",
            "            311.5008544921875\n",
            "          ],\n",
            "          [\n",
            "            1365.037353515625,\n",
            "            311.5008544921875\n",
            "          ],\n",
            "          [\n",
            "            1365.037353515625,\n",
            "            281.6643371582031\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"3b6229680e5b76a64d828388fc9558af\",\n",
            "    \"text\": \"Yuvanesh Anand Nomic AI yuvanesh@nomic.ai\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.4871159791946411,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            311.67401123046875,\n",
            "            351.6892395019531\n",
            "          ],\n",
            "          [\n",
            "            311.67401123046875,\n",
            "            446.8622131347656\n",
            "          ],\n",
            "          [\n",
            "            552.476318359375,\n",
            "            446.8622131347656\n",
            "          ],\n",
            "          [\n",
            "            552.476318359375,\n",
            "            351.6892395019531\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"aa5e7c4eb5afd8a6a701200d14d0c5c1\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"2b31179eb0e5f5f7d85c9fb0cb5b961e\",\n",
            "    \"text\": \"Zach Nussbaum Nomic AI zach@nomic. ai\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.469629168510437,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            618.5408935546875,\n",
            "            356.0069580078125\n",
            "          ],\n",
            "          [\n",
            "            618.5408935546875,\n",
            "            448.8507995605469\n",
            "          ],\n",
            "          [\n",
            "            798.0371704101562,\n",
            "            448.8507995605469\n",
            "          ],\n",
            "          [\n",
            "            798.0371704101562,\n",
            "            356.0069580078125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"aa5e7c4eb5afd8a6a701200d14d0c5c1\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"7a7d1c29b06a89db7c7ee29e70877278\",\n",
            "    \"text\": \"Adam Treat Nomic AI adam@nomic. ai\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.4653831422328949,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            904.9122314453125,\n",
            "            356.7784423828125\n",
            "          ],\n",
            "          [\n",
            "            904.9122314453125,\n",
            "            450.34698486328125\n",
            "          ],\n",
            "          [\n",
            "            1080.4359130859375,\n",
            "            450.34698486328125\n",
            "          ],\n",
            "          [\n",
            "            1080.4359130859375,\n",
            "            356.7784423828125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"aa5e7c4eb5afd8a6a701200d14d0c5c1\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"7db0b87ebaf95200e60899e7b95899a4\",\n",
            "    \"text\": \"Aaron Miller Nomic AI aaron@nomic.ai\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.5281911492347717,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            1178.643310546875,\n",
            "            357.61138916015625\n",
            "          ],\n",
            "          [\n",
            "            1178.643310546875,\n",
            "            449.8150939941406\n",
            "          ],\n",
            "          [\n",
            "            1368.121826171875,\n",
            "            449.8150939941406\n",
            "          ],\n",
            "          [\n",
            "            1368.121826171875,\n",
            "            357.61138916015625\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"aa5e7c4eb5afd8a6a701200d14d0c5c1\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"03b1afbbb44842034b8293706639f7cd\",\n",
            "    \"text\": \"Richard Guo Nomic AI richard@nomic. ai\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.5810609459877014,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            386.0674743652344,\n",
            "            504.1565246582031\n",
            "          ],\n",
            "          [\n",
            "            386.0674743652344,\n",
            "            597.4337768554688\n",
            "          ],\n",
            "          [\n",
            "            605.2667846679688,\n",
            "            597.4337768554688\n",
            "          ],\n",
            "          [\n",
            "            605.2667846679688,\n",
            "            504.1565246582031\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"aa5e7c4eb5afd8a6a701200d14d0c5c1\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"982987ea2abb7d1d9ec3c815deec5dd1\",\n",
            "    \"text\": \"Ben Schmidt Nomic AI ben@nomic. ai\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.6449708938598633,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            764.7431640625,\n",
            "            508.09454345703125\n",
            "          ],\n",
            "          [\n",
            "            764.7431640625,\n",
            "            600.0762329101562\n",
            "          ],\n",
            "          [\n",
            "            935.64404296875,\n",
            "            600.0762329101562\n",
            "          ],\n",
            "          [\n",
            "            935.64404296875,\n",
            "            508.09454345703125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"aa5e7c4eb5afd8a6a701200d14d0c5c1\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"941dd02cd64fc418c67f37ecd7447eaf\",\n",
            "    \"text\": \"GPT4AIl Community Planet Earth\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.5254923105239868,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            1093.162353515625,\n",
            "            508.01739501953125\n",
            "          ],\n",
            "          [\n",
            "            1093.162353515625,\n",
            "            567.9408569335938\n",
            "          ],\n",
            "          [\n",
            "            1310.8515625,\n",
            "            567.9408569335938\n",
            "          ],\n",
            "          [\n",
            "            1310.8515625,\n",
            "            508.01739501953125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"aa5e7c4eb5afd8a6a701200d14d0c5c1\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"6ec733c3e3a00bcc21fa6f20cab5d532\",\n",
            "    \"text\": \"Brandon Duderstadt* Nomic AI brandon@nomic. ai\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.4401948153972626,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            495.36895751953125,\n",
            "            655.016845703125\n",
            "          ],\n",
            "          [\n",
            "            495.36895751953125,\n",
            "            748.2459106445312\n",
            "          ],\n",
            "          [\n",
            "            741.5177612304688,\n",
            "            748.2459106445312\n",
            "          ],\n",
            "          [\n",
            "            741.5177612304688,\n",
            "            655.016845703125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"aa5e7c4eb5afd8a6a701200d14d0c5c1\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"e73b527ae3de7105c066be325e6e3457\",\n",
            "    \"text\": \"Andriy Mulyar* Nomic AI andriy@nomic.ai\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.6033192873001099,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            977.3466796875,\n",
            "            657.3770141601562\n",
            "          ],\n",
            "          [\n",
            "            977.3466796875,\n",
            "            748.8932495117188\n",
            "          ],\n",
            "          [\n",
            "            1193.7236328125,\n",
            "            748.8932495117188\n",
            "          ],\n",
            "          [\n",
            "            1193.7236328125,\n",
            "            657.3770141601562\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"aa5e7c4eb5afd8a6a701200d14d0c5c1\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"d45b444f1e80dd600069b7da09cee282\",\n",
            "    \"text\": \"Abstract\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            509.0,\n",
            "            813.0\n",
            "          ],\n",
            "          [\n",
            "            509.0,\n",
            "            847.0\n",
            "          ],\n",
            "          [\n",
            "            627.0,\n",
            "            847.0\n",
            "          ],\n",
            "          [\n",
            "            627.0,\n",
            "            813.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"db9aa1d8179cc3192d44f5a90f3b1826\",\n",
            "    \"text\": \"Large language models (LLMs) have recently achieved human-level performance on a range of professional and academic benchmarks. The accessibility of these models has lagged behind their performance. State-of-the-art LLMs re- quire costly infrastructure; are only accessible via rate-limited, geo-locked, and censored web interfaces; and lack publicly available code and technical reports.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9393344521522522,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            356.5932312011719,\n",
            "            878.8330078125\n",
            "          ],\n",
            "          [\n",
            "            356.5932312011719,\n",
            "            1126.6077880859375\n",
            "          ],\n",
            "          [\n",
            "            795.5685424804688,\n",
            "            1126.6077880859375\n",
            "          ],\n",
            "          [\n",
            "            795.5685424804688,\n",
            "            878.8330078125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"d45b444f1e80dd600069b7da09cee282\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"36ed8f41aa2fe1874422c75d79b033a8\",\n",
            "    \"text\": \"variety of queries, responding only with the now infa- mous \\\"As an AI Language Model, I cannot...\\\" prefix (Vincent, 2023). These transparency and accessibility concerns spurred several developers to begin creating open source large language model (LLM) alternatives. Several grassroots efforts focused on fine tuning Meta\\u2019s open code LLaMA model (Touvron et al., 2023; McMil- lan, 2023), whose weights were leaked on BitTorrent less than_a week prior to the release of GPT-4 (Verge, 2023). GIJT4All started as one of these variants.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9476661086082458,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            870.2737426757812,\n",
            "            822.445556640625\n",
            "          ],\n",
            "          [\n",
            "            870.2737426757812,\n",
            "            1094.8389892578125\n",
            "          ],\n",
            "          [\n",
            "            1389.4317626953125,\n",
            "            1094.8389892578125\n",
            "          ],\n",
            "          [\n",
            "            1389.4317626953125,\n",
            "            822.445556640625\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"d45b444f1e80dd600069b7da09cee282\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"3a41b9635b90a4dfd4b38b911c6a9da8\",\n",
            "    \"text\": \"In this paper, we tell the story of GPT4All, a popular open source repository that aims to democratize access to LLMs. We outline the technical details of the original GPT4AII mode] family, as well as the evolution of the GPT4Al] project from a single model into a fully fledged open source ecosystem. It is our hope that this paper acts as both a technical overview of the original GPT4Al models as well as a case study on the subsequent growth of the GPT4AI] open source ecosystem.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9432600736618042,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            353.97564697265625,\n",
            "            1145.4993896484375\n",
            "          ],\n",
            "          [\n",
            "            353.97564697265625,\n",
            "            1450.2889404296875\n",
            "          ],\n",
            "          [\n",
            "            797.5936279296875,\n",
            "            1450.2889404296875\n",
            "          ],\n",
            "          [\n",
            "            797.5936279296875,\n",
            "            1145.4993896484375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"d45b444f1e80dd600069b7da09cee282\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"6667a156554994f45ec82307a8aa06ad\",\n",
            "    \"text\": \"In thiASaper, we tell the story of GPT4AlI. We com- ment on the technical details of the original GPT4Al model (Anand et al., 2023), as well as the evolution of GPT4AIl from a single model to an ecosystem of several models. We remark on the impact that the project has had on the open source community, and discuss future directions. It is our hope that this paper acts as both a technical overview of the original GPT4Al] models as well as a case study on the subsequent growth of the GPT4All open source ecosystem.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9492384195327759,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            869.2228393554688,\n",
            "            1103.26123046875\n",
            "          ],\n",
            "          [\n",
            "            869.2228393554688,\n",
            "            1378.0030517578125\n",
            "          ],\n",
            "          [\n",
            "            1391.366943359375,\n",
            "            1378.0030517578125\n",
            "          ],\n",
            "          [\n",
            "            1391.366943359375,\n",
            "            1103.26123046875\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"d45b444f1e80dd600069b7da09cee282\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"af5ffcc37642b9d2d0e99532ecb0c4ac\",\n",
            "    \"text\": \"2 The Original GPT4AII Model\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8576385378837585,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            869.8643798828125,\n",
            "            1414.04638671875\n",
            "          ],\n",
            "          [\n",
            "            869.8643798828125,\n",
            "            1437.1588134765625\n",
            "          ],\n",
            "          [\n",
            "            1267.4658203125,\n",
            "            1437.1588134765625\n",
            "          ],\n",
            "          [\n",
            "            1267.4658203125,\n",
            "            1414.04638671875\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"b86fb3cfbb2562fe20ae819e41db4f63\",\n",
            "    \"text\": \"2.1 Data Collection and Curation\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8208933472633362,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            869.8379516601562,\n",
            "            1464.2177734375\n",
            "          ],\n",
            "          [\n",
            "            869.8379516601562,\n",
            "            1484.450439453125\n",
            "          ],\n",
            "          [\n",
            "            1219.3873291015625,\n",
            "            1484.450439453125\n",
            "          ],\n",
            "          [\n",
            "            1219.3873291015625,\n",
            "            1464.2177734375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"1a2527f9f828de968622402594415f33\",\n",
            "    \"text\": \"1 Introduction\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.835685133934021,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            313.1302185058594,\n",
            "            1491.400146484375\n",
            "          ],\n",
            "          [\n",
            "            313.1302185058594,\n",
            "            1519.2489013671875\n",
            "          ],\n",
            "          [\n",
            "            507.8752136230469,\n",
            "            1519.2489013671875\n",
            "          ],\n",
            "          [\n",
            "            507.8752136230469,\n",
            "            1491.400146484375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"103d30241b8f4f33440cde2f8c062ed1\",\n",
            "    \"text\": \"On March 14 2023, OpenAI released GPT-4, a large language model capable of achieving human level per- formance on a yariety of professional and academic benchmarks. Despite the popularity of the release, the GPT-4 technical report (OpenAl, 2023) contained virtually no details regarding the architecture, hard- ware, training compute, dataset construction, or training method used to create the model, Moreover, users could only access the model through the internet interface at chat.openai.com, which was severely rate limited and unavailable in several locales (e.g. Italy) (BBC News, 2023). Additionally, GPT-4 refused to answer a wide\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9468173980712891,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            308.257568359375,\n",
            "            1541.1007080078125\n",
            "          ],\n",
            "          [\n",
            "            308.257568359375,\n",
            "            1883.820068359375\n",
            "          ],\n",
            "          [\n",
            "            837.3360595703125,\n",
            "            1883.820068359375\n",
            "          ],\n",
            "          [\n",
            "            837.3360595703125,\n",
            "            1541.1007080078125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"1a2527f9f828de968622402594415f33\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"8d8277c86b679fcbadd288f1bacdf824\",\n",
            "    \"text\": \"To train the original GPT4All model, we collected roughly one million prompt-response pairs using the GPT-3,5-Turbo OpenAI API between March 20, 2023 and March 26th, 2023, In particular, we gathered GPT- 3.5-Turbo responses to prompts of three publicly avail- able datasets: the unified chip2 subset of LAION OIG, a random sub-sample of Stackoverflow Questions, and a sub-sample of Bigscience/P3 (Sanh et al., 2021). Fol- lowing the approach in Stanford Alpaca (Taori et al., 2023), an open source LLaMA variant that came just be- fore GPT4AIl, we focused substantial effort on dataset curation,\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9404544234275818,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            869.7801513671875,\n",
            "            1503.2587890625\n",
            "          ],\n",
            "          [\n",
            "            869.7801513671875,\n",
            "            1841.6685791015625\n",
            "          ],\n",
            "          [\n",
            "            1397.6998291015625,\n",
            "            1841.6685791015625\n",
            "          ],\n",
            "          [\n",
            "            1397.6998291015625,\n",
            "            1503.2587890625\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"1a2527f9f828de968622402594415f33\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"655e1b7d92cbf6324e65f613100aa570\",\n",
            "    \"text\": \"* Shared Senior Authorship\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.6288466453552246,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            336.6943359375,\n",
            "            1913.42529296875\n",
            "          ],\n",
            "          [\n",
            "            336.6943359375,\n",
            "            1933.592529296875\n",
            "          ],\n",
            "          [\n",
            "            565.4310913085938,\n",
            "            1933.592529296875\n",
            "          ],\n",
            "          [\n",
            "            565.4310913085938,\n",
            "            1913.42529296875\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"1a2527f9f828de968622402594415f33\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"acb228dd280ec3e448618148ec7de215\",\n",
            "    \"text\": \"The collected dataset was loaded into Atlas (Al, 2023)\\u2014a visual interface for exploring and tagging mas sive unstructured datasets \\u2014for data curation, Using At\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9268862009048462,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            871.0282592773438,\n",
            "            1849.0352783203125\n",
            "          ],\n",
            "          [\n",
            "            871.0282592773438,\n",
            "            1929.71435546875\n",
            "          ],\n",
            "          [\n",
            "            1394.6534423828125,\n",
            "            1929.71435546875\n",
            "          ],\n",
            "          [\n",
            "            1394.6534423828125,\n",
            "            1849.0352783203125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 1,\n",
            "      \"parent_id\": \"1a2527f9f828de968622402594415f33\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"9f9c38708322ca2ad595d06e8dce7f36\",\n",
            "    \"text\": \"las, we identified and removed subsets of the data where GPT-3.5-Turbo refused to respond, had malformed out- put, or produced a very short response. This resulted in the removal of the entire Bigscience/P3 subset of our data, as many P3 prompts induced responses that were simply one word. After curation, we were left with a set of 437,605 prompt-response pairs, which we visualize in Figure 1a.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9441847205162048,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            320.8945617675781,\n",
            "            259.8636474609375\n",
            "          ],\n",
            "          [\n",
            "            320.8945617675781,\n",
            "            484.81048583984375\n",
            "          ],\n",
            "          [\n",
            "            838.0132446289062,\n",
            "            484.81048583984375\n",
            "          ],\n",
            "          [\n",
            "            838.0132446289062,\n",
            "            259.8636474609375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"1a2527f9f828de968622402594415f33\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"9d7097ade60591eb70584599d4462684\",\n",
            "    \"text\": \"2.2. Model Training\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8165757060050964,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            321.9754638671875,\n",
            "            508.0442199707031\n",
            "          ],\n",
            "          [\n",
            "            321.9754638671875,\n",
            "            534.4871215820312\n",
            "          ],\n",
            "          [\n",
            "            534.75830078125,\n",
            "            534.4871215820312\n",
            "          ],\n",
            "          [\n",
            "            534.75830078125,\n",
            "            508.0442199707031\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"bf370cf310c8b4025edf6daf794976f0\",\n",
            "    \"text\": \"The original GPT4AI1 model was a fine tuned variant\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.5734759569168091,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            319.71484375,\n",
            "            550.2962646484375\n",
            "          ],\n",
            "          [\n",
            "            319.71484375,\n",
            "            573.5416259765625\n",
            "          ],\n",
            "          [\n",
            "            833.6873779296875,\n",
            "            573.5416259765625\n",
            "          ],\n",
            "          [\n",
            "            833.6873779296875,\n",
            "            550.2962646484375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"9d7097ade60591eb70584599d4462684\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"56a086f1f788c38f50b1466182cb5b0a\",\n",
            "    \"text\": \"of LLaMA 7B. In order to train it more efficiently, we froze the base weights of LLaMA, and only trained a small set of LoRA (Hu et al., 2021) weights during the fine tuning process. Detailed model hyper-parameters and training code can be found in our associated code repository\\u2019.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8686404228210449,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            290.8384704589844,\n",
            "            579.4189453125\n",
            "          ],\n",
            "          [\n",
            "            290.8384704589844,\n",
            "            742.62060546875\n",
            "          ],\n",
            "          [\n",
            "            855.4991455078125,\n",
            "            742.62060546875\n",
            "          ],\n",
            "          [\n",
            "            855.4991455078125,\n",
            "            579.4189453125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"9d7097ade60591eb70584599d4462684\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"bb0dd3bd181d33c79cb8e6e1b63e5e22\",\n",
            "    \"text\": \"2.3. Model Access\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8413587808609009,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            323.1849670410156,\n",
            "            764.8734130859375\n",
            "          ],\n",
            "          [\n",
            "            323.1849670410156,\n",
            "            791.444580078125\n",
            "          ],\n",
            "          [\n",
            "            513.9146118164062,\n",
            "            791.444580078125\n",
            "          ],\n",
            "          [\n",
            "            513.9146118164062,\n",
            "            764.8734130859375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"838e5a807702b27e299c0c3343d2cce4\",\n",
            "    \"text\": \"We publicly released all data, training code, and model weights for the community to build upon. Further, we provided a 4-bit quantized version of the model, which enabled users to run it on their own commodity hard- ware without transferring data to a 3rd party service.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9317830801010132,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            319.9345703125,\n",
            "            807.614990234375\n",
            "          ],\n",
            "          [\n",
            "            319.9345703125,\n",
            "            941.8294677734375\n",
            "          ],\n",
            "          [\n",
            "            845.7492065429688,\n",
            "            941.8294677734375\n",
            "          ],\n",
            "          [\n",
            "            845.7492065429688,\n",
            "            807.614990234375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"bb0dd3bd181d33c79cb8e6e1b63e5e22\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"9bfdc2ba1ef989b79da304187cb93eef\",\n",
            "    \"text\": \"Our research and development costs were dominated by ~$800 in GPU spend (rented from Lambda Labs and Paperspace) and ~$500 in OpenAl API spend. Our final GPT4AII model could be trained in about eight hours ona Lambda Labs DGX A100 8x 80GB for a total cost of ~$100.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9430202841758728,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            322.70880126953125,\n",
            "            948.4578857421875\n",
            "          ],\n",
            "          [\n",
            "            322.70880126953125,\n",
            "            1109.8153076171875\n",
            "          ],\n",
            "          [\n",
            "            835.965576171875,\n",
            "            1109.8153076171875\n",
            "          ],\n",
            "          [\n",
            "            835.965576171875,\n",
            "            948.4578857421875\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"bb0dd3bd181d33c79cb8e6e1b63e5e22\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"cdcd35e68cd19d4dd4f635cec9abcebe\",\n",
            "    \"text\": \"2.4 Model Evaluation\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8239712715148926,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            323.6431884765625,\n",
            "            1135.2135009765625\n",
            "          ],\n",
            "          [\n",
            "            323.6431884765625,\n",
            "            1159.323486328125\n",
            "          ],\n",
            "          [\n",
            "            556.37451171875,\n",
            "            1159.323486328125\n",
            "          ],\n",
            "          [\n",
            "            556.37451171875,\n",
            "            1135.2135009765625\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"2af07e90c36a648bfb48f13316102955\",\n",
            "    \"text\": \"We performed a preliminary evaluation of our model using the human evaluation data from the Self Instruct paper (Wang et al., 2023). We reported the ground truth perplexity of our model against what was, to our knowl- edge, the best openly available alpaca-lora model at the time, provided by user chainyo on HuggingFace. Both models had very large perplexities on a small number of tasks, so we reported perplexities clipped to a maximum of 100, We found that GPT4All produces stochastically lower ground truth perplexitics than alpaca-lora (Anand et al., 2023).\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9474015235900879,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            321.9371643066406,\n",
            "            1175.1939697265625\n",
            "          ],\n",
            "          [\n",
            "            321.9371643066406,\n",
            "            1475.82763671875\n",
            "          ],\n",
            "          [\n",
            "            837.9116821289062,\n",
            "            1475.82763671875\n",
            "          ],\n",
            "          [\n",
            "            837.9116821289062,\n",
            "            1175.1939697265625\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"cdcd35e68cd19d4dd4f635cec9abcebe\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"6f4f90867d8d04875180aca00689cedf\",\n",
            "    \"text\": \"3 From a Model to an Ecosystem\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.7870762348175049,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            317.7433776855469,\n",
            "            1504.808837890625\n",
            "          ],\n",
            "          [\n",
            "            317.7433776855469,\n",
            "            1534.271728515625\n",
            "          ],\n",
            "          [\n",
            "            736.4494018554688,\n",
            "            1534.271728515625\n",
            "          ],\n",
            "          [\n",
            "            736.4494018554688,\n",
            "            1504.808837890625\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"cdcd35e68cd19d4dd4f635cec9abcebe\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"fdba4511020a50b8ae796b8cbf3e3b09\",\n",
            "    \"text\": \"3.1 GPT4AII-J: Repository Growth and the implications of the LLaMA License\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.7292912602424622,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            317.25811767578125,\n",
            "            1554.0673828125\n",
            "          ],\n",
            "          [\n",
            "            317.25811767578125,\n",
            "            1605.45361328125\n",
            "          ],\n",
            "          [\n",
            "            770.439453125,\n",
            "            1605.45361328125\n",
            "          ],\n",
            "          [\n",
            "            770.439453125,\n",
            "            1554.0673828125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"cdcd35e68cd19d4dd4f635cec9abcebe\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"c62cc0eeee4bf18104e4fa92e557cd4f\",\n",
            "    \"text\": \"The GPT4AIl repository grew rapidly after its release, gaining over 20000 GitHub stars in just one week, as shown in Figure 2. This growth was supported by an in-person hackathon hosted in New York City three days after the model release, which attracted several hundred participants, As the Nomic discord, the home of online discussion about GPT4AII, ballooned to over 10000 people, one thing became very clear - there was massive demand for a model that could be used commercially\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9447706937789917,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            317.32763671875,\n",
            "            1620.1363525390625\n",
            "          ],\n",
            "          [\n",
            "            317.32763671875,\n",
            "            1871.9107666015625\n",
            "          ],\n",
            "          [\n",
            "            835.9295043945312,\n",
            "            1871.9107666015625\n",
            "          ],\n",
            "          [\n",
            "            835.9295043945312,\n",
            "            1620.1363525390625\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"cdcd35e68cd19d4dd4f635cec9abcebe\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"3d76b9feebb0c6f79568254ff74ab2f0\",\n",
            "    \"text\": \"hups://github.com/nomic-ai/gpttall\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.7074752449989319,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            344.36578369140625,\n",
            "            1894.2257080078125\n",
            "          ],\n",
            "          [\n",
            "            344.36578369140625,\n",
            "            1915.5667724609375\n",
            "          ],\n",
            "          [\n",
            "            627.6140747070312,\n",
            "            1915.5667724609375\n",
            "          ],\n",
            "          [\n",
            "            627.6140747070312,\n",
            "            1894.2257080078125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"cdcd35e68cd19d4dd4f635cec9abcebe\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"857e0eaf55376e282404d4ad1b14152d\",\n",
            "    \"text\": \"The LLaMA model that GPT4AII was based on was licensed for research only, which severely limited the set of domains that GPT4AII could be applied in. As a response to this, the Nomic team repeated the model training procedure of the original GPT4AII model, but based on the already open source and commercially li- censed GPT-J model (Wang and Komatsuzaki, 2021). GPT4AII-J also had an augmented training set, which contained multi-tum QA examples and creative writing such as poetry, rap, and short stories. The creative writ- ing prompts were generated by filling in schemas such as \\\"Write a [CREATIVE STORY TYPE] about [NOUN] in the style of [PERSON].\\\" We again employed Atlas to curate the prompt-response pairs in this data set.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9396345019340515,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            872.7468872070312,\n",
            "            267.03472900390625\n",
            "          ],\n",
            "          [\n",
            "            872.7468872070312,\n",
            "            662.8563842773438\n",
            "          ],\n",
            "          [\n",
            "            1393.45947265625,\n",
            "            662.8563842773438\n",
            "          ],\n",
            "          [\n",
            "            1393.45947265625,\n",
            "            267.03472900390625\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"cdcd35e68cd19d4dd4f635cec9abcebe\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"5e45065b9e6ca1ea3c7ab2299aeda506\",\n",
            "    \"text\": \"Our evaluation methodology also evolved as the project grew. In particular, we began evaluating GPT4All models using a suite of seven reasoning tasks that were used for evaluation of the Databricks Dolly (Conover et al., 2023b) model, which was re- leased on April 12, 2023. Unfortunately, GPT4AII-J did not outperform other prominent open source models on this evaluation. As a result, we endeavoured to create a model that did,\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9483440518379211,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            872.5713500976562,\n",
            "            670.2465209960938\n",
            "          ],\n",
            "          [\n",
            "            872.5713500976562,\n",
            "            915.9075317382812\n",
            "          ],\n",
            "          [\n",
            "            1389.849609375,\n",
            "            915.9075317382812\n",
            "          ],\n",
            "          [\n",
            "            1389.849609375,\n",
            "            670.2465209960938\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"cdcd35e68cd19d4dd4f635cec9abcebe\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"cecbb16941932a87be2fe18464a7a384\",\n",
            "    \"text\": \"3.2. GPT4All-Snoozy: the Emergence of the GPT4All Ecosystem\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8794780969619751,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            874.1194458007812,\n",
            "            949.46826171875\n",
            "          ],\n",
            "          [\n",
            "            874.1194458007812,\n",
            "            995.743896484375\n",
            "          ],\n",
            "          [\n",
            "            1322.0965576171875,\n",
            "            995.743896484375\n",
            "          ],\n",
            "          [\n",
            "            1322.0965576171875,\n",
            "            949.46826171875\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"a869aab3955b4fe902314d9fe048185e\",\n",
            "    \"text\": \"GPT4All-Snoozy was developed using roughly the same procedure as the previous GPT4AIl models, but with a few key modifications. First, GPT4All-Snoozy used the LLaMA-13B base mcs due to its superior base metrics when compared to orf Next, GPT4All-Snoozy incor- porated the Dolly\\u2019s traifing data into its train mix. After data curation and deduplication with Atlas, this yielded a training set of 739,259 total prompt-response pairs. We dubbed the model that resulted from training on this improved dataset GPT4AIl-Snoozy. As shown in Figure 1, GPT4All-Snoozy had the best average score on our evaluation benchmark of any model in the ecosystem at the time of its release.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9439041018486023,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            870.1834716796875,\n",
            "            1017.2853393554688\n",
            "          ],\n",
            "          [\n",
            "            870.1834716796875,\n",
            "            1374.783935546875\n",
            "          ],\n",
            "          [\n",
            "            1387.443359375,\n",
            "            1374.783935546875\n",
            "          ],\n",
            "          [\n",
            "            1387.443359375,\n",
            "            1017.2853393554688\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"cecbb16941932a87be2fe18464a7a384\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"1368ebb4388da5cdcba87ba9a64bde1f\",\n",
            "    \"text\": \"Concurrently with the development of GPT4AI, sev- eral organizations such as LMSys, Stability Al, BAIR, and Databricks built and deployed open source language models, We heard increasingly from the community that they wanted quantized versions of these models for local use. As we realized that organizations with ever more resources were developing source language models, we decided to pivot our effort away from training increas: ingly capable models and towards providing easy access to the plethora of models being produced by the open source community. Practically, this meant spending our time compressing open source models for use on com- modity hardware, providing stable and simple high level model APIs, and supporting a GUI for no code model experimentation\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9415037631988525,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            867.2464599609375,\n",
            "            1383.7464599609375\n",
            "          ],\n",
            "          [\n",
            "            867.2464599609375,\n",
            "            1799.5350341796875\n",
            "          ],\n",
            "          [\n",
            "            1384.6209716796875,\n",
            "            1799.5350341796875\n",
            "          ],\n",
            "          [\n",
            "            1384.6209716796875,\n",
            "            1383.7464599609375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"cecbb16941932a87be2fe18464a7a384\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"7f1ded200b1c8ecc2226d7fda79a94e6\",\n",
            "    \"text\": \"33\\u00b0 The Current State of GPT4AlL\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8186454176902771,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            864.1806640625,\n",
            "            1828.4063720703125\n",
            "          ],\n",
            "          [\n",
            "            864.1806640625,\n",
            "            1853.010986328125\n",
            "          ],\n",
            "          [\n",
            "            1225.5865478515625,\n",
            "            1853.010986328125\n",
            "          ],\n",
            "          [\n",
            "            1225.5865478515625,\n",
            "            1828.4063720703125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"2d36d8b847abbb8c43bb7ccc1ca04abb\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"80a41a3c652cbb6c144502f8e407a1b1\",\n",
            "    \"text\": \"Today, GPT4AI1 is focused on improving the accessi bility of open source language models. The repository\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.905586838722229,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            861.33203125,\n",
            "            1870.272216796875\n",
            "          ],\n",
            "          [\n",
            "            861.33203125,\n",
            "            1922.2794189453125\n",
            "          ],\n",
            "          [\n",
            "            1385.8746337890625,\n",
            "            1922.2794189453125\n",
            "          ],\n",
            "          [\n",
            "            1385.8746337890625,\n",
            "            1870.272216796875\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 2,\n",
            "      \"parent_id\": \"7f1ded200b1c8ecc2226d7fda79a94e6\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Image\",\n",
            "    \"element_id\": \"583893028def4f6b9b760a521a2d550d\",\n",
            "    \"text\": \"@) (b) (\\u00a9) (d)\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.84317547082901,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            247.09678649902344,\n",
            "            265.791259765625\n",
            "          ],\n",
            "          [\n",
            "            247.09678649902344,\n",
            "            547.1163940429688\n",
            "          ],\n",
            "          [\n",
            "            1355.7847900390625,\n",
            "            547.1163940429688\n",
            "          ],\n",
            "          [\n",
            "            1355.7847900390625,\n",
            "            265.791259765625\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 3,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"FigureCaption\",\n",
            "    \"element_id\": \"e134e4782987530cad118447d806ce4a\",\n",
            "    \"text\": \"Figure 1: TSNE visualizations showing the progression of the GPT4AII train set. Panel (a) shows the original uncurated data, The red arrow denotes a region of highly homogeneous prompt-response pairs. The coloring denotes which open dataset contributed the prompt. Panel (b) shows the original GPT4AlI data after curation. This panel, as well as panels (c) and (d) are 10 colored by topic, which Atlas automatically extracts. Notice that the large homogeneous prompt-response blobs no longer appearl. Panel (c) shows the GPT4AlIlI-J dataset. The \\\"starburst\\\" clusters introduced on the right side of the panel correspond to the newly added creative data. Panel (d) shows the final GPT4All-snoozy dataset. All datasets have been released to the public, and can be interactively explored online. In the web version of this article, you can click on a panel to be taken to its interactive visualization.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.928982675075531,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            301.1387023925781,\n",
            "            575.5286865234375\n",
            "          ],\n",
            "          [\n",
            "            301.1387023925781,\n",
            "            794.4069213867188\n",
            "          ],\n",
            "          [\n",
            "            1386.0469970703125,\n",
            "            794.4069213867188\n",
            "          ],\n",
            "          [\n",
            "            1386.0469970703125,\n",
            "            575.5286865234375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 3,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Table\",\n",
            "    \"element_id\": \"8ad44ca09461bffe5911992317f925f7\",\n",
            "    \"text\": \"Model BoolQ PIQA HellaSwag WinoG. ARC-c ARC-c OBQA Avg. GPT4AII-J 6B v1.0* 73.4 74.8 634 64.7 54.9 36 40.2 58.2 GPT4AII-J v1.1-breezy* 74 75.1 63.2 63.6 55.4 34.9 38.4 57.8 GPT4AIIL-J v1.2-jazzy* 74.8 74.9 63.6 638 56.6 35.3 41 58.6 GPT4AII-J v1.3-groovy* 73.6 74.3 63.8 63.5 57.7 35 38.8 \\u00a9 58.1 GPT4AII-J Lora 6B* 68.6 75.8 66.2 63.5 56.4 35.7 402 58.1 GPT4All LLaMa Lora 7B* 73.1 77.6 721 67.8 SIE 40.4 40.2 60.3 GPT4All 13B snoozy* 83.3 79.2 75 71.3 60.9 44.2 43.4 65.3 GPT4AIl Falcon 71.6 79.8 749 70.1 67.9 4B4 42.6 65.2 Nous-Hermes (Nous-Research, 2023b) 79.5 78.9 80 19 74.2 50.9 64 68.3 Nous-Hermes2 (Nous-Research, 2023c) 83.9 80.7 80.1 71.3 75.7 52.1 46.2 70.0 Nous-Puffin (Nous-Research, 2023d) 815 80.7 80.4 72.5 771.6 50.7 45.6 69.9 Dolly 6B* (Conover et al., 2023a) 68.8 71.3 67.6 63.9 62.9 38.7 412 1 Dolly 12B* (Conover et al., 2023) 56.7 75.4 1 62.2 64.6 38.5 404 584 Alpaca 7B* (Taori et al. , 2023) 73.9 TT 73.9 66.1 59.8 43.3 434 62.5 Alpaca Lora 7B* Wang. 2023) 94325793 74 68.8 56.6 43.9 426 628 GPT-J* 6.7B (Wang and Komatsuzaki, 2021) 654 76.2 66.2 64.1 62.2 36.6 38.2 58.4 LLama 7B* (Touvron et al., 2023) 73.1 714 13 66.9 52.5 414 42.4 61.0 LLama 13B* (Touvron et al_, 2023) 68.5 79.1 76.2 70.1 60 44.6 422 63.0 Pythia 6.7B* (Biderman et al., 2023) 63.5 76.3 64 61.1 61.3 35.2 37.2 56.9 Pythia 12B* (Biderman et al., 2023) 67.7 16.6 67.3 63.8 63.9 34.8 38 58.9 Fastchat TS* (Zheng et al., 2023) 815 64.6 46.3 618 49.3 (33.2. 39.4 53.7 Fastchat Vicufia* 7B (Zheng et al., 2023) 76.6 77.2 70.7 67.3 53.5 41.2 40.8 61.0 Fastchat Vicufia 13B* (Zheng et al., 2023) 815 76.8 73.3 66.7 57.4 42.7 3.6 63.1 Stable Vicufia RLHF* (Stability-Al, 2023) 82.3 78.6 74.1 70.9 61 43.5 444 65.0 StableLM Tuned* (Stability-Al, 2023) 625 71.2 53.6 54.8 52.4 31 33.4 SUS StableLM Base* (Stability-Al, 2023) 60.1 67.4 412 50.1 44.9 27 32 46.1 Koala 13B* (Geng et al., 2023) 765 71.9 72.6 68.8 54.3 4l 42.8 62.0 Open Assistant Pythia 12B* 67.9 3 68.1 65 64.2 40.4 43.2 61.0 Mosaic MPT7B (MosaicML-Team, 2023) 748 193 76.3 68.6 70 42.2 42.6 64.8 Mosaic mpt-instruct (MosaicML-Team, 2023) 743 80.4 77.2. 678 72.2 44.6 43 65.6 Mosaic mpt-chat (MosaicML-Team, 2023) 771 78.2 74.5 67.5 69.4 43.3 44.2 9 Wizard 7B xu et al., 2023) 74 772 69.9 66,5 56.8 40.5 42.6 61,7 Wizard 7B Uncensored (Xu et al., 2023) 717 74.2 68 65.2 53.5 38,7 416 59.8 Wizard 13B Uncensored (Xu et al,, 2023) 784 15.5 21 69.5 57.5 40.4 44 62.5 GPT4-x-Vicuna-13b (Nous-Research, 2023a) 813 75 75.2 65 58.7 43,9 43.6 63,2 Falcon 7b (Almazrouei et al., 2023) 7236 80.7 16.3 67,3 1 43.3 444 65.2 Falcon 7b instruct (Almazrouei et al., 2023) 9 78.6 69.8 66.7 619) 4a 4 OS text-davinci-003 88.1 83.8 834 75.8 83.9 63.9 SLO 2\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9163863062858582,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            309.4304504394531,\n",
            "            820.4803466796875\n",
            "          ],\n",
            "          [\n",
            "            309.4304504394531,\n",
            "            1646.1417236328125\n",
            "          ],\n",
            "          [\n",
            "            1373.5946044921875,\n",
            "            1646.1417236328125\n",
            "          ],\n",
            "          [\n",
            "            1373.5946044921875,\n",
            "            820.4803466796875\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"text_as_html\": \"<table><thead><tr><th>Model</th><th>BoolQ</th><th>PIQA</th><th>HellaSwag</th><th>WinoG.</th><th>ARC-c</th><th>ARC-c</th><th>OBQA</th><th>Avg</th></tr></thead><tbody><tr><td>GPT4AII-J 6B v1.0*</td><td>73.4</td><td>74.8</td><td>634</td><td>64.7</td><td>54.9</td><td>36</td><td>40.2</td><td>58.2</td></tr><tr><td>GPT4AII-J v1.1-breezy*</td><td>74</td><td>75.1</td><td>63.2</td><td>63.6</td><td>55.4</td><td>34.9</td><td>38.4</td><td>SL</td></tr><tr><td>GPT4AIIL-J v1.2-jazzy*</td><td>74.8</td><td>74.9</td><td>63.6</td><td>638</td><td>56.6</td><td>35.3</td><td>41</td><td>58.6</td></tr><tr><td>GPT4AII-J v1.3-groovy*</td><td>73.6</td><td>74.3</td><td>63.8</td><td>63.5</td><td>57.7</td><td>35</td><td>38.8 \\u00a9</td><td>58.1</td></tr><tr><td>GPT4AII-J Lora 6B*</td><td>68.6</td><td>75.8</td><td>66.2</td><td>63.5</td><td>56.4</td><td>35.7</td><td>402</td><td>58.1</td></tr><tr><td>GPT4All LLaMa Lora 7B*</td><td>73.1</td><td>77.6</td><td>721</td><td>67.8</td><td>SIE</td><td>40.4</td><td>40.2</td><td>60.3</td></tr><tr><td>GPT4All 13B snoozy*</td><td>83.3</td><td>79.2</td><td>75</td><td>71.3</td><td>60.9</td><td>44.2</td><td>43.4</td><td>65.3</td></tr><tr><td>GPT4AIl Falcon</td><td>71.6</td><td>79.8</td><td>749</td><td>70.1</td><td>67.9</td><td>4B4</td><td>42.6</td><td>65.2</td></tr><tr><td>Nous-Hermes (Nous-Research, 2023b)</td><td>79.5</td><td>78.9</td><td>80</td><td>19</td><td>74.2</td><td>50.9</td><td>4.4</td><td>688</td></tr><tr><td>Nous-Hermes2 (Nous-Research, 2023c)</td><td>83.9</td><td>80.7</td><td>80.1</td><td>71.3</td><td>75.7</td><td>52.1</td><td>46.2</td><td>70.0</td></tr><tr><td>Nous-Puffin (Nous-Research, 2023d)</td><td>815</td><td>80.7</td><td>80.4</td><td>72.5</td><td>771.6</td><td>50.7</td><td>45.6</td><td>69.9</td></tr><tr><td>Dolly 6B* (Conover et al., 2023a)</td><td>68.8</td><td>71.3</td><td>67.6</td><td>63.9</td><td>62.9</td><td>38.7</td><td>412</td><td>601</td></tr><tr><td>Dolly 12B* (Conover et al., 2023)</td><td>56.7</td><td>75.4</td><td>1</td><td>62.2</td><td>64.6</td><td>38.5</td><td>404</td><td>584</td></tr><tr><td>Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7B* 2023)</td><td>94325793</td><td></td><td>73.9 74</td><td>66.1 68.8</td><td>56.6</td><td>43.3 43.9</td><td>426</td><td>62.8</td></tr><tr><td>Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021)</td><td>654</td><td>76.2</td><td>66.2</td><td>64.1</td><td>62.2</td><td>36.6</td><td>38.2</td><td>58.4</td></tr><tr><td>LLama 7B* (Touvron et al., 2023)</td><td>73.1</td><td>714</td><td>13</td><td>66.9</td><td>52.5</td><td>414</td><td>42.4</td><td>61.0</td></tr><tr><td>LLama 13B* (Touvron et al_, 2023)</td><td>68.5</td><td>79.1</td><td>76.2</td><td>70.1</td><td>60</td><td>44.6</td><td>422</td><td>63.0</td></tr><tr><td>Pythia 6.7B* (Biderman et al., 2023)</td><td>63.5</td><td>76.3</td><td>64</td><td>61.1</td><td>61.3</td><td>35.2</td><td>37.2</td><td>56.9</td></tr><tr><td>Pythia 12B* (Biderman et al., 2023)</td><td>67.7</td><td>16.6</td><td>67.3</td><td>63.8</td><td>63.9</td><td>34.8</td><td>38</td><td>58.9</td></tr><tr><td>Fastchat TS* (Zheng et al., 2023)</td><td>815</td><td>64.6</td><td>46.3</td><td>618</td><td>49.3</td><td>(33.2.</td><td>39.4</td><td>53.7</td></tr><tr><td>Fastchat Vicufia* 7B (Zheng et al., 2023)</td><td>76.6</td><td>77.2</td><td>70.7</td><td>67.3</td><td>53.5</td><td>41.2</td><td>40.8</td><td>61.0</td></tr><tr><td>Fastchat Vicufia 13B* (Zheng et al., 2023)</td><td>815</td><td>76.8</td><td>73.3</td><td>66.7</td><td>57.4</td><td>42.7</td><td>3.6</td><td>63.1</td></tr><tr><td>Stable Vicufia RLHF* (Stability-Al, 2023)</td><td>82.3</td><td>78.6</td><td>74.1</td><td>70.9</td><td>61</td><td>43.5</td><td>WA</td><td>65.0</td></tr><tr><td>StableLM Tuned* (Stability-Al, 2023)</td><td>625</td><td>71.2</td><td>53.6</td><td>54.8</td><td>52.4</td><td>31</td><td>33.4</td><td>SiS</td></tr><tr><td>StableLM Base* (Stability-Al, 2023)</td><td>60.1</td><td>67.4</td><td>412</td><td>50.1</td><td>44.9</td><td>27</td><td>32</td><td>46.1</td></tr><tr><td>Koala 13B* (Geng et al., 2023)</td><td>765</td><td>71.9</td><td>72.6</td><td>68.8</td><td>54.3</td><td>4l</td><td>42.8</td><td>62.0</td></tr><tr><td>Open Assistant Pythia 12B*</td><td>67.9</td><td>3</td><td>68.1</td><td>65</td><td>64.2</td><td>404</td><td>43.2</td><td>61.0</td></tr><tr><td>Mosaic MPT7B (MosaicML-Team, 2023)</td><td>74.8</td><td>79.3</td><td>76.3</td><td>68.6</td><td>70</td><td>42.2</td><td>42.6</td><td>64.8</td></tr><tr><td>Mosaic mpt-instruct (MosaicML-Team, 2023)</td><td>743</td><td>80.4</td><td>77.2.</td><td>678</td><td>72.2</td><td>44.6</td><td>43</td><td>65.6</td></tr><tr><td>Mosaic mpt-chat (MosaicML-Team, 2023)</td><td>771</td><td>78.2</td><td>74S</td><td>67.5</td><td>69.4</td><td>43.3</td><td>44.2</td><td>64.9</td></tr><tr><td>Wizard 7B xu et al., 2023)</td><td>74</td><td>772</td><td>69.9</td><td>66,5</td><td>56.8</td><td>40.5</td><td>42.6</td><td>61,7</td></tr><tr><td>Wizard 7B Uncensored (Xu et al., 2023)</td><td>717</td><td>74.2</td><td>68</td><td>65.2</td><td>53.5</td><td>38,7</td><td>416</td><td>59.8</td></tr><tr><td>Wizard 13B Uncensored (Xu et al,, 2023)</td><td>784</td><td>15.5</td><td>21</td><td>69.5</td><td>57.5</td><td>40.4</td><td>44</td><td>62.5</td></tr><tr><td>GPT4-x-Vicuna-13b (Nous-Research, 2023a)</td><td>813</td><td>75</td><td>75.2</td><td>65</td><td>58.7</td><td>43,9</td><td>43.6</td><td>63,2</td></tr><tr><td>Falcon 7b (Almazrouei et al., 2023)</td><td>73.6</td><td>80.7</td><td>76.3</td><td>67,3</td><td>7</td><td>43.3</td><td>44.4</td><td>65.2</td></tr><tr><td>Falcon 7b instruct (Almazrouei et al., 2023)</td><td>709</td><td>78.6</td><td>69.8</td><td>66.7</td><td>67.9</td><td>42.7</td><td>412</td><td>62.5</td></tr></tbody></table>\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 3,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"57f7ed876c54c522595f29bfa50ae0ed\",\n",
            "    \"text\": \"Table 1: Evaluations of all language models in the GPT4AIl ecosystem as of August 1, 2023, Code models are not included. OpenAI\\u2019s text-davinci-003 is included as a point of comparison. The best overall performing model in the GPT4AIl ecosystem, Nous-Hermes?, achieves over 92% of the average performance of text-davinci-003, Models marked with an asterisk were available in the ecosystem as of the release of GPT4All-Snoozy. Note that at release, GPT4AII-Snoozy had the best average performance of any model in the ecosystem. Bolded numbers indicate the best performing model as of August 1, 2023\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9210993051528931,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            306.297607421875,\n",
            "            1677.7933349609375\n",
            "          ],\n",
            "          [\n",
            "            306.297607421875,\n",
            "            1843.080810546875\n",
            "          ],\n",
            "          [\n",
            "            1378.650634765625,\n",
            "            1843.080810546875\n",
            "          ],\n",
            "          [\n",
            "            1378.650634765625,\n",
            "            1677.7933349609375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 3,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Image\",\n",
            "    \"element_id\": \"a0ba59eb68956209b29ac1f8add10073\",\n",
            "    \"text\": \"Github Repo Growth \\u2014 GPT4All \\u2014- UaMA \\u2014 Apaca 50000 40000 30000 Github Stars i 10000 0 20 40 60 80 100-120 140 Days Since Launch\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8708685040473938,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            364.3476867675781,\n",
            "            285.80804443359375\n",
            "          ],\n",
            "          [\n",
            "            364.3476867675781,\n",
            "            736.1420288085938\n",
            "          ],\n",
            "          [\n",
            "            1171.9842529296875,\n",
            "            736.1420288085938\n",
            "          ],\n",
            "          [\n",
            "            1171.9842529296875,\n",
            "            285.80804443359375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"FigureCaption\",\n",
            "    \"element_id\": \"8c66a757b9d403d609040dfdaf49b511\",\n",
            "    \"text\": \"Figure 2: Comparison of the github start growth of GPT4All, Meta\\u2019s LLaMA, and Stanford\\u2019s Alpaca. We conjecture that GPT4AIl achieved and maintains faster ecosystem growth due to the focus on access, which allows more users to meaningfully participate.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9072695374488831,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            315.8026123046875,\n",
            "            772.1033325195312\n",
            "          ],\n",
            "          [\n",
            "            315.8026123046875,\n",
            "            848.3175659179688\n",
            "          ],\n",
            "          [\n",
            "            1388.649658203125,\n",
            "            848.3175659179688\n",
            "          ],\n",
            "          [\n",
            "            1388.649658203125,\n",
            "            772.1033325195312\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"4b3227025511abcb3b7192c4cd04d284\",\n",
            "    \"text\": \"provides compressed versions of open source models for use on commodity hardware, stable and simple high level model APIs, and a GUI for no code model ex- perimentation. The project continues to increase in popularity, and as of August 1 2023, has garnered over 50000 GitHub stars and over 5000 forks.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9354279637336731,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            319.3470153808594,\n",
            "            908.0654907226562\n",
            "          ],\n",
            "          [\n",
            "            319.3470153808594,\n",
            "            1071.406982421875\n",
            "          ],\n",
            "          [\n",
            "            839.2305908203125,\n",
            "            1071.406982421875\n",
            "          ],\n",
            "          [\n",
            "            839.2305908203125,\n",
            "            908.0654907226562\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"75b0bc8519ac1101a44552b3e77c1e97\",\n",
            "    \"text\": \"\\u201cjust work\\\" on any machine, whether it comes equipped with Apple Metal silicon, NVIDIA, AMD, or other edge- accelerated hardware, Overall, we envision a world where anyone, anywhere, with any machine, can access and contribute to the cutting edge of AI.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.929227352142334,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            870.3804321289062,\n",
            "            910.4838256835938\n",
            "          ],\n",
            "          [\n",
            "            870.3804321289062,\n",
            "            1043.3155517578125\n",
            "          ],\n",
            "          [\n",
            "            1393.669921875,\n",
            "            1043.3155517578125\n",
            "          ],\n",
            "          [\n",
            "            1393.669921875,\n",
            "            910.4838256835938\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"cb9c28eeb7af6891825cf3ab518a7503\",\n",
            "    \"text\": \"GPT4All currently provides native support and benchmark data for over 35 models (see Figure 1), and includes several models co-developed with industry part- ners such as Replit and Hugging Face. GPT4AII also provides high level model APIs in languages includ- ing Python, Typescript, Go, C#, and Java, among oth- ers. Furthermore, the GPT4All no code GUI currently supports the workflows of over 50000 monthly active users, with over 25% of users coming back to the tool every day of the week. (Note that all GPT4AII user data is collected on an opt in basis.) GPT4AIl has be- come the top language model integration in the popular open source AI orchestration library LangChain (Chase, 2022), and powers many popular open source projects such as PrivateGPT (imartinez, 2023), Quiver (StanGi- rard, 2023), and MindsDB (MindsDB, 2023), among others, GPT4AII is the 3rd fastest growing GitHub repository of all time (Leo, 2023), and is the 185th most popular repository on the platform, by star count.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9414840340614319,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            318.37109375,\n",
            "            1081.3922119140625\n",
            "          ],\n",
            "          [\n",
            "            318.37109375,\n",
            "            1611.921875\n",
            "          ],\n",
            "          [\n",
            "            840.0160522460938,\n",
            "            1611.921875\n",
            "          ],\n",
            "          [\n",
            "            840.0160522460938,\n",
            "            1081.3922119140625\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"d147cfb7cb1aec3c5e3a01cb7d3d0a87\",\n",
            "    \"text\": \"4 The Future of GPT4AIl\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8407053351402283,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            314.88934326171875,\n",
            "            1649.770263671875\n",
            "          ],\n",
            "          [\n",
            "            314.88934326171875,\n",
            "            1679.01220703125\n",
            "          ],\n",
            "          [\n",
            "            644.4810791015625,\n",
            "            1679.01220703125\n",
            "          ],\n",
            "          [\n",
            "            644.4810791015625,\n",
            "            1649.770263671875\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"03d7dd6667945b2aedce05c90ac746f6\",\n",
            "    \"text\": \"In the future, we will continue to grow GPT4AN, sup- porting it as the de facto solution for LLM accessibil- ity. Concretely, this means continuing to compress and distribute important open-source language models de- veloped by the community, as well as compressing and distributing increasingly multimodal AI models, Fur- thermore, we will expand the set of hardware devices that GPT4AII models run on, so that GPT4AIl models\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9457899332046509,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            315.0162658691406,\n",
            "            1705.4500732421875\n",
            "          ],\n",
            "          [\n",
            "            315.0162658691406,\n",
            "            1931.087646484375\n",
            "          ],\n",
            "          [\n",
            "            840.438720703125,\n",
            "            1931.087646484375\n",
            "          ],\n",
            "          [\n",
            "            840.438720703125,\n",
            "            1705.4500732421875\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"d147cfb7cb1aec3c5e3a01cb7d3d0a87\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"65fe5169b886a5c32bef95f78f214bb9\",\n",
            "    \"text\": \"Limitations\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8675901889801025,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            874.3472900390625,\n",
            "            1083.5989990234375\n",
            "          ],\n",
            "          [\n",
            "            874.3472900390625,\n",
            "            1105.80419921875\n",
            "          ],\n",
            "          [\n",
            "            1011.0413208007812,\n",
            "            1105.80419921875\n",
            "          ],\n",
            "          [\n",
            "            1011.0413208007812,\n",
            "            1083.5989990234375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"0cbf657555bd65e6f7c5004cc74191e7\",\n",
            "    \"text\": \"uk\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            1007.0,\n",
            "            1099.0\n",
            "          ],\n",
            "          [\n",
            "            1007.0,\n",
            "            1156.0\n",
            "          ],\n",
            "          [\n",
            "            1097.0,\n",
            "            1156.0\n",
            "          ],\n",
            "          [\n",
            "            1097.0,\n",
            "            1099.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 4,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"00d778311243601579e4103db56bde43\",\n",
            "    \"text\": \"By enabling large language models, the GPT4AII project also inherits many of the ethical con- cems associated with generative models. Principal among these is the concern that unfiltered language models like GPT4All enable malicious users to generate content that could be harmful and dangerous (e.g., in- structions on building bioweapons), While we recognize this risk, we also acknowledge the risk of concentrating this technology in the hands of a limited number of in- creasingly secretive research groups, We believe that the risk of focusing on the benefits of language model technology significantly outweighs the risk of misuse, and hence we prefer to make the technology as widely available as possible.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9439144134521484,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            873.4852905273438,\n",
            "            1136.11328125\n",
            "          ],\n",
            "          [\n",
            "            873.4852905273438,\n",
            "            1522.942626953125\n",
            "          ],\n",
            "          [\n",
            "            1393.2860107421875,\n",
            "            1522.942626953125\n",
            "          ],\n",
            "          [\n",
            "            1393.2860107421875,\n",
            "            1136.11328125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"0cbf657555bd65e6f7c5004cc74191e7\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"b4c0f98fe231c2befd1aab2046cad875\",\n",
            "    \"text\": \"Finally, we realize the challenge in assigning credit for large-scale open source initiatives. We make a first attempt at fair credit assignment by explicitly includ- ing the GPT4AII open source developers as authors on this work, but recognize that this is insufficient fully characterize everyone involved in the GPT4AII effort. Furthermore, we acknowledge the difficulty in citing open source works that do not necessarily have standard- ized citations, and do our best in this paper to provide URLs to projects whenever possible. We encourage further research in the area of open source credit as signment, and hope to be able to support some of this research ourselves in the future\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9481733441352844,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            872.8200073242188,\n",
            "            1534.714111328125\n",
            "          ],\n",
            "          [\n",
            "            872.8200073242188,\n",
            "            1902.781005859375\n",
            "          ],\n",
            "          [\n",
            "            1398.0157470703125,\n",
            "            1902.781005859375\n",
            "          ],\n",
            "          [\n",
            "            1398.0157470703125,\n",
            "            1534.714111328125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 4,\n",
            "      \"parent_id\": \"0cbf657555bd65e6f7c5004cc74191e7\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "    \"text\": \"References\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8165109157562256,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            323.6335144042969,\n",
            "            256.2832946777344\n",
            "          ],\n",
            "          [\n",
            "            323.6335144042969,\n",
            "            287.6946105957031\n",
            "          ],\n",
            "          [\n",
            "            457.59991455078125,\n",
            "            287.6946105957031\n",
            "          ],\n",
            "          [\n",
            "            457.59991455078125,\n",
            "            256.2832946777344\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"c0ebd30986550bc57caf57d1e1f6fa9a\",\n",
            "    \"text\": \"Nomic AT. 2023. Atlas. https://atlas.nomic.ai/.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.7809240221977234,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            323.16424560546875,\n",
            "            303.74078369140625\n",
            "          ],\n",
            "          [\n",
            "            323.16424560546875,\n",
            "            332.01934814453125\n",
            "          ],\n",
            "          [\n",
            "            834.1893310546875,\n",
            "            332.01934814453125\n",
            "          ],\n",
            "          [\n",
            "            834.1893310546875,\n",
            "            303.74078369140625\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"9f15d733aee304c4c72894208b31bc64\",\n",
            "    \"text\": \"MosaicML-Team. 2023. Introducing mpt-7b: A new standard for open-source, commercially usable lms. Accessed: 2023-08-07.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8573061227798462,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            878.0604858398438,\n",
            "            265.44927978515625\n",
            "          ],\n",
            "          [\n",
            "            878.0604858398438,\n",
            "            339.80035400390625\n",
            "          ],\n",
            "          [\n",
            "            1391.1954345703125,\n",
            "            339.80035400390625\n",
            "          ],\n",
            "          [\n",
            "            1391.1954345703125,\n",
            "            265.44927978515625\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"f431d4365ea80e864b3a1de4f9d5a291\",\n",
            "    \"text\": \"Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Al- shamsi, Alessandro Cappelli, Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Hes- low, Julien Launay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. 2023. Falcon-40B: an open large language model with state-of-the-art performance.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.884958803653717,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            321.4091796875,\n",
            "            355.8954772949219\n",
            "          ],\n",
            "          [\n",
            "            321.4091796875,\n",
            "            536.5584716796875\n",
            "          ],\n",
            "          [\n",
            "            839.4834594726562,\n",
            "            536.5584716796875\n",
            "          ],\n",
            "          [\n",
            "            839.4834594726562,\n",
            "            355.8954772949219\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"2638c19b4370c622261d655b41008aaf\",\n",
            "    \"text\": \"Nous-Research. 2023a. gpt4-x-vicuna-13b. https: //huggingface.co/NousResearch/ gpt4-x-vicuna-13b. Model on Hugging Face.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.7881004810333252,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            881.4146118164062,\n",
            "            367.8905944824219\n",
            "          ],\n",
            "          [\n",
            "            881.4146118164062,\n",
            "            441.9910583496094\n",
            "          ],\n",
            "          [\n",
            "            1387.7169189453125,\n",
            "            441.9910583496094\n",
            "          ],\n",
            "          [\n",
            "            1387.7169189453125,\n",
            "            367.8905944824219\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"e47a165ec4dc1174b1bc089e3f602f48\",\n",
            "    \"text\": \"Nous-Research. 2023b. Nous-hermes-13b. https: //huggingface.co/NousResearch/ Nous-Hermes-13b. Model on Hugging Face.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8133750557899475,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            880.1997680664062,\n",
            "            469.07861328125\n",
            "          ],\n",
            "          [\n",
            "            880.1997680664062,\n",
            "            542.4092407226562\n",
            "          ],\n",
            "          [\n",
            "            1387.319091796875,\n",
            "            542.4092407226562\n",
            "          ],\n",
            "          [\n",
            "            1387.319091796875,\n",
            "            469.07861328125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"7addbbb165f90ceac055454262c0bc9e\",\n",
            "    \"text\": \"Yuvanesh Anand, Zach Nussbaum, Brandon Duder- stadt, Benjamin Schmidt, and Andriy Mulyar. 2023. Gpt4all: Training an assistant-style chatbot with large scale data distillation from gpt-3.5-turbo. https: //github.com/nomic-ai/gpt4all.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9011225700378418,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            308.5872802734375,\n",
            "            561.3509521484375\n",
            "          ],\n",
            "          [\n",
            "            308.5872802734375,\n",
            "            687.0341186523438\n",
            "          ],\n",
            "          [\n",
            "            852.7594604492188,\n",
            "            687.0341186523438\n",
            "          ],\n",
            "          [\n",
            "            852.7594604492188,\n",
            "            561.3509521484375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"38bfa62cb8a674c16d450f6f3cb7df0c\",\n",
            "    \"text\": \"Nous-Research. 2023c. Nous-hermes-Ilama-2-7b. https: //huggingface.co/NousResearch/ Nous-Hermes-llama-2-7b. Model on Hugging Face.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8658347725868225,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            878.3175659179688,\n",
            "            569.4051513671875\n",
            "          ],\n",
            "          [\n",
            "            878.3175659179688,\n",
            "            669.9036254882812\n",
            "          ],\n",
            "          [\n",
            "            1388.3759765625,\n",
            "            669.9036254882812\n",
            "          ],\n",
            "          [\n",
            "            1388.3759765625,\n",
            "            569.4051513671875\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"e13431c2052771855860888f3d425f30\",\n",
            "    \"text\": \"BBC News. 2023. Chatgpt banned in italy over privacy concerns. BBC News.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8478924036026001,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            319.994873046875,\n",
            "            710.995361328125\n",
            "          ],\n",
            "          [\n",
            "            319.994873046875,\n",
            "            760.974853515625\n",
            "          ],\n",
            "          [\n",
            "            840.0192260742188,\n",
            "            760.974853515625\n",
            "          ],\n",
            "          [\n",
            "            840.0192260742188,\n",
            "            710.995361328125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"d8a3c42a6978070896a808791638a231\",\n",
            "    \"text\": \"Nous-Research. 2023d. Redmond-puffin-13b. https: //huggingface.co/NousResearch/ Redmond-Puf fin-13B. Model on Hugging Face.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.875937283039093,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            871.6441650390625,\n",
            "            695.470947265625\n",
            "          ],\n",
            "          [\n",
            "            871.6441650390625,\n",
            "            769.2915649414062\n",
            "          ],\n",
            "          [\n",
            "            1391.613037109375,\n",
            "            769.2915649414062\n",
            "          ],\n",
            "          [\n",
            "            1391.613037109375,\n",
            "            695.470947265625\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"b901be1f53d56920fa53834938cdd0ba\",\n",
            "    \"text\": \"Stella Biderman, Hailey Schoelkopf, Quentin An- thony, Herbie Bradley, Kyle O\\u2019Brien, Eric Hal- lahan, Mohammad Aflah Khan, Shivanshu Puro- hit, USVSN Sai Prashanth, Edward Raff, Aviya Skowron, Lintang Sutawika, and Oskar van der Wal. 2023. Pythia: A suite for analyzing large language models across training and scaling.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8832610249519348,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            309.3657531738281,\n",
            "            788.0254516601562\n",
            "          ],\n",
            "          [\n",
            "            309.3657531738281,\n",
            "            961.2088623046875\n",
            "          ],\n",
            "          [\n",
            "            864.4655151367188,\n",
            "            961.2088623046875\n",
            "          ],\n",
            "          [\n",
            "            864.4655151367188,\n",
            "            788.0254516601562\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"f2311f17c2c71112d67caec6c5ee6d6d\",\n",
            "    \"text\": \"Harrison Chase. 2022. langchain. https://github. com/langchain-ai/langchain.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.5967409610748291,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            318.55322265625,\n",
            "            987.0906982421875\n",
            "          ],\n",
            "          [\n",
            "            318.55322265625,\n",
            "            1037.481201171875\n",
            "          ],\n",
            "          [\n",
            "            848.4509887695312,\n",
            "            1037.481201171875\n",
            "          ],\n",
            "          [\n",
            "            848.4509887695312,\n",
            "            987.0906982421875\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"4c541e4b02c1d69b80da2d9fafb47e3f\",\n",
            "    \"text\": \"Mike Conover, Matt Hayes, Ankit Mathur, Xiangrui Meng, Jianwei Xie, Jun Wan, Ali Ghodsi, Patrick Wendell, and Matei Zaharia. 2023a. Hello dolly: Democratizing the magic of chatgpt with open mod- els.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8952468633651733,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            309.6745300292969,\n",
            "            1062.8521728515625\n",
            "          ],\n",
            "          [\n",
            "            309.6745300292969,\n",
            "            1186.4356689453125\n",
            "          ],\n",
            "          [\n",
            "            855.876220703125,\n",
            "            1186.4356689453125\n",
            "          ],\n",
            "          [\n",
            "            855.876220703125,\n",
            "            1062.8521728515625\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"NarrativeText\",\n",
            "    \"element_id\": \"dac5493f0fd15fa083ce475f3055ac73\",\n",
            "    \"text\": \"OpenAI. 2023. Gpt-4 technical report.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.6892600655555725,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            876.5171508789062,\n",
            "            794.2494506835938\n",
            "          ],\n",
            "          [\n",
            "            876.5171508789062,\n",
            "            817.843994140625\n",
            "          ],\n",
            "          [\n",
            "            1234.154296875,\n",
            "            817.843994140625\n",
            "          ],\n",
            "          [\n",
            "            1234.154296875,\n",
            "            794.2494506835938\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"f4132cae4d7aa07243b93c06e6c7dfda\",\n",
            "    \"text\": \"Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szezechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Teshala Neeraj, Jos Rozen, Ab- heesht Sharma, Ar}irea Santilli, Thibault Fevry, Ja- son Alan Fries, RxAn Teehan, Stella Biderman, Leo Gao, Tali Bers, Thomas Wolf, and Alexander M. Rush. 2021. Multitask prompted training enables zero-shot task generalization,\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.9085522294044495,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            872.9061889648438,\n",
            "            843.8441162109375\n",
            "          ],\n",
            "          [\n",
            "            872.9061889648438,\n",
            "            1217.8609619140625\n",
            "          ],\n",
            "          [\n",
            "            1411.3651123046875,\n",
            "            1217.8609619140625\n",
            "          ],\n",
            "          [\n",
            "            1411.3651123046875,\n",
            "            843.8441162109375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"b33574f8b2f917f59e52f7dddc86da97\",\n",
            "    \"text\": \"Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin. 2023b. Free dolly: Introducing the world\\u2019s first truly open instruction- tuned Im.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8988226652145386,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            313.4408264160156,\n",
            "            1213.277099609375\n",
            "          ],\n",
            "          [\n",
            "            313.4408264160156,\n",
            "            1340.6673583984375\n",
            "          ],\n",
            "          [\n",
            "            853.0631103515625,\n",
            "            1340.6673583984375\n",
            "          ],\n",
            "          [\n",
            "            853.0631103515625,\n",
            "            1213.277099609375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"1685f18a8d54abf1d6d7014338d39466\",\n",
            "    \"text\": \"Stability-AL. 2023. Stablelm. https: //github.com/ Stability-AI/StableLM. GitHub repository.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.7069557905197144,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            879.7740478515625,\n",
            "            1254.066162109375\n",
            "          ],\n",
            "          [\n",
            "            879.7740478515625,\n",
            "            1301.79541015625\n",
            "          ],\n",
            "          [\n",
            "            1392.0322265625,\n",
            "            1301.79541015625\n",
            "          ],\n",
            "          [\n",
            "            1392.0322265625,\n",
            "            1254.066162109375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"63a6fb09ddc0e4c1bbbe348eb654bf97\",\n",
            "    \"text\": \"Xinyang Geng, Arnav Gudibande, Hao Liu, Eric Wal- Jace, Pieter Abbeel, Sergey Levine, and Dawn Song. 2023. Koala: A dialogue model for academic re- search. Blog post.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8863738179206848,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            316.2239685058594,\n",
            "            1366.4324951171875\n",
            "          ],\n",
            "          [\n",
            "            316.2239685058594,\n",
            "            1467.014892578125\n",
            "          ],\n",
            "          [\n",
            "            847.9456176757812,\n",
            "            1467.014892578125\n",
            "          ],\n",
            "          [\n",
            "            847.9456176757812,\n",
            "            1366.4324951171875\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"2fd5c4dc7d9aee015beec43d3a2dd51e\",\n",
            "    \"text\": \"Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen, 2021, Lora: Low-rank adaptation of large language models,\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8681251406669617,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            313.5329895019531,\n",
            "            1492.6971435546875\n",
            "          ],\n",
            "          [\n",
            "            313.5329895019531,\n",
            "            1594.7303466796875\n",
            "          ],\n",
            "          [\n",
            "            849.5582275390625,\n",
            "            1594.7303466796875\n",
            "          ],\n",
            "          [\n",
            "            849.5582275390625,\n",
            "            1492.6971435546875\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"68232fb79c8114a4bcb48a38cdf3fb85\",\n",
            "    \"text\": \"imartinez. 2023. privategpt, https://github.com/ imartinez/privateGPT.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.5315879583358765,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            318.3378601074219,\n",
            "            1620.3861083984375\n",
            "          ],\n",
            "          [\n",
            "            318.3378601074219,\n",
            "            1670.581787109375\n",
            "          ],\n",
            "          [\n",
            "            844.2793579101562,\n",
            "            1670.581787109375\n",
            "          ],\n",
            "          [\n",
            "            844.2793579101562,\n",
            "            1620.3861083984375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"47cf52e4295349ab2462cd4ed3b6a044\",\n",
            "    \"text\": \"Oscar Leo, 2023. GitHub: The Fastest Growing Repos- itories of AJ] Time.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.7494208216667175,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            314.58892822265625,\n",
            "            1694.7196044921875\n",
            "          ],\n",
            "          [\n",
            "            314.58892822265625,\n",
            "            1746.0809326171875\n",
            "          ],\n",
            "          [\n",
            "            841.4545288085938,\n",
            "            1746.0809326171875\n",
            "          ],\n",
            "          [\n",
            "            841.4545288085938,\n",
            "            1694.7196044921875\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"9040b9a0fb5d1ffa3f8f3e83543cb2a8\",\n",
            "    \"text\": \"StanGirard. 2023. quivr. https://github.com/ StanGirard/quivr, GitHub repository.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.7443868517875671,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            874.9909057617188,\n",
            "            1329.6654052734375\n",
            "          ],\n",
            "          [\n",
            "            874.9909057617188,\n",
            "            1377.678955078125\n",
            "          ],\n",
            "          [\n",
            "            1389.090087890625,\n",
            "            1377.678955078125\n",
            "          ],\n",
            "          [\n",
            "            1389.090087890625,\n",
            "            1329.6654052734375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"107e5b4a0ff2ad9fad93190874542b1c\",\n",
            "    \"text\": \"Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B, Hashimoto. 2023. Stanford alpaca: An instruction-following llama model, https: // github. com/tatsu-lab/stanford_alpaca.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.881890058517456,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            864.5420532226562,\n",
            "            1403.415771484375\n",
            "          ],\n",
            "          [\n",
            "            864.5420532226562,\n",
            "            1530.091064453125\n",
            "          ],\n",
            "          [\n",
            "            1395.8299560546875,\n",
            "            1530.091064453125\n",
            "          ],\n",
            "          [\n",
            "            1395.8299560546875,\n",
            "            1403.415771484375\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"f0e9f248e66c702acffab103d49d5810\",\n",
            "    \"text\": \"Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\\u00e9e Lacroix, Baptiste Rozi\\u00e9re, Naman Goyal, Bric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample, 2023, Llama: Open and efficient foundation language models,\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8762736320495605,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            868.0520629882812,\n",
            "            1559.406494140625\n",
            "          ],\n",
            "          [\n",
            "            868.0520629882812,\n",
            "            1737.20068359375\n",
            "          ],\n",
            "          [\n",
            "            1405.802734375,\n",
            "            1737.20068359375\n",
            "          ],\n",
            "          [\n",
            "            1405.802734375,\n",
            "            1559.406494140625\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"306172d5c1bcd8e14280db86ab92417e\",\n",
            "    \"text\": \"Robert McMillan, 2023. A meta platforms leak put powerful ai in the hands of everyone. The Wall Street Journal\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.844599723815918,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            314.8537292480469,\n",
            "            1771.673828125\n",
            "          ],\n",
            "          [\n",
            "            314.8537292480469,\n",
            "            1848.074462890625\n",
            "          ],\n",
            "          [\n",
            "            843.6608276367188,\n",
            "            1848.074462890625\n",
            "          ],\n",
            "          [\n",
            "            843.6608276367188,\n",
            "            1771.673828125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"96193587a3ec137f8f1402f5ba65703e\",\n",
            "    \"text\": \"The Verge. 2023, Meta\\u2019s powerful ai language model has leaked online \\u2014 what happens now? The Verge\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.7548224329948425,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            871.3294067382812,\n",
            "            1765.517822265625\n",
            "          ],\n",
            "          [\n",
            "            871.3294067382812,\n",
            "            1816.924072265625\n",
            "          ],\n",
            "          [\n",
            "            1392.5386962890625,\n",
            "            1816.924072265625\n",
            "          ],\n",
            "          [\n",
            "            1392.5386962890625,\n",
            "            1765.517822265625\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"0bb3a4940f456c3908ee228d0fee1b59\",\n",
            "    \"text\": \"MindsDB, 2023, Mindsdb. https://github.com/ mindsdb/mindsdb, GitHub repository\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.6084710359573364,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            315.8533630371094,\n",
            "            1873.15625\n",
            "          ],\n",
            "          [\n",
            "            315.8533630371094,\n",
            "            1924.0263671875\n",
            "          ],\n",
            "          [\n",
            "            839.9713745117188,\n",
            "            1924.0263671875\n",
            "          ],\n",
            "          [\n",
            "            839.9713745117188,\n",
            "            1873.15625\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"ListItem\",\n",
            "    \"element_id\": \"ae163c12121ea64331f632b14ab253db\",\n",
            "    \"text\": \"James Vincent. 2023. As an ai generated language model; The phrase that shows how ai is polluting the web. The Verge.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.8694372177124023,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            870.0297241210938,\n",
            "            1845.6807861328125\n",
            "          ],\n",
            "          [\n",
            "            870.0297241210938,\n",
            "            1921.2481689453125\n",
            "          ],\n",
            "          [\n",
            "            1393.6605224609375,\n",
            "            1921.2481689453125\n",
            "          ],\n",
            "          [\n",
            "            1393.6605224609375,\n",
            "            1845.6807861328125\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"parent_id\": \"011e920644821d5d9d1c98a9626c9875\",\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Title\",\n",
            "    \"element_id\": \"5c1a14888b5688ea6e995b2bb2cb4baf\",\n",
            "    \"text\": \"| fren\",\n",
            "    \"metadata\": {\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            147.0,\n",
            "            2063.0\n",
            "          ],\n",
            "          [\n",
            "            147.0,\n",
            "            2112.0\n",
            "          ],\n",
            "          [\n",
            "            1556.0,\n",
            "            2112.0\n",
            "          ],\n",
            "          [\n",
            "            1556.0,\n",
            "            2063.0\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 5,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Image\",\n",
            "    \"element_id\": \"3ba94d878c9246aae80112037f966ce2\",\n",
            "    \"text\": \"Ben Wang and Aran Komatsuzaki. 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https: //github.com/kingoflolz/ mesh-transformer-jax. Enc J. Wang. 2023. alpaca-lora. https://github. com/tloen/alpaca-lora. GitHub repository. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Han- nanch Hajishirzi. 2023. Self-instruct: Aligning lan- guage models with self-generated instructions. Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023. Wizardlm: Empowering large language models to follow complex instructions. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging Ilm-as-a-judge with mt-bench and chatbot arena.\",\n",
            "    \"metadata\": {\n",
            "      \"detection_class_prob\": 0.3342369496822357,\n",
            "      \"coordinates\": {\n",
            "        \"points\": [\n",
            "          [\n",
            "            149.89720153808594,\n",
            "            213.85157775878906\n",
            "          ],\n",
            "          [\n",
            "            149.89720153808594,\n",
            "            1925.6368408203125\n",
            "          ],\n",
            "          [\n",
            "            1577.909912109375,\n",
            "            1925.6368408203125\n",
            "          ],\n",
            "          [\n",
            "            1577.909912109375,\n",
            "            213.85157775878906\n",
            "          ]\n",
            "        ],\n",
            "        \"system\": \"PixelSpace\",\n",
            "        \"layout_width\": 1700,\n",
            "        \"layout_height\": 2200\n",
            "      },\n",
            "      \"last_modified\": \"2024-11-05T15:08:14\",\n",
            "      \"filetype\": \"application/pdf\",\n",
            "      \"languages\": [\n",
            "        \"eng\"\n",
            "      ],\n",
            "      \"page_number\": 6,\n",
            "      \"file_directory\": \"/content\",\n",
            "      \"filename\": \"scanned_gpt4all.pdf\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "{'NarrativeText', 'Image', 'Header', 'FigureCaption', 'Title', 'Table', 'ListItem'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tables = [el for el in elements if el.category == \"Table\"]\n",
        "\n",
        "print(tables[0].text)\n",
        "print(tables[0].metadata.text_as_html)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRDe0D7c-wWc",
        "outputId": "d0876b6e-c809-4ad4-9673-2ab5c7683431"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BoolQ PIQA HellaSwag WinoG. ARC-c ARC-c OBQA Avg. GPT4AII-J 6B v1.0* 73.4 74.8 634 64.7 54.9 36 40.2 58.2 GPT4AII-J v1.1-breezy* 74 75.1 63.2 63.6 55.4 34.9 38.4 57.8 GPT4AIIL-J v1.2-jazzy* 74.8 74.9 63.6 638 56.6 35.3 41 58.6 GPT4AII-J v1.3-groovy* 73.6 74.3 63.8 63.5 57.7 35 38.8 © 58.1 GPT4AII-J Lora 6B* 68.6 75.8 66.2 63.5 56.4 35.7 402 58.1 GPT4All LLaMa Lora 7B* 73.1 77.6 721 67.8 SIE 40.4 40.2 60.3 GPT4All 13B snoozy* 83.3 79.2 75 71.3 60.9 44.2 43.4 65.3 GPT4AIl Falcon 71.6 79.8 749 70.1 67.9 4B4 42.6 65.2 Nous-Hermes (Nous-Research, 2023b) 79.5 78.9 80 19 74.2 50.9 64 68.3 Nous-Hermes2 (Nous-Research, 2023c) 83.9 80.7 80.1 71.3 75.7 52.1 46.2 70.0 Nous-Puffin (Nous-Research, 2023d) 815 80.7 80.4 72.5 771.6 50.7 45.6 69.9 Dolly 6B* (Conover et al., 2023a) 68.8 71.3 67.6 63.9 62.9 38.7 412 1 Dolly 12B* (Conover et al., 2023) 56.7 75.4 1 62.2 64.6 38.5 404 584 Alpaca 7B* (Taori et al. , 2023) 73.9 TT 73.9 66.1 59.8 43.3 434 62.5 Alpaca Lora 7B* Wang. 2023) 94325793 74 68.8 56.6 43.9 426 628 GPT-J* 6.7B (Wang and Komatsuzaki, 2021) 654 76.2 66.2 64.1 62.2 36.6 38.2 58.4 LLama 7B* (Touvron et al., 2023) 73.1 714 13 66.9 52.5 414 42.4 61.0 LLama 13B* (Touvron et al_, 2023) 68.5 79.1 76.2 70.1 60 44.6 422 63.0 Pythia 6.7B* (Biderman et al., 2023) 63.5 76.3 64 61.1 61.3 35.2 37.2 56.9 Pythia 12B* (Biderman et al., 2023) 67.7 16.6 67.3 63.8 63.9 34.8 38 58.9 Fastchat TS* (Zheng et al., 2023) 815 64.6 46.3 618 49.3 (33.2. 39.4 53.7 Fastchat Vicufia* 7B (Zheng et al., 2023) 76.6 77.2 70.7 67.3 53.5 41.2 40.8 61.0 Fastchat Vicufia 13B* (Zheng et al., 2023) 815 76.8 73.3 66.7 57.4 42.7 3.6 63.1 Stable Vicufia RLHF* (Stability-Al, 2023) 82.3 78.6 74.1 70.9 61 43.5 444 65.0 StableLM Tuned* (Stability-Al, 2023) 625 71.2 53.6 54.8 52.4 31 33.4 SUS StableLM Base* (Stability-Al, 2023) 60.1 67.4 412 50.1 44.9 27 32 46.1 Koala 13B* (Geng et al., 2023) 765 71.9 72.6 68.8 54.3 4l 42.8 62.0 Open Assistant Pythia 12B* 67.9 3 68.1 65 64.2 40.4 43.2 61.0 Mosaic MPT7B (MosaicML-Team, 2023) 748 193 76.3 68.6 70 42.2 42.6 64.8 Mosaic mpt-instruct (MosaicML-Team, 2023) 743 80.4 77.2. 678 72.2 44.6 43 65.6 Mosaic mpt-chat (MosaicML-Team, 2023) 771 78.2 74.5 67.5 69.4 43.3 44.2 9 Wizard 7B xu et al., 2023) 74 772 69.9 66,5 56.8 40.5 42.6 61,7 Wizard 7B Uncensored (Xu et al., 2023) 717 74.2 68 65.2 53.5 38,7 416 59.8 Wizard 13B Uncensored (Xu et al,, 2023) 784 15.5 21 69.5 57.5 40.4 44 62.5 GPT4-x-Vicuna-13b (Nous-Research, 2023a) 813 75 75.2 65 58.7 43,9 43.6 63,2 Falcon 7b (Almazrouei et al., 2023) 7236 80.7 16.3 67,3 1 43.3 444 65.2 Falcon 7b instruct (Almazrouei et al., 2023) 9 78.6 69.8 66.7 619) 4a 4 OS text-davinci-003 88.1 83.8 834 75.8 83.9 63.9 SLO 2\n",
            "<table><thead><tr><th>Model</th><th>BoolQ</th><th>PIQA</th><th>HellaSwag</th><th>WinoG.</th><th>ARC-c</th><th>ARC-c</th><th>OBQA</th><th>Avg</th></tr></thead><tbody><tr><td>GPT4AII-J 6B v1.0*</td><td>73.4</td><td>74.8</td><td>634</td><td>64.7</td><td>54.9</td><td>36</td><td>40.2</td><td>58.2</td></tr><tr><td>GPT4AII-J v1.1-breezy*</td><td>74</td><td>75.1</td><td>63.2</td><td>63.6</td><td>55.4</td><td>34.9</td><td>38.4</td><td>SL</td></tr><tr><td>GPT4AIIL-J v1.2-jazzy*</td><td>74.8</td><td>74.9</td><td>63.6</td><td>638</td><td>56.6</td><td>35.3</td><td>41</td><td>58.6</td></tr><tr><td>GPT4AII-J v1.3-groovy*</td><td>73.6</td><td>74.3</td><td>63.8</td><td>63.5</td><td>57.7</td><td>35</td><td>38.8 ©</td><td>58.1</td></tr><tr><td>GPT4AII-J Lora 6B*</td><td>68.6</td><td>75.8</td><td>66.2</td><td>63.5</td><td>56.4</td><td>35.7</td><td>402</td><td>58.1</td></tr><tr><td>GPT4All LLaMa Lora 7B*</td><td>73.1</td><td>77.6</td><td>721</td><td>67.8</td><td>SIE</td><td>40.4</td><td>40.2</td><td>60.3</td></tr><tr><td>GPT4All 13B snoozy*</td><td>83.3</td><td>79.2</td><td>75</td><td>71.3</td><td>60.9</td><td>44.2</td><td>43.4</td><td>65.3</td></tr><tr><td>GPT4AIl Falcon</td><td>71.6</td><td>79.8</td><td>749</td><td>70.1</td><td>67.9</td><td>4B4</td><td>42.6</td><td>65.2</td></tr><tr><td>Nous-Hermes (Nous-Research, 2023b)</td><td>79.5</td><td>78.9</td><td>80</td><td>19</td><td>74.2</td><td>50.9</td><td>4.4</td><td>688</td></tr><tr><td>Nous-Hermes2 (Nous-Research, 2023c)</td><td>83.9</td><td>80.7</td><td>80.1</td><td>71.3</td><td>75.7</td><td>52.1</td><td>46.2</td><td>70.0</td></tr><tr><td>Nous-Puffin (Nous-Research, 2023d)</td><td>815</td><td>80.7</td><td>80.4</td><td>72.5</td><td>771.6</td><td>50.7</td><td>45.6</td><td>69.9</td></tr><tr><td>Dolly 6B* (Conover et al., 2023a)</td><td>68.8</td><td>71.3</td><td>67.6</td><td>63.9</td><td>62.9</td><td>38.7</td><td>412</td><td>601</td></tr><tr><td>Dolly 12B* (Conover et al., 2023)</td><td>56.7</td><td>75.4</td><td>1</td><td>62.2</td><td>64.6</td><td>38.5</td><td>404</td><td>584</td></tr><tr><td>Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7B* 2023)</td><td>94325793</td><td></td><td>73.9 74</td><td>66.1 68.8</td><td>56.6</td><td>43.3 43.9</td><td>426</td><td>62.8</td></tr><tr><td>Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021)</td><td>654</td><td>76.2</td><td>66.2</td><td>64.1</td><td>62.2</td><td>36.6</td><td>38.2</td><td>58.4</td></tr><tr><td>LLama 7B* (Touvron et al., 2023)</td><td>73.1</td><td>714</td><td>13</td><td>66.9</td><td>52.5</td><td>414</td><td>42.4</td><td>61.0</td></tr><tr><td>LLama 13B* (Touvron et al_, 2023)</td><td>68.5</td><td>79.1</td><td>76.2</td><td>70.1</td><td>60</td><td>44.6</td><td>422</td><td>63.0</td></tr><tr><td>Pythia 6.7B* (Biderman et al., 2023)</td><td>63.5</td><td>76.3</td><td>64</td><td>61.1</td><td>61.3</td><td>35.2</td><td>37.2</td><td>56.9</td></tr><tr><td>Pythia 12B* (Biderman et al., 2023)</td><td>67.7</td><td>16.6</td><td>67.3</td><td>63.8</td><td>63.9</td><td>34.8</td><td>38</td><td>58.9</td></tr><tr><td>Fastchat TS* (Zheng et al., 2023)</td><td>815</td><td>64.6</td><td>46.3</td><td>618</td><td>49.3</td><td>(33.2.</td><td>39.4</td><td>53.7</td></tr><tr><td>Fastchat Vicufia* 7B (Zheng et al., 2023)</td><td>76.6</td><td>77.2</td><td>70.7</td><td>67.3</td><td>53.5</td><td>41.2</td><td>40.8</td><td>61.0</td></tr><tr><td>Fastchat Vicufia 13B* (Zheng et al., 2023)</td><td>815</td><td>76.8</td><td>73.3</td><td>66.7</td><td>57.4</td><td>42.7</td><td>3.6</td><td>63.1</td></tr><tr><td>Stable Vicufia RLHF* (Stability-Al, 2023)</td><td>82.3</td><td>78.6</td><td>74.1</td><td>70.9</td><td>61</td><td>43.5</td><td>WA</td><td>65.0</td></tr><tr><td>StableLM Tuned* (Stability-Al, 2023)</td><td>625</td><td>71.2</td><td>53.6</td><td>54.8</td><td>52.4</td><td>31</td><td>33.4</td><td>SiS</td></tr><tr><td>StableLM Base* (Stability-Al, 2023)</td><td>60.1</td><td>67.4</td><td>412</td><td>50.1</td><td>44.9</td><td>27</td><td>32</td><td>46.1</td></tr><tr><td>Koala 13B* (Geng et al., 2023)</td><td>765</td><td>71.9</td><td>72.6</td><td>68.8</td><td>54.3</td><td>4l</td><td>42.8</td><td>62.0</td></tr><tr><td>Open Assistant Pythia 12B*</td><td>67.9</td><td>3</td><td>68.1</td><td>65</td><td>64.2</td><td>404</td><td>43.2</td><td>61.0</td></tr><tr><td>Mosaic MPT7B (MosaicML-Team, 2023)</td><td>74.8</td><td>79.3</td><td>76.3</td><td>68.6</td><td>70</td><td>42.2</td><td>42.6</td><td>64.8</td></tr><tr><td>Mosaic mpt-instruct (MosaicML-Team, 2023)</td><td>743</td><td>80.4</td><td>77.2.</td><td>678</td><td>72.2</td><td>44.6</td><td>43</td><td>65.6</td></tr><tr><td>Mosaic mpt-chat (MosaicML-Team, 2023)</td><td>771</td><td>78.2</td><td>74S</td><td>67.5</td><td>69.4</td><td>43.3</td><td>44.2</td><td>64.9</td></tr><tr><td>Wizard 7B xu et al., 2023)</td><td>74</td><td>772</td><td>69.9</td><td>66,5</td><td>56.8</td><td>40.5</td><td>42.6</td><td>61,7</td></tr><tr><td>Wizard 7B Uncensored (Xu et al., 2023)</td><td>717</td><td>74.2</td><td>68</td><td>65.2</td><td>53.5</td><td>38,7</td><td>416</td><td>59.8</td></tr><tr><td>Wizard 13B Uncensored (Xu et al,, 2023)</td><td>784</td><td>15.5</td><td>21</td><td>69.5</td><td>57.5</td><td>40.4</td><td>44</td><td>62.5</td></tr><tr><td>GPT4-x-Vicuna-13b (Nous-Research, 2023a)</td><td>813</td><td>75</td><td>75.2</td><td>65</td><td>58.7</td><td>43,9</td><td>43.6</td><td>63,2</td></tr><tr><td>Falcon 7b (Almazrouei et al., 2023)</td><td>73.6</td><td>80.7</td><td>76.3</td><td>67,3</td><td>7</td><td>43.3</td><td>44.4</td><td>65.2</td></tr><tr><td>Falcon 7b instruct (Almazrouei et al., 2023)</td><td>709</td><td>78.6</td><td>69.8</td><td>66.7</td><td>67.9</td><td>42.7</td><td>412</td><td>62.5</td></tr></tbody></table>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCJoUceX_Q1M",
        "outputId": "8382819d-86d5-4ffc-d616-6e6b30dffa80"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<unstructured.documents.elements.Table at 0x7a0e72741ed0>]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCL9LOZC_Q38",
        "outputId": "4e58e540-130f-4d56-bc1c-27b4d9fba71c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tables[0].text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "56Yyjzsp_Q58",
        "outputId": "c2c978ff-4cfb-4cf7-8688-afb5744c5ef5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Model BoolQ PIQA HellaSwag WinoG. ARC-c ARC-c OBQA Avg. GPT4AII-J 6B v1.0* 73.4 74.8 634 64.7 54.9 36 40.2 58.2 GPT4AII-J v1.1-breezy* 74 75.1 63.2 63.6 55.4 34.9 38.4 57.8 GPT4AIIL-J v1.2-jazzy* 74.8 74.9 63.6 638 56.6 35.3 41 58.6 GPT4AII-J v1.3-groovy* 73.6 74.3 63.8 63.5 57.7 35 38.8 © 58.1 GPT4AII-J Lora 6B* 68.6 75.8 66.2 63.5 56.4 35.7 402 58.1 GPT4All LLaMa Lora 7B* 73.1 77.6 721 67.8 SIE 40.4 40.2 60.3 GPT4All 13B snoozy* 83.3 79.2 75 71.3 60.9 44.2 43.4 65.3 GPT4AIl Falcon 71.6 79.8 749 70.1 67.9 4B4 42.6 65.2 Nous-Hermes (Nous-Research, 2023b) 79.5 78.9 80 19 74.2 50.9 64 68.3 Nous-Hermes2 (Nous-Research, 2023c) 83.9 80.7 80.1 71.3 75.7 52.1 46.2 70.0 Nous-Puffin (Nous-Research, 2023d) 815 80.7 80.4 72.5 771.6 50.7 45.6 69.9 Dolly 6B* (Conover et al., 2023a) 68.8 71.3 67.6 63.9 62.9 38.7 412 1 Dolly 12B* (Conover et al., 2023) 56.7 75.4 1 62.2 64.6 38.5 404 584 Alpaca 7B* (Taori et al. , 2023) 73.9 TT 73.9 66.1 59.8 43.3 434 62.5 Alpaca Lora 7B* Wang. 2023) 94325793 74 68.8 56.6 43.9 426 628 GPT-J* 6.7B (Wang and Komatsuzaki, 2021) 654 76.2 66.2 64.1 62.2 36.6 38.2 58.4 LLama 7B* (Touvron et al., 2023) 73.1 714 13 66.9 52.5 414 42.4 61.0 LLama 13B* (Touvron et al_, 2023) 68.5 79.1 76.2 70.1 60 44.6 422 63.0 Pythia 6.7B* (Biderman et al., 2023) 63.5 76.3 64 61.1 61.3 35.2 37.2 56.9 Pythia 12B* (Biderman et al., 2023) 67.7 16.6 67.3 63.8 63.9 34.8 38 58.9 Fastchat TS* (Zheng et al., 2023) 815 64.6 46.3 618 49.3 (33.2. 39.4 53.7 Fastchat Vicufia* 7B (Zheng et al., 2023) 76.6 77.2 70.7 67.3 53.5 41.2 40.8 61.0 Fastchat Vicufia 13B* (Zheng et al., 2023) 815 76.8 73.3 66.7 57.4 42.7 3.6 63.1 Stable Vicufia RLHF* (Stability-Al, 2023) 82.3 78.6 74.1 70.9 61 43.5 444 65.0 StableLM Tuned* (Stability-Al, 2023) 625 71.2 53.6 54.8 52.4 31 33.4 SUS StableLM Base* (Stability-Al, 2023) 60.1 67.4 412 50.1 44.9 27 32 46.1 Koala 13B* (Geng et al., 2023) 765 71.9 72.6 68.8 54.3 4l 42.8 62.0 Open Assistant Pythia 12B* 67.9 3 68.1 65 64.2 40.4 43.2 61.0 Mosaic MPT7B (MosaicML-Team, 2023) 748 193 76.3 68.6 70 42.2 42.6 64.8 Mosaic mpt-instruct (MosaicML-Team, 2023) 743 80.4 77.2. 678 72.2 44.6 43 65.6 Mosaic mpt-chat (MosaicML-Team, 2023) 771 78.2 74.5 67.5 69.4 43.3 44.2 9 Wizard 7B xu et al., 2023) 74 772 69.9 66,5 56.8 40.5 42.6 61,7 Wizard 7B Uncensored (Xu et al., 2023) 717 74.2 68 65.2 53.5 38,7 416 59.8 Wizard 13B Uncensored (Xu et al,, 2023) 784 15.5 21 69.5 57.5 40.4 44 62.5 GPT4-x-Vicuna-13b (Nous-Research, 2023a) 813 75 75.2 65 58.7 43,9 43.6 63,2 Falcon 7b (Almazrouei et al., 2023) 7236 80.7 16.3 67,3 1 43.3 444 65.2 Falcon 7b instruct (Almazrouei et al., 2023) 9 78.6 69.8 66.7 619) 4a 4 OS text-davinci-003 88.1 83.8 834 75.8 83.9 63.9 SLO 2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tables[0].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AH-qZDs_Q8b",
        "outputId": "59fe98d0-fb20-4695-e504-69daa6faa30f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unstructured.documents.elements.ElementMetadata at 0x7a0e72741f00>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table_html = tables[0].metadata.text_as_html"
      ],
      "metadata": {
        "id": "fGGVSdYq_Q-n"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "5w2eKy_f_RA-",
        "outputId": "f05f1140-41c1-4bca-d7a4-86b119bd498f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<table><thead><tr><th>Model</th><th>BoolQ</th><th>PIQA</th><th>HellaSwag</th><th>WinoG.</th><th>ARC-c</th><th>ARC-c</th><th>OBQA</th><th>Avg</th></tr></thead><tbody><tr><td>GPT4AII-J 6B v1.0*</td><td>73.4</td><td>74.8</td><td>634</td><td>64.7</td><td>54.9</td><td>36</td><td>40.2</td><td>58.2</td></tr><tr><td>GPT4AII-J v1.1-breezy*</td><td>74</td><td>75.1</td><td>63.2</td><td>63.6</td><td>55.4</td><td>34.9</td><td>38.4</td><td>SL</td></tr><tr><td>GPT4AIIL-J v1.2-jazzy*</td><td>74.8</td><td>74.9</td><td>63.6</td><td>638</td><td>56.6</td><td>35.3</td><td>41</td><td>58.6</td></tr><tr><td>GPT4AII-J v1.3-groovy*</td><td>73.6</td><td>74.3</td><td>63.8</td><td>63.5</td><td>57.7</td><td>35</td><td>38.8 ©</td><td>58.1</td></tr><tr><td>GPT4AII-J Lora 6B*</td><td>68.6</td><td>75.8</td><td>66.2</td><td>63.5</td><td>56.4</td><td>35.7</td><td>402</td><td>58.1</td></tr><tr><td>GPT4All LLaMa Lora 7B*</td><td>73.1</td><td>77.6</td><td>721</td><td>67.8</td><td>SIE</td><td>40.4</td><td>40.2</td><td>60.3</td></tr><tr><td>GPT4All 13B snoozy*</td><td>83.3</td><td>79.2</td><td>75</td><td>71.3</td><td>60.9</td><td>44.2</td><td>43.4</td><td>65.3</td></tr><tr><td>GPT4AIl Falcon</td><td>71.6</td><td>79.8</td><td>749</td><td>70.1</td><td>67.9</td><td>4B4</td><td>42.6</td><td>65.2</td></tr><tr><td>Nous-Hermes (Nous-Research, 2023b)</td><td>79.5</td><td>78.9</td><td>80</td><td>19</td><td>74.2</td><td>50.9</td><td>4.4</td><td>688</td></tr><tr><td>Nous-Hermes2 (Nous-Research, 2023c)</td><td>83.9</td><td>80.7</td><td>80.1</td><td>71.3</td><td>75.7</td><td>52.1</td><td>46.2</td><td>70.0</td></tr><tr><td>Nous-Puffin (Nous-Research, 2023d)</td><td>815</td><td>80.7</td><td>80.4</td><td>72.5</td><td>771.6</td><td>50.7</td><td>45.6</td><td>69.9</td></tr><tr><td>Dolly 6B* (Conover et al., 2023a)</td><td>68.8</td><td>71.3</td><td>67.6</td><td>63.9</td><td>62.9</td><td>38.7</td><td>412</td><td>601</td></tr><tr><td>Dolly 12B* (Conover et al., 2023)</td><td>56.7</td><td>75.4</td><td>1</td><td>62.2</td><td>64.6</td><td>38.5</td><td>404</td><td>584</td></tr><tr><td>Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7B* 2023)</td><td>94325793</td><td></td><td>73.9 74</td><td>66.1 68.8</td><td>56.6</td><td>43.3 43.9</td><td>426</td><td>62.8</td></tr><tr><td>Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021)</td><td>654</td><td>76.2</td><td>66.2</td><td>64.1</td><td>62.2</td><td>36.6</td><td>38.2</td><td>58.4</td></tr><tr><td>LLama 7B* (Touvron et al., 2023)</td><td>73.1</td><td>714</td><td>13</td><td>66.9</td><td>52.5</td><td>414</td><td>42.4</td><td>61.0</td></tr><tr><td>LLama 13B* (Touvron et al_, 2023)</td><td>68.5</td><td>79.1</td><td>76.2</td><td>70.1</td><td>60</td><td>44.6</td><td>422</td><td>63.0</td></tr><tr><td>Pythia 6.7B* (Biderman et al., 2023)</td><td>63.5</td><td>76.3</td><td>64</td><td>61.1</td><td>61.3</td><td>35.2</td><td>37.2</td><td>56.9</td></tr><tr><td>Pythia 12B* (Biderman et al., 2023)</td><td>67.7</td><td>16.6</td><td>67.3</td><td>63.8</td><td>63.9</td><td>34.8</td><td>38</td><td>58.9</td></tr><tr><td>Fastchat TS* (Zheng et al., 2023)</td><td>815</td><td>64.6</td><td>46.3</td><td>618</td><td>49.3</td><td>(33.2.</td><td>39.4</td><td>53.7</td></tr><tr><td>Fastchat Vicufia* 7B (Zheng et al., 2023)</td><td>76.6</td><td>77.2</td><td>70.7</td><td>67.3</td><td>53.5</td><td>41.2</td><td>40.8</td><td>61.0</td></tr><tr><td>Fastchat Vicufia 13B* (Zheng et al., 2023)</td><td>815</td><td>76.8</td><td>73.3</td><td>66.7</td><td>57.4</td><td>42.7</td><td>3.6</td><td>63.1</td></tr><tr><td>Stable Vicufia RLHF* (Stability-Al, 2023)</td><td>82.3</td><td>78.6</td><td>74.1</td><td>70.9</td><td>61</td><td>43.5</td><td>WA</td><td>65.0</td></tr><tr><td>StableLM Tuned* (Stability-Al, 2023)</td><td>625</td><td>71.2</td><td>53.6</td><td>54.8</td><td>52.4</td><td>31</td><td>33.4</td><td>SiS</td></tr><tr><td>StableLM Base* (Stability-Al, 2023)</td><td>60.1</td><td>67.4</td><td>412</td><td>50.1</td><td>44.9</td><td>27</td><td>32</td><td>46.1</td></tr><tr><td>Koala 13B* (Geng et al., 2023)</td><td>765</td><td>71.9</td><td>72.6</td><td>68.8</td><td>54.3</td><td>4l</td><td>42.8</td><td>62.0</td></tr><tr><td>Open Assistant Pythia 12B*</td><td>67.9</td><td>3</td><td>68.1</td><td>65</td><td>64.2</td><td>404</td><td>43.2</td><td>61.0</td></tr><tr><td>Mosaic MPT7B (MosaicML-Team, 2023)</td><td>74.8</td><td>79.3</td><td>76.3</td><td>68.6</td><td>70</td><td>42.2</td><td>42.6</td><td>64.8</td></tr><tr><td>Mosaic mpt-instruct (MosaicML-Team, 2023)</td><td>743</td><td>80.4</td><td>77.2.</td><td>678</td><td>72.2</td><td>44.6</td><td>43</td><td>65.6</td></tr><tr><td>Mosaic mpt-chat (MosaicML-Team, 2023)</td><td>771</td><td>78.2</td><td>74S</td><td>67.5</td><td>69.4</td><td>43.3</td><td>44.2</td><td>64.9</td></tr><tr><td>Wizard 7B xu et al., 2023)</td><td>74</td><td>772</td><td>69.9</td><td>66,5</td><td>56.8</td><td>40.5</td><td>42.6</td><td>61,7</td></tr><tr><td>Wizard 7B Uncensored (Xu et al., 2023)</td><td>717</td><td>74.2</td><td>68</td><td>65.2</td><td>53.5</td><td>38,7</td><td>416</td><td>59.8</td></tr><tr><td>Wizard 13B Uncensored (Xu et al,, 2023)</td><td>784</td><td>15.5</td><td>21</td><td>69.5</td><td>57.5</td><td>40.4</td><td>44</td><td>62.5</td></tr><tr><td>GPT4-x-Vicuna-13b (Nous-Research, 2023a)</td><td>813</td><td>75</td><td>75.2</td><td>65</td><td>58.7</td><td>43,9</td><td>43.6</td><td>63,2</td></tr><tr><td>Falcon 7b (Almazrouei et al., 2023)</td><td>73.6</td><td>80.7</td><td>76.3</td><td>67,3</td><td>7</td><td>43.3</td><td>44.4</td><td>65.2</td></tr><tr><td>Falcon 7b instruct (Almazrouei et al., 2023)</td><td>709</td><td>78.6</td><td>69.8</td><td>66.7</td><td>67.9</td><td>42.7</td><td>412</td><td>62.5</td></tr></tbody></table>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view what the HTML in the metadata field looks like\n",
        "\n",
        "from io import StringIO\n",
        "from lxml import etree\n",
        "\n",
        "parser = etree.XMLParser(remove_blank_text=True)\n",
        "file_obj = StringIO(table_html)\n",
        "tree = etree.parse(file_obj, parser)\n",
        "print(etree.tostring(tree, pretty_print=True).decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkD3FUbQ_RDL",
        "outputId": "f7b5eb67-28db-45d1-e4b5-fb4d5f8a3e2e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<table>\n",
            "  <thead>\n",
            "    <tr>\n",
            "      <th>Model</th>\n",
            "      <th>BoolQ</th>\n",
            "      <th>PIQA</th>\n",
            "      <th>HellaSwag</th>\n",
            "      <th>WinoG.</th>\n",
            "      <th>ARC-c</th>\n",
            "      <th>ARC-c</th>\n",
            "      <th>OBQA</th>\n",
            "      <th>Avg</th>\n",
            "    </tr>\n",
            "  </thead>\n",
            "  <tbody>\n",
            "    <tr>\n",
            "      <td>GPT4AII-J 6B v1.0*</td>\n",
            "      <td>73.4</td>\n",
            "      <td>74.8</td>\n",
            "      <td>634</td>\n",
            "      <td>64.7</td>\n",
            "      <td>54.9</td>\n",
            "      <td>36</td>\n",
            "      <td>40.2</td>\n",
            "      <td>58.2</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>GPT4AII-J v1.1-breezy*</td>\n",
            "      <td>74</td>\n",
            "      <td>75.1</td>\n",
            "      <td>63.2</td>\n",
            "      <td>63.6</td>\n",
            "      <td>55.4</td>\n",
            "      <td>34.9</td>\n",
            "      <td>38.4</td>\n",
            "      <td>SL</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>GPT4AIIL-J v1.2-jazzy*</td>\n",
            "      <td>74.8</td>\n",
            "      <td>74.9</td>\n",
            "      <td>63.6</td>\n",
            "      <td>638</td>\n",
            "      <td>56.6</td>\n",
            "      <td>35.3</td>\n",
            "      <td>41</td>\n",
            "      <td>58.6</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>GPT4AII-J v1.3-groovy*</td>\n",
            "      <td>73.6</td>\n",
            "      <td>74.3</td>\n",
            "      <td>63.8</td>\n",
            "      <td>63.5</td>\n",
            "      <td>57.7</td>\n",
            "      <td>35</td>\n",
            "      <td>38.8 &#169;</td>\n",
            "      <td>58.1</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>GPT4AII-J Lora 6B*</td>\n",
            "      <td>68.6</td>\n",
            "      <td>75.8</td>\n",
            "      <td>66.2</td>\n",
            "      <td>63.5</td>\n",
            "      <td>56.4</td>\n",
            "      <td>35.7</td>\n",
            "      <td>402</td>\n",
            "      <td>58.1</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>GPT4All LLaMa Lora 7B*</td>\n",
            "      <td>73.1</td>\n",
            "      <td>77.6</td>\n",
            "      <td>721</td>\n",
            "      <td>67.8</td>\n",
            "      <td>SIE</td>\n",
            "      <td>40.4</td>\n",
            "      <td>40.2</td>\n",
            "      <td>60.3</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>GPT4All 13B snoozy*</td>\n",
            "      <td>83.3</td>\n",
            "      <td>79.2</td>\n",
            "      <td>75</td>\n",
            "      <td>71.3</td>\n",
            "      <td>60.9</td>\n",
            "      <td>44.2</td>\n",
            "      <td>43.4</td>\n",
            "      <td>65.3</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>GPT4AIl Falcon</td>\n",
            "      <td>71.6</td>\n",
            "      <td>79.8</td>\n",
            "      <td>749</td>\n",
            "      <td>70.1</td>\n",
            "      <td>67.9</td>\n",
            "      <td>4B4</td>\n",
            "      <td>42.6</td>\n",
            "      <td>65.2</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Nous-Hermes (Nous-Research, 2023b)</td>\n",
            "      <td>79.5</td>\n",
            "      <td>78.9</td>\n",
            "      <td>80</td>\n",
            "      <td>19</td>\n",
            "      <td>74.2</td>\n",
            "      <td>50.9</td>\n",
            "      <td>4.4</td>\n",
            "      <td>688</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Nous-Hermes2 (Nous-Research, 2023c)</td>\n",
            "      <td>83.9</td>\n",
            "      <td>80.7</td>\n",
            "      <td>80.1</td>\n",
            "      <td>71.3</td>\n",
            "      <td>75.7</td>\n",
            "      <td>52.1</td>\n",
            "      <td>46.2</td>\n",
            "      <td>70.0</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Nous-Puffin (Nous-Research, 2023d)</td>\n",
            "      <td>815</td>\n",
            "      <td>80.7</td>\n",
            "      <td>80.4</td>\n",
            "      <td>72.5</td>\n",
            "      <td>771.6</td>\n",
            "      <td>50.7</td>\n",
            "      <td>45.6</td>\n",
            "      <td>69.9</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Dolly 6B* (Conover et al., 2023a)</td>\n",
            "      <td>68.8</td>\n",
            "      <td>71.3</td>\n",
            "      <td>67.6</td>\n",
            "      <td>63.9</td>\n",
            "      <td>62.9</td>\n",
            "      <td>38.7</td>\n",
            "      <td>412</td>\n",
            "      <td>601</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Dolly 12B* (Conover et al., 2023)</td>\n",
            "      <td>56.7</td>\n",
            "      <td>75.4</td>\n",
            "      <td>1</td>\n",
            "      <td>62.2</td>\n",
            "      <td>64.6</td>\n",
            "      <td>38.5</td>\n",
            "      <td>404</td>\n",
            "      <td>584</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7B* 2023)</td>\n",
            "      <td>94325793</td>\n",
            "      <td/>\n",
            "      <td>73.9 74</td>\n",
            "      <td>66.1 68.8</td>\n",
            "      <td>56.6</td>\n",
            "      <td>43.3 43.9</td>\n",
            "      <td>426</td>\n",
            "      <td>62.8</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021)</td>\n",
            "      <td>654</td>\n",
            "      <td>76.2</td>\n",
            "      <td>66.2</td>\n",
            "      <td>64.1</td>\n",
            "      <td>62.2</td>\n",
            "      <td>36.6</td>\n",
            "      <td>38.2</td>\n",
            "      <td>58.4</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>LLama 7B* (Touvron et al., 2023)</td>\n",
            "      <td>73.1</td>\n",
            "      <td>714</td>\n",
            "      <td>13</td>\n",
            "      <td>66.9</td>\n",
            "      <td>52.5</td>\n",
            "      <td>414</td>\n",
            "      <td>42.4</td>\n",
            "      <td>61.0</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>LLama 13B* (Touvron et al_, 2023)</td>\n",
            "      <td>68.5</td>\n",
            "      <td>79.1</td>\n",
            "      <td>76.2</td>\n",
            "      <td>70.1</td>\n",
            "      <td>60</td>\n",
            "      <td>44.6</td>\n",
            "      <td>422</td>\n",
            "      <td>63.0</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Pythia 6.7B* (Biderman et al., 2023)</td>\n",
            "      <td>63.5</td>\n",
            "      <td>76.3</td>\n",
            "      <td>64</td>\n",
            "      <td>61.1</td>\n",
            "      <td>61.3</td>\n",
            "      <td>35.2</td>\n",
            "      <td>37.2</td>\n",
            "      <td>56.9</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Pythia 12B* (Biderman et al., 2023)</td>\n",
            "      <td>67.7</td>\n",
            "      <td>16.6</td>\n",
            "      <td>67.3</td>\n",
            "      <td>63.8</td>\n",
            "      <td>63.9</td>\n",
            "      <td>34.8</td>\n",
            "      <td>38</td>\n",
            "      <td>58.9</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Fastchat TS* (Zheng et al., 2023)</td>\n",
            "      <td>815</td>\n",
            "      <td>64.6</td>\n",
            "      <td>46.3</td>\n",
            "      <td>618</td>\n",
            "      <td>49.3</td>\n",
            "      <td>(33.2.</td>\n",
            "      <td>39.4</td>\n",
            "      <td>53.7</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Fastchat Vicufia* 7B (Zheng et al., 2023)</td>\n",
            "      <td>76.6</td>\n",
            "      <td>77.2</td>\n",
            "      <td>70.7</td>\n",
            "      <td>67.3</td>\n",
            "      <td>53.5</td>\n",
            "      <td>41.2</td>\n",
            "      <td>40.8</td>\n",
            "      <td>61.0</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Fastchat Vicufia 13B* (Zheng et al., 2023)</td>\n",
            "      <td>815</td>\n",
            "      <td>76.8</td>\n",
            "      <td>73.3</td>\n",
            "      <td>66.7</td>\n",
            "      <td>57.4</td>\n",
            "      <td>42.7</td>\n",
            "      <td>3.6</td>\n",
            "      <td>63.1</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Stable Vicufia RLHF* (Stability-Al, 2023)</td>\n",
            "      <td>82.3</td>\n",
            "      <td>78.6</td>\n",
            "      <td>74.1</td>\n",
            "      <td>70.9</td>\n",
            "      <td>61</td>\n",
            "      <td>43.5</td>\n",
            "      <td>WA</td>\n",
            "      <td>65.0</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>StableLM Tuned* (Stability-Al, 2023)</td>\n",
            "      <td>625</td>\n",
            "      <td>71.2</td>\n",
            "      <td>53.6</td>\n",
            "      <td>54.8</td>\n",
            "      <td>52.4</td>\n",
            "      <td>31</td>\n",
            "      <td>33.4</td>\n",
            "      <td>SiS</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>StableLM Base* (Stability-Al, 2023)</td>\n",
            "      <td>60.1</td>\n",
            "      <td>67.4</td>\n",
            "      <td>412</td>\n",
            "      <td>50.1</td>\n",
            "      <td>44.9</td>\n",
            "      <td>27</td>\n",
            "      <td>32</td>\n",
            "      <td>46.1</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Koala 13B* (Geng et al., 2023)</td>\n",
            "      <td>765</td>\n",
            "      <td>71.9</td>\n",
            "      <td>72.6</td>\n",
            "      <td>68.8</td>\n",
            "      <td>54.3</td>\n",
            "      <td>4l</td>\n",
            "      <td>42.8</td>\n",
            "      <td>62.0</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Open Assistant Pythia 12B*</td>\n",
            "      <td>67.9</td>\n",
            "      <td>3</td>\n",
            "      <td>68.1</td>\n",
            "      <td>65</td>\n",
            "      <td>64.2</td>\n",
            "      <td>404</td>\n",
            "      <td>43.2</td>\n",
            "      <td>61.0</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Mosaic MPT7B (MosaicML-Team, 2023)</td>\n",
            "      <td>74.8</td>\n",
            "      <td>79.3</td>\n",
            "      <td>76.3</td>\n",
            "      <td>68.6</td>\n",
            "      <td>70</td>\n",
            "      <td>42.2</td>\n",
            "      <td>42.6</td>\n",
            "      <td>64.8</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Mosaic mpt-instruct (MosaicML-Team, 2023)</td>\n",
            "      <td>743</td>\n",
            "      <td>80.4</td>\n",
            "      <td>77.2.</td>\n",
            "      <td>678</td>\n",
            "      <td>72.2</td>\n",
            "      <td>44.6</td>\n",
            "      <td>43</td>\n",
            "      <td>65.6</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Mosaic mpt-chat (MosaicML-Team, 2023)</td>\n",
            "      <td>771</td>\n",
            "      <td>78.2</td>\n",
            "      <td>74S</td>\n",
            "      <td>67.5</td>\n",
            "      <td>69.4</td>\n",
            "      <td>43.3</td>\n",
            "      <td>44.2</td>\n",
            "      <td>64.9</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Wizard 7B xu et al., 2023)</td>\n",
            "      <td>74</td>\n",
            "      <td>772</td>\n",
            "      <td>69.9</td>\n",
            "      <td>66,5</td>\n",
            "      <td>56.8</td>\n",
            "      <td>40.5</td>\n",
            "      <td>42.6</td>\n",
            "      <td>61,7</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Wizard 7B Uncensored (Xu et al., 2023)</td>\n",
            "      <td>717</td>\n",
            "      <td>74.2</td>\n",
            "      <td>68</td>\n",
            "      <td>65.2</td>\n",
            "      <td>53.5</td>\n",
            "      <td>38,7</td>\n",
            "      <td>416</td>\n",
            "      <td>59.8</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Wizard 13B Uncensored (Xu et al,, 2023)</td>\n",
            "      <td>784</td>\n",
            "      <td>15.5</td>\n",
            "      <td>21</td>\n",
            "      <td>69.5</td>\n",
            "      <td>57.5</td>\n",
            "      <td>40.4</td>\n",
            "      <td>44</td>\n",
            "      <td>62.5</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>GPT4-x-Vicuna-13b (Nous-Research, 2023a)</td>\n",
            "      <td>813</td>\n",
            "      <td>75</td>\n",
            "      <td>75.2</td>\n",
            "      <td>65</td>\n",
            "      <td>58.7</td>\n",
            "      <td>43,9</td>\n",
            "      <td>43.6</td>\n",
            "      <td>63,2</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Falcon 7b (Almazrouei et al., 2023)</td>\n",
            "      <td>73.6</td>\n",
            "      <td>80.7</td>\n",
            "      <td>76.3</td>\n",
            "      <td>67,3</td>\n",
            "      <td>7</td>\n",
            "      <td>43.3</td>\n",
            "      <td>44.4</td>\n",
            "      <td>65.2</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Falcon 7b instruct (Almazrouei et al., 2023)</td>\n",
            "      <td>709</td>\n",
            "      <td>78.6</td>\n",
            "      <td>69.8</td>\n",
            "      <td>66.7</td>\n",
            "      <td>67.9</td>\n",
            "      <td>42.7</td>\n",
            "      <td>412</td>\n",
            "      <td>62.5</td>\n",
            "    </tr>\n",
            "  </tbody>\n",
            "</table>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's display this table\n",
        "\n",
        "from IPython.core.display import HTML\n",
        "HTML(table_html)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "id": "SGaEL6Yx_RFk",
        "outputId": "8635d1c1-80b0-423b-9ba6-8e0bb85fdc37"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table><thead><tr><th>Model</th><th>BoolQ</th><th>PIQA</th><th>HellaSwag</th><th>WinoG.</th><th>ARC-c</th><th>ARC-c</th><th>OBQA</th><th>Avg</th></tr></thead><tbody><tr><td>GPT4AII-J 6B v1.0*</td><td>73.4</td><td>74.8</td><td>634</td><td>64.7</td><td>54.9</td><td>36</td><td>40.2</td><td>58.2</td></tr><tr><td>GPT4AII-J v1.1-breezy*</td><td>74</td><td>75.1</td><td>63.2</td><td>63.6</td><td>55.4</td><td>34.9</td><td>38.4</td><td>SL</td></tr><tr><td>GPT4AIIL-J v1.2-jazzy*</td><td>74.8</td><td>74.9</td><td>63.6</td><td>638</td><td>56.6</td><td>35.3</td><td>41</td><td>58.6</td></tr><tr><td>GPT4AII-J v1.3-groovy*</td><td>73.6</td><td>74.3</td><td>63.8</td><td>63.5</td><td>57.7</td><td>35</td><td>38.8 ©</td><td>58.1</td></tr><tr><td>GPT4AII-J Lora 6B*</td><td>68.6</td><td>75.8</td><td>66.2</td><td>63.5</td><td>56.4</td><td>35.7</td><td>402</td><td>58.1</td></tr><tr><td>GPT4All LLaMa Lora 7B*</td><td>73.1</td><td>77.6</td><td>721</td><td>67.8</td><td>SIE</td><td>40.4</td><td>40.2</td><td>60.3</td></tr><tr><td>GPT4All 13B snoozy*</td><td>83.3</td><td>79.2</td><td>75</td><td>71.3</td><td>60.9</td><td>44.2</td><td>43.4</td><td>65.3</td></tr><tr><td>GPT4AIl Falcon</td><td>71.6</td><td>79.8</td><td>749</td><td>70.1</td><td>67.9</td><td>4B4</td><td>42.6</td><td>65.2</td></tr><tr><td>Nous-Hermes (Nous-Research, 2023b)</td><td>79.5</td><td>78.9</td><td>80</td><td>19</td><td>74.2</td><td>50.9</td><td>4.4</td><td>688</td></tr><tr><td>Nous-Hermes2 (Nous-Research, 2023c)</td><td>83.9</td><td>80.7</td><td>80.1</td><td>71.3</td><td>75.7</td><td>52.1</td><td>46.2</td><td>70.0</td></tr><tr><td>Nous-Puffin (Nous-Research, 2023d)</td><td>815</td><td>80.7</td><td>80.4</td><td>72.5</td><td>771.6</td><td>50.7</td><td>45.6</td><td>69.9</td></tr><tr><td>Dolly 6B* (Conover et al., 2023a)</td><td>68.8</td><td>71.3</td><td>67.6</td><td>63.9</td><td>62.9</td><td>38.7</td><td>412</td><td>601</td></tr><tr><td>Dolly 12B* (Conover et al., 2023)</td><td>56.7</td><td>75.4</td><td>1</td><td>62.2</td><td>64.6</td><td>38.5</td><td>404</td><td>584</td></tr><tr><td>Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7B* 2023)</td><td>94325793</td><td></td><td>73.9 74</td><td>66.1 68.8</td><td>56.6</td><td>43.3 43.9</td><td>426</td><td>62.8</td></tr><tr><td>Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021)</td><td>654</td><td>76.2</td><td>66.2</td><td>64.1</td><td>62.2</td><td>36.6</td><td>38.2</td><td>58.4</td></tr><tr><td>LLama 7B* (Touvron et al., 2023)</td><td>73.1</td><td>714</td><td>13</td><td>66.9</td><td>52.5</td><td>414</td><td>42.4</td><td>61.0</td></tr><tr><td>LLama 13B* (Touvron et al_, 2023)</td><td>68.5</td><td>79.1</td><td>76.2</td><td>70.1</td><td>60</td><td>44.6</td><td>422</td><td>63.0</td></tr><tr><td>Pythia 6.7B* (Biderman et al., 2023)</td><td>63.5</td><td>76.3</td><td>64</td><td>61.1</td><td>61.3</td><td>35.2</td><td>37.2</td><td>56.9</td></tr><tr><td>Pythia 12B* (Biderman et al., 2023)</td><td>67.7</td><td>16.6</td><td>67.3</td><td>63.8</td><td>63.9</td><td>34.8</td><td>38</td><td>58.9</td></tr><tr><td>Fastchat TS* (Zheng et al., 2023)</td><td>815</td><td>64.6</td><td>46.3</td><td>618</td><td>49.3</td><td>(33.2.</td><td>39.4</td><td>53.7</td></tr><tr><td>Fastchat Vicufia* 7B (Zheng et al., 2023)</td><td>76.6</td><td>77.2</td><td>70.7</td><td>67.3</td><td>53.5</td><td>41.2</td><td>40.8</td><td>61.0</td></tr><tr><td>Fastchat Vicufia 13B* (Zheng et al., 2023)</td><td>815</td><td>76.8</td><td>73.3</td><td>66.7</td><td>57.4</td><td>42.7</td><td>3.6</td><td>63.1</td></tr><tr><td>Stable Vicufia RLHF* (Stability-Al, 2023)</td><td>82.3</td><td>78.6</td><td>74.1</td><td>70.9</td><td>61</td><td>43.5</td><td>WA</td><td>65.0</td></tr><tr><td>StableLM Tuned* (Stability-Al, 2023)</td><td>625</td><td>71.2</td><td>53.6</td><td>54.8</td><td>52.4</td><td>31</td><td>33.4</td><td>SiS</td></tr><tr><td>StableLM Base* (Stability-Al, 2023)</td><td>60.1</td><td>67.4</td><td>412</td><td>50.1</td><td>44.9</td><td>27</td><td>32</td><td>46.1</td></tr><tr><td>Koala 13B* (Geng et al., 2023)</td><td>765</td><td>71.9</td><td>72.6</td><td>68.8</td><td>54.3</td><td>4l</td><td>42.8</td><td>62.0</td></tr><tr><td>Open Assistant Pythia 12B*</td><td>67.9</td><td>3</td><td>68.1</td><td>65</td><td>64.2</td><td>404</td><td>43.2</td><td>61.0</td></tr><tr><td>Mosaic MPT7B (MosaicML-Team, 2023)</td><td>74.8</td><td>79.3</td><td>76.3</td><td>68.6</td><td>70</td><td>42.2</td><td>42.6</td><td>64.8</td></tr><tr><td>Mosaic mpt-instruct (MosaicML-Team, 2023)</td><td>743</td><td>80.4</td><td>77.2.</td><td>678</td><td>72.2</td><td>44.6</td><td>43</td><td>65.6</td></tr><tr><td>Mosaic mpt-chat (MosaicML-Team, 2023)</td><td>771</td><td>78.2</td><td>74S</td><td>67.5</td><td>69.4</td><td>43.3</td><td>44.2</td><td>64.9</td></tr><tr><td>Wizard 7B xu et al., 2023)</td><td>74</td><td>772</td><td>69.9</td><td>66,5</td><td>56.8</td><td>40.5</td><td>42.6</td><td>61,7</td></tr><tr><td>Wizard 7B Uncensored (Xu et al., 2023)</td><td>717</td><td>74.2</td><td>68</td><td>65.2</td><td>53.5</td><td>38,7</td><td>416</td><td>59.8</td></tr><tr><td>Wizard 13B Uncensored (Xu et al,, 2023)</td><td>784</td><td>15.5</td><td>21</td><td>69.5</td><td>57.5</td><td>40.4</td><td>44</td><td>62.5</td></tr><tr><td>GPT4-x-Vicuna-13b (Nous-Research, 2023a)</td><td>813</td><td>75</td><td>75.2</td><td>65</td><td>58.7</td><td>43,9</td><td>43.6</td><td>63,2</td></tr><tr><td>Falcon 7b (Almazrouei et al., 2023)</td><td>73.6</td><td>80.7</td><td>76.3</td><td>67,3</td><td>7</td><td>43.3</td><td>44.4</td><td>65.2</td></tr><tr><td>Falcon 7b instruct (Almazrouei et al., 2023)</td><td>709</td><td>78.6</td><td>69.8</td><td>66.7</td><td>67.9</td><td>42.7</td><td>412</td><td>62.5</td></tr></tbody></table>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Parse the HTML\n",
        "soup = BeautifulSoup(table_html, 'html.parser')\n",
        "\n",
        "# Extract headers and rows\n",
        "headers = [th.get_text() for th in soup.find_all('th')]\n",
        "rows = []\n",
        "\n",
        "for row in soup.find_all('tr')[1:]:  # Skip the header row\n",
        "    cells = row.find_all('td')\n",
        "    row_data = [cell.get_text() for cell in cells]\n",
        "    rows.append(dict(zip(headers, row_data)))  # Map headers to row data\n",
        "\n",
        "# Print the structured table data\n",
        "for row in rows:\n",
        "    print(row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLXCU-ssE1ba",
        "outputId": "55af7195-401d-4395-eb33-d0e729cd7ff1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Model': 'GPT4AII-J 6B v1.0*', 'BoolQ': '73.4', 'PIQA': '74.8', 'HellaSwag': '634', 'WinoG.': '64.7', 'ARC-c': '36', 'OBQA': '40.2', 'Avg': '58.2'}\n",
            "{'Model': 'GPT4AII-J v1.1-breezy*', 'BoolQ': '74', 'PIQA': '75.1', 'HellaSwag': '63.2', 'WinoG.': '63.6', 'ARC-c': '34.9', 'OBQA': '38.4', 'Avg': 'SL'}\n",
            "{'Model': 'GPT4AIIL-J v1.2-jazzy*', 'BoolQ': '74.8', 'PIQA': '74.9', 'HellaSwag': '63.6', 'WinoG.': '638', 'ARC-c': '35.3', 'OBQA': '41', 'Avg': '58.6'}\n",
            "{'Model': 'GPT4AII-J v1.3-groovy*', 'BoolQ': '73.6', 'PIQA': '74.3', 'HellaSwag': '63.8', 'WinoG.': '63.5', 'ARC-c': '35', 'OBQA': '38.8 ©', 'Avg': '58.1'}\n",
            "{'Model': 'GPT4AII-J Lora 6B*', 'BoolQ': '68.6', 'PIQA': '75.8', 'HellaSwag': '66.2', 'WinoG.': '63.5', 'ARC-c': '35.7', 'OBQA': '402', 'Avg': '58.1'}\n",
            "{'Model': 'GPT4All LLaMa Lora 7B*', 'BoolQ': '73.1', 'PIQA': '77.6', 'HellaSwag': '721', 'WinoG.': '67.8', 'ARC-c': '40.4', 'OBQA': '40.2', 'Avg': '60.3'}\n",
            "{'Model': 'GPT4All 13B snoozy*', 'BoolQ': '83.3', 'PIQA': '79.2', 'HellaSwag': '75', 'WinoG.': '71.3', 'ARC-c': '44.2', 'OBQA': '43.4', 'Avg': '65.3'}\n",
            "{'Model': 'GPT4AIl Falcon', 'BoolQ': '71.6', 'PIQA': '79.8', 'HellaSwag': '749', 'WinoG.': '70.1', 'ARC-c': '4B4', 'OBQA': '42.6', 'Avg': '65.2'}\n",
            "{'Model': 'Nous-Hermes (Nous-Research, 2023b)', 'BoolQ': '79.5', 'PIQA': '78.9', 'HellaSwag': '80', 'WinoG.': '19', 'ARC-c': '50.9', 'OBQA': '4.4', 'Avg': '688'}\n",
            "{'Model': 'Nous-Hermes2 (Nous-Research, 2023c)', 'BoolQ': '83.9', 'PIQA': '80.7', 'HellaSwag': '80.1', 'WinoG.': '71.3', 'ARC-c': '52.1', 'OBQA': '46.2', 'Avg': '70.0'}\n",
            "{'Model': 'Nous-Puffin (Nous-Research, 2023d)', 'BoolQ': '815', 'PIQA': '80.7', 'HellaSwag': '80.4', 'WinoG.': '72.5', 'ARC-c': '50.7', 'OBQA': '45.6', 'Avg': '69.9'}\n",
            "{'Model': 'Dolly 6B* (Conover et al., 2023a)', 'BoolQ': '68.8', 'PIQA': '71.3', 'HellaSwag': '67.6', 'WinoG.': '63.9', 'ARC-c': '38.7', 'OBQA': '412', 'Avg': '601'}\n",
            "{'Model': 'Dolly 12B* (Conover et al., 2023)', 'BoolQ': '56.7', 'PIQA': '75.4', 'HellaSwag': '1', 'WinoG.': '62.2', 'ARC-c': '38.5', 'OBQA': '404', 'Avg': '584'}\n",
            "{'Model': 'Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7B* 2023)', 'BoolQ': '94325793', 'PIQA': '', 'HellaSwag': '73.9 74', 'WinoG.': '66.1 68.8', 'ARC-c': '43.3 43.9', 'OBQA': '426', 'Avg': '62.8'}\n",
            "{'Model': 'Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021)', 'BoolQ': '654', 'PIQA': '76.2', 'HellaSwag': '66.2', 'WinoG.': '64.1', 'ARC-c': '36.6', 'OBQA': '38.2', 'Avg': '58.4'}\n",
            "{'Model': 'LLama 7B* (Touvron et al., 2023)', 'BoolQ': '73.1', 'PIQA': '714', 'HellaSwag': '13', 'WinoG.': '66.9', 'ARC-c': '414', 'OBQA': '42.4', 'Avg': '61.0'}\n",
            "{'Model': 'LLama 13B* (Touvron et al_, 2023)', 'BoolQ': '68.5', 'PIQA': '79.1', 'HellaSwag': '76.2', 'WinoG.': '70.1', 'ARC-c': '44.6', 'OBQA': '422', 'Avg': '63.0'}\n",
            "{'Model': 'Pythia 6.7B* (Biderman et al., 2023)', 'BoolQ': '63.5', 'PIQA': '76.3', 'HellaSwag': '64', 'WinoG.': '61.1', 'ARC-c': '35.2', 'OBQA': '37.2', 'Avg': '56.9'}\n",
            "{'Model': 'Pythia 12B* (Biderman et al., 2023)', 'BoolQ': '67.7', 'PIQA': '16.6', 'HellaSwag': '67.3', 'WinoG.': '63.8', 'ARC-c': '34.8', 'OBQA': '38', 'Avg': '58.9'}\n",
            "{'Model': 'Fastchat TS* (Zheng et al., 2023)', 'BoolQ': '815', 'PIQA': '64.6', 'HellaSwag': '46.3', 'WinoG.': '618', 'ARC-c': '(33.2.', 'OBQA': '39.4', 'Avg': '53.7'}\n",
            "{'Model': 'Fastchat Vicufia* 7B (Zheng et al., 2023)', 'BoolQ': '76.6', 'PIQA': '77.2', 'HellaSwag': '70.7', 'WinoG.': '67.3', 'ARC-c': '41.2', 'OBQA': '40.8', 'Avg': '61.0'}\n",
            "{'Model': 'Fastchat Vicufia 13B* (Zheng et al., 2023)', 'BoolQ': '815', 'PIQA': '76.8', 'HellaSwag': '73.3', 'WinoG.': '66.7', 'ARC-c': '42.7', 'OBQA': '3.6', 'Avg': '63.1'}\n",
            "{'Model': 'Stable Vicufia RLHF* (Stability-Al, 2023)', 'BoolQ': '82.3', 'PIQA': '78.6', 'HellaSwag': '74.1', 'WinoG.': '70.9', 'ARC-c': '43.5', 'OBQA': 'WA', 'Avg': '65.0'}\n",
            "{'Model': 'StableLM Tuned* (Stability-Al, 2023)', 'BoolQ': '625', 'PIQA': '71.2', 'HellaSwag': '53.6', 'WinoG.': '54.8', 'ARC-c': '31', 'OBQA': '33.4', 'Avg': 'SiS'}\n",
            "{'Model': 'StableLM Base* (Stability-Al, 2023)', 'BoolQ': '60.1', 'PIQA': '67.4', 'HellaSwag': '412', 'WinoG.': '50.1', 'ARC-c': '27', 'OBQA': '32', 'Avg': '46.1'}\n",
            "{'Model': 'Koala 13B* (Geng et al., 2023)', 'BoolQ': '765', 'PIQA': '71.9', 'HellaSwag': '72.6', 'WinoG.': '68.8', 'ARC-c': '4l', 'OBQA': '42.8', 'Avg': '62.0'}\n",
            "{'Model': 'Open Assistant Pythia 12B*', 'BoolQ': '67.9', 'PIQA': '3', 'HellaSwag': '68.1', 'WinoG.': '65', 'ARC-c': '404', 'OBQA': '43.2', 'Avg': '61.0'}\n",
            "{'Model': 'Mosaic MPT7B (MosaicML-Team, 2023)', 'BoolQ': '74.8', 'PIQA': '79.3', 'HellaSwag': '76.3', 'WinoG.': '68.6', 'ARC-c': '42.2', 'OBQA': '42.6', 'Avg': '64.8'}\n",
            "{'Model': 'Mosaic mpt-instruct (MosaicML-Team, 2023)', 'BoolQ': '743', 'PIQA': '80.4', 'HellaSwag': '77.2.', 'WinoG.': '678', 'ARC-c': '44.6', 'OBQA': '43', 'Avg': '65.6'}\n",
            "{'Model': 'Mosaic mpt-chat (MosaicML-Team, 2023)', 'BoolQ': '771', 'PIQA': '78.2', 'HellaSwag': '74S', 'WinoG.': '67.5', 'ARC-c': '43.3', 'OBQA': '44.2', 'Avg': '64.9'}\n",
            "{'Model': 'Wizard 7B xu et al., 2023)', 'BoolQ': '74', 'PIQA': '772', 'HellaSwag': '69.9', 'WinoG.': '66,5', 'ARC-c': '40.5', 'OBQA': '42.6', 'Avg': '61,7'}\n",
            "{'Model': 'Wizard 7B Uncensored (Xu et al., 2023)', 'BoolQ': '717', 'PIQA': '74.2', 'HellaSwag': '68', 'WinoG.': '65.2', 'ARC-c': '38,7', 'OBQA': '416', 'Avg': '59.8'}\n",
            "{'Model': 'Wizard 13B Uncensored (Xu et al,, 2023)', 'BoolQ': '784', 'PIQA': '15.5', 'HellaSwag': '21', 'WinoG.': '69.5', 'ARC-c': '40.4', 'OBQA': '44', 'Avg': '62.5'}\n",
            "{'Model': 'GPT4-x-Vicuna-13b (Nous-Research, 2023a)', 'BoolQ': '813', 'PIQA': '75', 'HellaSwag': '75.2', 'WinoG.': '65', 'ARC-c': '43,9', 'OBQA': '43.6', 'Avg': '63,2'}\n",
            "{'Model': 'Falcon 7b (Almazrouei et al., 2023)', 'BoolQ': '73.6', 'PIQA': '80.7', 'HellaSwag': '76.3', 'WinoG.': '67,3', 'ARC-c': '43.3', 'OBQA': '44.4', 'Avg': '65.2'}\n",
            "{'Model': 'Falcon 7b instruct (Almazrouei et al., 2023)', 'BoolQ': '709', 'PIQA': '78.6', 'HellaSwag': '69.8', 'WinoG.': '66.7', 'ARC-c': '42.7', 'OBQA': '412', 'Avg': '62.5'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the structured data into a plain text format for LLM\n",
        "table_str = \"Here is a table with model performance data:\\n\"\n",
        "table_str += \"Model | BoolQ | PIQA | HellaSwag | WinoG. | ARC-c | ARC-c | OBQA | Avg\\n\"\n",
        "\n",
        "# Add each row to the table string\n",
        "for row in rows:\n",
        "    table_str += \" | \".join([row[\"Model\"], row[\"BoolQ\"], row[\"PIQA\"], row[\"HellaSwag\"], row[\"WinoG.\"], row[\"ARC-c\"], row[\"ARC-c\"], row[\"OBQA\"], row[\"Avg\"]]) + \"\\n\"\n",
        "\n",
        "# Now `table_str` contains the table in a format suitable for LLM input\n",
        "print(table_str)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2AoXsvPFDT1",
        "outputId": "1fa17ab2-a2ce-4dfd-d8f5-8a3c213dc5f4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a table with model performance data:\n",
            "Model | BoolQ | PIQA | HellaSwag | WinoG. | ARC-c | ARC-c | OBQA | Avg\n",
            "GPT4AII-J 6B v1.0* | 73.4 | 74.8 | 634 | 64.7 | 36 | 36 | 40.2 | 58.2\n",
            "GPT4AII-J v1.1-breezy* | 74 | 75.1 | 63.2 | 63.6 | 34.9 | 34.9 | 38.4 | SL\n",
            "GPT4AIIL-J v1.2-jazzy* | 74.8 | 74.9 | 63.6 | 638 | 35.3 | 35.3 | 41 | 58.6\n",
            "GPT4AII-J v1.3-groovy* | 73.6 | 74.3 | 63.8 | 63.5 | 35 | 35 | 38.8 © | 58.1\n",
            "GPT4AII-J Lora 6B* | 68.6 | 75.8 | 66.2 | 63.5 | 35.7 | 35.7 | 402 | 58.1\n",
            "GPT4All LLaMa Lora 7B* | 73.1 | 77.6 | 721 | 67.8 | 40.4 | 40.4 | 40.2 | 60.3\n",
            "GPT4All 13B snoozy* | 83.3 | 79.2 | 75 | 71.3 | 44.2 | 44.2 | 43.4 | 65.3\n",
            "GPT4AIl Falcon | 71.6 | 79.8 | 749 | 70.1 | 4B4 | 4B4 | 42.6 | 65.2\n",
            "Nous-Hermes (Nous-Research, 2023b) | 79.5 | 78.9 | 80 | 19 | 50.9 | 50.9 | 4.4 | 688\n",
            "Nous-Hermes2 (Nous-Research, 2023c) | 83.9 | 80.7 | 80.1 | 71.3 | 52.1 | 52.1 | 46.2 | 70.0\n",
            "Nous-Puffin (Nous-Research, 2023d) | 815 | 80.7 | 80.4 | 72.5 | 50.7 | 50.7 | 45.6 | 69.9\n",
            "Dolly 6B* (Conover et al., 2023a) | 68.8 | 71.3 | 67.6 | 63.9 | 38.7 | 38.7 | 412 | 601\n",
            "Dolly 12B* (Conover et al., 2023) | 56.7 | 75.4 | 1 | 62.2 | 38.5 | 38.5 | 404 | 584\n",
            "Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7B* 2023) | 94325793 |  | 73.9 74 | 66.1 68.8 | 43.3 43.9 | 43.3 43.9 | 426 | 62.8\n",
            "Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021) | 654 | 76.2 | 66.2 | 64.1 | 36.6 | 36.6 | 38.2 | 58.4\n",
            "LLama 7B* (Touvron et al., 2023) | 73.1 | 714 | 13 | 66.9 | 414 | 414 | 42.4 | 61.0\n",
            "LLama 13B* (Touvron et al_, 2023) | 68.5 | 79.1 | 76.2 | 70.1 | 44.6 | 44.6 | 422 | 63.0\n",
            "Pythia 6.7B* (Biderman et al., 2023) | 63.5 | 76.3 | 64 | 61.1 | 35.2 | 35.2 | 37.2 | 56.9\n",
            "Pythia 12B* (Biderman et al., 2023) | 67.7 | 16.6 | 67.3 | 63.8 | 34.8 | 34.8 | 38 | 58.9\n",
            "Fastchat TS* (Zheng et al., 2023) | 815 | 64.6 | 46.3 | 618 | (33.2. | (33.2. | 39.4 | 53.7\n",
            "Fastchat Vicufia* 7B (Zheng et al., 2023) | 76.6 | 77.2 | 70.7 | 67.3 | 41.2 | 41.2 | 40.8 | 61.0\n",
            "Fastchat Vicufia 13B* (Zheng et al., 2023) | 815 | 76.8 | 73.3 | 66.7 | 42.7 | 42.7 | 3.6 | 63.1\n",
            "Stable Vicufia RLHF* (Stability-Al, 2023) | 82.3 | 78.6 | 74.1 | 70.9 | 43.5 | 43.5 | WA | 65.0\n",
            "StableLM Tuned* (Stability-Al, 2023) | 625 | 71.2 | 53.6 | 54.8 | 31 | 31 | 33.4 | SiS\n",
            "StableLM Base* (Stability-Al, 2023) | 60.1 | 67.4 | 412 | 50.1 | 27 | 27 | 32 | 46.1\n",
            "Koala 13B* (Geng et al., 2023) | 765 | 71.9 | 72.6 | 68.8 | 4l | 4l | 42.8 | 62.0\n",
            "Open Assistant Pythia 12B* | 67.9 | 3 | 68.1 | 65 | 404 | 404 | 43.2 | 61.0\n",
            "Mosaic MPT7B (MosaicML-Team, 2023) | 74.8 | 79.3 | 76.3 | 68.6 | 42.2 | 42.2 | 42.6 | 64.8\n",
            "Mosaic mpt-instruct (MosaicML-Team, 2023) | 743 | 80.4 | 77.2. | 678 | 44.6 | 44.6 | 43 | 65.6\n",
            "Mosaic mpt-chat (MosaicML-Team, 2023) | 771 | 78.2 | 74S | 67.5 | 43.3 | 43.3 | 44.2 | 64.9\n",
            "Wizard 7B xu et al., 2023) | 74 | 772 | 69.9 | 66,5 | 40.5 | 40.5 | 42.6 | 61,7\n",
            "Wizard 7B Uncensored (Xu et al., 2023) | 717 | 74.2 | 68 | 65.2 | 38,7 | 38,7 | 416 | 59.8\n",
            "Wizard 13B Uncensored (Xu et al,, 2023) | 784 | 15.5 | 21 | 69.5 | 40.4 | 40.4 | 44 | 62.5\n",
            "GPT4-x-Vicuna-13b (Nous-Research, 2023a) | 813 | 75 | 75.2 | 65 | 43,9 | 43,9 | 43.6 | 63,2\n",
            "Falcon 7b (Almazrouei et al., 2023) | 73.6 | 80.7 | 76.3 | 67,3 | 43.3 | 43.3 | 44.4 | 65.2\n",
            "Falcon 7b instruct (Almazrouei et al., 2023) | 709 | 78.6 | 69.8 | 66.7 | 42.7 | 42.7 | 412 | 62.5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install langchain-ollama langchain_core langchain_community"
      ],
      "metadata": {
        "id": "Qkcx1dij_RIO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "from langchain_core.documents import Document\n",
        "from langchain.chains.summarize import load_summarize_chain"
      ],
      "metadata": {
        "id": "aTw4Z-So_RKL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR RUNNING LOCAL\n",
        "\n",
        "\n",
        "# llm = ChatOllama(model=\"llama3.1:8b\")\n",
        "# chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
        "# output = chain.invoke([Document(page_content=table_html)])"
      ],
      "metadata": {
        "id": "lFDdIGbY_RMj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(output['output_text'])"
      ],
      "metadata": {
        "id": "LLr45bTkBehb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HF_TOKEN = ''\n",
        "!huggingface-cli login --token $HF_TOKEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i2GA6MRDAK6",
        "outputId": "2423e030-cf40-42ac-bb2d-5de555bc6c12"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "# Define the Llama model from Hugging Face Hub\n",
        "llama_model = HuggingFaceHub(\n",
        "    repo_id= \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "    model_kwargs={\"temperature\": 0.1, \"max_length\": 1024},\n",
        "    huggingfacehub_api_token=HF_TOKEN\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "Oc9bwvqYBrck"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt template that includes the table content\n",
        "prompt_template = \"\"\"\n",
        "I have the following table data:\n",
        "\n",
        "{table_data}\n",
        "\n",
        "Based on this data, please answer the following question: {question}\n",
        "\"\"\"\n",
        "\n",
        "# Create the prompt template with table data and question placeholders\n",
        "prompt = PromptTemplate(input_variables=[\"table_data\", \"question\"], template=prompt_template)\n",
        "\n",
        "# Create the LLMChain to query the model\n",
        "chain = LLMChain(llm=llama_model, prompt=prompt)\n",
        "\n",
        "# Use the structured table string (`table_str`) and define a question\n",
        "question = \"What is the average score of GPT4AII-J 6B v1.0*?\"\n",
        "answer = chain.run(table_data=table_str, question=question)\n",
        "\n",
        "# Print the result\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T84OQ3itG8wS",
        "outputId": "36ee02e5-8dab-4873-a7da-12d416af5d84"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: \n",
            "I have the following table data:\n",
            "\n",
            "Here is a table with model performance data:\n",
            "Model | BoolQ | PIQA | HellaSwag | WinoG. | ARC-c | ARC-c | OBQA | Avg\n",
            "GPT4AII-J 6B v1.0* | 73.4 | 74.8 | 634 | 64.7 | 36 | 36 | 40.2 | 58.2\n",
            "GPT4AII-J v1.1-breezy* | 74 | 75.1 | 63.2 | 63.6 | 34.9 | 34.9 | 38.4 | SL\n",
            "GPT4AIIL-J v1.2-jazzy* | 74.8 | 74.9 | 63.6 | 638 | 35.3 | 35.3 | 41 | 58.6\n",
            "GPT4AII-J v1.3-groovy* | 73.6 | 74.3 | 63.8 | 63.5 | 35 | 35 | 38.8 © | 58.1\n",
            "GPT4AII-J Lora 6B* | 68.6 | 75.8 | 66.2 | 63.5 | 35.7 | 35.7 | 402 | 58.1\n",
            "GPT4All LLaMa Lora 7B* | 73.1 | 77.6 | 721 | 67.8 | 40.4 | 40.4 | 40.2 | 60.3\n",
            "GPT4All 13B snoozy* | 83.3 | 79.2 | 75 | 71.3 | 44.2 | 44.2 | 43.4 | 65.3\n",
            "GPT4AIl Falcon | 71.6 | 79.8 | 749 | 70.1 | 4B4 | 4B4 | 42.6 | 65.2\n",
            "Nous-Hermes (Nous-Research, 2023b) | 79.5 | 78.9 | 80 | 19 | 50.9 | 50.9 | 4.4 | 688\n",
            "Nous-Hermes2 (Nous-Research, 2023c) | 83.9 | 80.7 | 80.1 | 71.3 | 52.1 | 52.1 | 46.2 | 70.0\n",
            "Nous-Puffin (Nous-Research, 2023d) | 815 | 80.7 | 80.4 | 72.5 | 50.7 | 50.7 | 45.6 | 69.9\n",
            "Dolly 6B* (Conover et al., 2023a) | 68.8 | 71.3 | 67.6 | 63.9 | 38.7 | 38.7 | 412 | 601\n",
            "Dolly 12B* (Conover et al., 2023) | 56.7 | 75.4 | 1 | 62.2 | 38.5 | 38.5 | 404 | 584\n",
            "Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7B* 2023) | 94325793 |  | 73.9 74 | 66.1 68.8 | 43.3 43.9 | 43.3 43.9 | 426 | 62.8\n",
            "Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021) | 654 | 76.2 | 66.2 | 64.1 | 36.6 | 36.6 | 38.2 | 58.4\n",
            "LLama 7B* (Touvron et al., 2023) | 73.1 | 714 | 13 | 66.9 | 414 | 414 | 42.4 | 61.0\n",
            "LLama 13B* (Touvron et al_, 2023) | 68.5 | 79.1 | 76.2 | 70.1 | 44.6 | 44.6 | 422 | 63.0\n",
            "Pythia 6.7B* (Biderman et al., 2023) | 63.5 | 76.3 | 64 | 61.1 | 35.2 | 35.2 | 37.2 | 56.9\n",
            "Pythia 12B* (Biderman et al., 2023) | 67.7 | 16.6 | 67.3 | 63.8 | 34.8 | 34.8 | 38 | 58.9\n",
            "Fastchat TS* (Zheng et al., 2023) | 815 | 64.6 | 46.3 | 618 | (33.2. | (33.2. | 39.4 | 53.7\n",
            "Fastchat Vicufia* 7B (Zheng et al., 2023) | 76.6 | 77.2 | 70.7 | 67.3 | 41.2 | 41.2 | 40.8 | 61.0\n",
            "Fastchat Vicufia 13B* (Zheng et al., 2023) | 815 | 76.8 | 73.3 | 66.7 | 42.7 | 42.7 | 3.6 | 63.1\n",
            "Stable Vicufia RLHF* (Stability-Al, 2023) | 82.3 | 78.6 | 74.1 | 70.9 | 43.5 | 43.5 | WA | 65.0\n",
            "StableLM Tuned* (Stability-Al, 2023) | 625 | 71.2 | 53.6 | 54.8 | 31 | 31 | 33.4 | SiS\n",
            "StableLM Base* (Stability-Al, 2023) | 60.1 | 67.4 | 412 | 50.1 | 27 | 27 | 32 | 46.1\n",
            "Koala 13B* (Geng et al., 2023) | 765 | 71.9 | 72.6 | 68.8 | 4l | 4l | 42.8 | 62.0\n",
            "Open Assistant Pythia 12B* | 67.9 | 3 | 68.1 | 65 | 404 | 404 | 43.2 | 61.0\n",
            "Mosaic MPT7B (MosaicML-Team, 2023) | 74.8 | 79.3 | 76.3 | 68.6 | 42.2 | 42.2 | 42.6 | 64.8\n",
            "Mosaic mpt-instruct (MosaicML-Team, 2023) | 743 | 80.4 | 77.2. | 678 | 44.6 | 44.6 | 43 | 65.6\n",
            "Mosaic mpt-chat (MosaicML-Team, 2023) | 771 | 78.2 | 74S | 67.5 | 43.3 | 43.3 | 44.2 | 64.9\n",
            "Wizard 7B xu et al., 2023) | 74 | 772 | 69.9 | 66,5 | 40.5 | 40.5 | 42.6 | 61,7\n",
            "Wizard 7B Uncensored (Xu et al., 2023) | 717 | 74.2 | 68 | 65.2 | 38,7 | 38,7 | 416 | 59.8\n",
            "Wizard 13B Uncensored (Xu et al,, 2023) | 784 | 15.5 | 21 | 69.5 | 40.4 | 40.4 | 44 | 62.5\n",
            "GPT4-x-Vicuna-13b (Nous-Research, 2023a) | 813 | 75 | 75.2 | 65 | 43,9 | 43,9 | 43.6 | 63,2\n",
            "Falcon 7b (Almazrouei et al., 2023) | 73.6 | 80.7 | 76.3 | 67,3 | 43.3 | 43.3 | 44.4 | 65.2\n",
            "Falcon 7b instruct (Almazrouei et al., 2023) | 709 | 78.6 | 69.8 | 66.7 | 42.7 | 42.7 | 412 | 62.5\n",
            "\n",
            "\n",
            "Based on this data, please answer the following question: What is the average score of GPT4AII-J 6B v1.0*?\n",
            "Answer: 58.2\n",
            "\n",
            "Here is the average score of GPT4AII-J 6B v1.0*: 58.2\n",
            "\n",
            "Here is the average score of GPT4AII-J 6B v1.0*: 58.2\n",
            "\n",
            "Here is the average score of GPT4AII-J 6B v1.0*: 58.2\n",
            "\n",
            "Here is the average score of GPT4AII-J 6B v1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gTH3eVVBrfh",
        "outputId": "7fd141bf-d5cc-4bfb-9313-baae3fe7a264"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert HTML table to pandas DataFrame\n",
        "dfs = pd.read_html(table_html)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie037w7dBriD",
        "outputId": "99a846db-e28b-44a2-eb67-36badf7d0421"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-ed61bc44639e>:4: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  dfs = pd.read_html(table_html)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM2-3Zm2KIKu",
        "outputId": "f71bd895-1bea-4afc-e997-e779836d6763"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[                                                Model       BoolQ   PIQA  \\\n",
              " 0                                  GPT4AII-J 6B v1.0*        73.4   74.8   \n",
              " 1                              GPT4AII-J v1.1-breezy*        74.0   75.1   \n",
              " 2                              GPT4AIIL-J v1.2-jazzy*        74.8   74.9   \n",
              " 3                              GPT4AII-J v1.3-groovy*        73.6   74.3   \n",
              " 4                                  GPT4AII-J Lora 6B*        68.6   75.8   \n",
              " 5                              GPT4All LLaMa Lora 7B*        73.1   77.6   \n",
              " 6                                 GPT4All 13B snoozy*        83.3   79.2   \n",
              " 7                                      GPT4AIl Falcon        71.6   79.8   \n",
              " 8                  Nous-Hermes (Nous-Research, 2023b)        79.5   78.9   \n",
              " 9                 Nous-Hermes2 (Nous-Research, 2023c)        83.9   80.7   \n",
              " 10                 Nous-Puffin (Nous-Research, 2023d)       815.0   80.7   \n",
              " 11                  Dolly 6B* (Conover et al., 2023a)        68.8   71.3   \n",
              " 12                  Dolly 12B* (Conover et al., 2023)        56.7   75.4   \n",
              " 13  Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7...  94325793.0    NaN   \n",
              " 14     Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021)       654.0   76.2   \n",
              " 15                   LLama 7B* (Touvron et al., 2023)        73.1  714.0   \n",
              " 16                  LLama 13B* (Touvron et al_, 2023)        68.5   79.1   \n",
              " 17               Pythia 6.7B* (Biderman et al., 2023)        63.5   76.3   \n",
              " 18                Pythia 12B* (Biderman et al., 2023)        67.7   16.6   \n",
              " 19                  Fastchat TS* (Zheng et al., 2023)       815.0   64.6   \n",
              " 20          Fastchat Vicufia* 7B (Zheng et al., 2023)        76.6   77.2   \n",
              " 21         Fastchat Vicufia 13B* (Zheng et al., 2023)       815.0   76.8   \n",
              " 22          Stable Vicufia RLHF* (Stability-Al, 2023)        82.3   78.6   \n",
              " 23               StableLM Tuned* (Stability-Al, 2023)       625.0   71.2   \n",
              " 24                StableLM Base* (Stability-Al, 2023)        60.1   67.4   \n",
              " 25                     Koala 13B* (Geng et al., 2023)       765.0   71.9   \n",
              " 26                         Open Assistant Pythia 12B*        67.9    3.0   \n",
              " 27                 Mosaic MPT7B (MosaicML-Team, 2023)        74.8   79.3   \n",
              " 28          Mosaic mpt-instruct (MosaicML-Team, 2023)       743.0   80.4   \n",
              " 29              Mosaic mpt-chat (MosaicML-Team, 2023)       771.0   78.2   \n",
              " 30                         Wizard 7B xu et al., 2023)        74.0  772.0   \n",
              " 31             Wizard 7B Uncensored (Xu et al., 2023)       717.0   74.2   \n",
              " 32            Wizard 13B Uncensored (Xu et al,, 2023)       784.0   15.5   \n",
              " 33           GPT4-x-Vicuna-13b (Nous-Research, 2023a)       813.0   75.0   \n",
              " 34                Falcon 7b (Almazrouei et al., 2023)        73.6   80.7   \n",
              " 35       Falcon 7b instruct (Almazrouei et al., 2023)       709.0   78.6   \n",
              " \n",
              "    HellaSwag     WinoG.  ARC-c    ARC-c.1    OBQA   Avg  \n",
              " 0        634       64.7   54.9         36    40.2  58.2  \n",
              " 1       63.2       63.6   55.4       34.9    38.4    SL  \n",
              " 2       63.6        638   56.6       35.3      41  58.6  \n",
              " 3       63.8       63.5   57.7         35  38.8 ©  58.1  \n",
              " 4       66.2       63.5   56.4       35.7     402  58.1  \n",
              " 5        721       67.8    SIE       40.4    40.2  60.3  \n",
              " 6         75       71.3   60.9       44.2    43.4  65.3  \n",
              " 7        749       70.1   67.9        4B4    42.6  65.2  \n",
              " 8         80         19   74.2       50.9     4.4   688  \n",
              " 9       80.1       71.3   75.7       52.1    46.2  70.0  \n",
              " 10      80.4       72.5  771.6       50.7    45.6  69.9  \n",
              " 11      67.6       63.9   62.9       38.7     412   601  \n",
              " 12         1       62.2   64.6       38.5     404   584  \n",
              " 13   73.9 74  66.1 68.8   56.6  43.3 43.9     426  62.8  \n",
              " 14      66.2       64.1   62.2       36.6    38.2  58.4  \n",
              " 15        13       66.9   52.5        414    42.4  61.0  \n",
              " 16      76.2       70.1     60       44.6     422  63.0  \n",
              " 17        64       61.1   61.3       35.2    37.2  56.9  \n",
              " 18      67.3       63.8   63.9       34.8      38  58.9  \n",
              " 19      46.3        618   49.3     (33.2.    39.4  53.7  \n",
              " 20      70.7       67.3   53.5       41.2    40.8  61.0  \n",
              " 21      73.3       66.7   57.4       42.7     3.6  63.1  \n",
              " 22      74.1       70.9     61       43.5      WA  65.0  \n",
              " 23      53.6       54.8   52.4         31    33.4   SiS  \n",
              " 24       412       50.1   44.9         27      32  46.1  \n",
              " 25      72.6       68.8   54.3         4l    42.8  62.0  \n",
              " 26      68.1         65   64.2        404    43.2  61.0  \n",
              " 27      76.3       68.6     70       42.2    42.6  64.8  \n",
              " 28     77.2.        678   72.2       44.6      43  65.6  \n",
              " 29       74S       67.5   69.4       43.3    44.2  64.9  \n",
              " 30      69.9        665   56.8       40.5    42.6   617  \n",
              " 31        68       65.2   53.5        387     416  59.8  \n",
              " 32        21       69.5   57.5       40.4      44  62.5  \n",
              " 33      75.2         65   58.7        439    43.6   632  \n",
              " 34      76.3        673      7       43.3    44.4  65.2  \n",
              " 35      69.8       66.7   67.9       42.7     412  62.5  ]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming there's only one table, get the DataFrame\n",
        "df = dfs[0]\n",
        "\n",
        "# Now you have the DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8kH1NSmKINd",
        "outputId": "6f53cc72-95cf-4903-fe9c-18e33feb0b3f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Model       BoolQ   PIQA  \\\n",
            "0                                  GPT4AII-J 6B v1.0*        73.4   74.8   \n",
            "1                              GPT4AII-J v1.1-breezy*        74.0   75.1   \n",
            "2                              GPT4AIIL-J v1.2-jazzy*        74.8   74.9   \n",
            "3                              GPT4AII-J v1.3-groovy*        73.6   74.3   \n",
            "4                                  GPT4AII-J Lora 6B*        68.6   75.8   \n",
            "5                              GPT4All LLaMa Lora 7B*        73.1   77.6   \n",
            "6                                 GPT4All 13B snoozy*        83.3   79.2   \n",
            "7                                      GPT4AIl Falcon        71.6   79.8   \n",
            "8                  Nous-Hermes (Nous-Research, 2023b)        79.5   78.9   \n",
            "9                 Nous-Hermes2 (Nous-Research, 2023c)        83.9   80.7   \n",
            "10                 Nous-Puffin (Nous-Research, 2023d)       815.0   80.7   \n",
            "11                  Dolly 6B* (Conover et al., 2023a)        68.8   71.3   \n",
            "12                  Dolly 12B* (Conover et al., 2023)        56.7   75.4   \n",
            "13  Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7...  94325793.0    NaN   \n",
            "14     Wang. GPT-J* 6.7B (Wang and Komatsuzaki, 2021)       654.0   76.2   \n",
            "15                   LLama 7B* (Touvron et al., 2023)        73.1  714.0   \n",
            "16                  LLama 13B* (Touvron et al_, 2023)        68.5   79.1   \n",
            "17               Pythia 6.7B* (Biderman et al., 2023)        63.5   76.3   \n",
            "18                Pythia 12B* (Biderman et al., 2023)        67.7   16.6   \n",
            "19                  Fastchat TS* (Zheng et al., 2023)       815.0   64.6   \n",
            "20          Fastchat Vicufia* 7B (Zheng et al., 2023)        76.6   77.2   \n",
            "21         Fastchat Vicufia 13B* (Zheng et al., 2023)       815.0   76.8   \n",
            "22          Stable Vicufia RLHF* (Stability-Al, 2023)        82.3   78.6   \n",
            "23               StableLM Tuned* (Stability-Al, 2023)       625.0   71.2   \n",
            "24                StableLM Base* (Stability-Al, 2023)        60.1   67.4   \n",
            "25                     Koala 13B* (Geng et al., 2023)       765.0   71.9   \n",
            "26                         Open Assistant Pythia 12B*        67.9    3.0   \n",
            "27                 Mosaic MPT7B (MosaicML-Team, 2023)        74.8   79.3   \n",
            "28          Mosaic mpt-instruct (MosaicML-Team, 2023)       743.0   80.4   \n",
            "29              Mosaic mpt-chat (MosaicML-Team, 2023)       771.0   78.2   \n",
            "30                         Wizard 7B xu et al., 2023)        74.0  772.0   \n",
            "31             Wizard 7B Uncensored (Xu et al., 2023)       717.0   74.2   \n",
            "32            Wizard 13B Uncensored (Xu et al,, 2023)       784.0   15.5   \n",
            "33           GPT4-x-Vicuna-13b (Nous-Research, 2023a)       813.0   75.0   \n",
            "34                Falcon 7b (Almazrouei et al., 2023)        73.6   80.7   \n",
            "35       Falcon 7b instruct (Almazrouei et al., 2023)       709.0   78.6   \n",
            "\n",
            "   HellaSwag     WinoG.  ARC-c    ARC-c.1    OBQA   Avg  \n",
            "0        634       64.7   54.9         36    40.2  58.2  \n",
            "1       63.2       63.6   55.4       34.9    38.4    SL  \n",
            "2       63.6        638   56.6       35.3      41  58.6  \n",
            "3       63.8       63.5   57.7         35  38.8 ©  58.1  \n",
            "4       66.2       63.5   56.4       35.7     402  58.1  \n",
            "5        721       67.8    SIE       40.4    40.2  60.3  \n",
            "6         75       71.3   60.9       44.2    43.4  65.3  \n",
            "7        749       70.1   67.9        4B4    42.6  65.2  \n",
            "8         80         19   74.2       50.9     4.4   688  \n",
            "9       80.1       71.3   75.7       52.1    46.2  70.0  \n",
            "10      80.4       72.5  771.6       50.7    45.6  69.9  \n",
            "11      67.6       63.9   62.9       38.7     412   601  \n",
            "12         1       62.2   64.6       38.5     404   584  \n",
            "13   73.9 74  66.1 68.8   56.6  43.3 43.9     426  62.8  \n",
            "14      66.2       64.1   62.2       36.6    38.2  58.4  \n",
            "15        13       66.9   52.5        414    42.4  61.0  \n",
            "16      76.2       70.1     60       44.6     422  63.0  \n",
            "17        64       61.1   61.3       35.2    37.2  56.9  \n",
            "18      67.3       63.8   63.9       34.8      38  58.9  \n",
            "19      46.3        618   49.3     (33.2.    39.4  53.7  \n",
            "20      70.7       67.3   53.5       41.2    40.8  61.0  \n",
            "21      73.3       66.7   57.4       42.7     3.6  63.1  \n",
            "22      74.1       70.9     61       43.5      WA  65.0  \n",
            "23      53.6       54.8   52.4         31    33.4   SiS  \n",
            "24       412       50.1   44.9         27      32  46.1  \n",
            "25      72.6       68.8   54.3         4l    42.8  62.0  \n",
            "26      68.1         65   64.2        404    43.2  61.0  \n",
            "27      76.3       68.6     70       42.2    42.6  64.8  \n",
            "28     77.2.        678   72.2       44.6      43  65.6  \n",
            "29       74S       67.5   69.4       43.3    44.2  64.9  \n",
            "30      69.9        665   56.8       40.5    42.6   617  \n",
            "31        68       65.2   53.5        387     416  59.8  \n",
            "32        21       69.5   57.5       40.4      44  62.5  \n",
            "33      75.2         65   58.7        439    43.6   632  \n",
            "34      76.3        673      7       43.3    44.4  65.2  \n",
            "35      69.8       66.7   67.9       42.7     412  62.5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30n5LgmJKIQH",
        "outputId": "30987b89-78e4-43bd-9276-90a8f10c674e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bVPY-B6qKU9l",
        "outputId": "b17d0684-c170-4c6b-80c2-a87c7c61eaf4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Model  BoolQ  PIQA HellaSwag WinoG. ARC-c ARC-c.1    OBQA  \\\n",
              "0      GPT4AII-J 6B v1.0*   73.4  74.8       634   64.7  54.9      36    40.2   \n",
              "1  GPT4AII-J v1.1-breezy*   74.0  75.1      63.2   63.6  55.4    34.9    38.4   \n",
              "2  GPT4AIIL-J v1.2-jazzy*   74.8  74.9      63.6    638  56.6    35.3      41   \n",
              "3  GPT4AII-J v1.3-groovy*   73.6  74.3      63.8   63.5  57.7      35  38.8 ©   \n",
              "4      GPT4AII-J Lora 6B*   68.6  75.8      66.2   63.5  56.4    35.7     402   \n",
              "\n",
              "    Avg  \n",
              "0  58.2  \n",
              "1    SL  \n",
              "2  58.6  \n",
              "3  58.1  \n",
              "4  58.1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3566fd92-f610-46bc-a07d-8cb21e9fbe79\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>BoolQ</th>\n",
              "      <th>PIQA</th>\n",
              "      <th>HellaSwag</th>\n",
              "      <th>WinoG.</th>\n",
              "      <th>ARC-c</th>\n",
              "      <th>ARC-c.1</th>\n",
              "      <th>OBQA</th>\n",
              "      <th>Avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GPT4AII-J 6B v1.0*</td>\n",
              "      <td>73.4</td>\n",
              "      <td>74.8</td>\n",
              "      <td>634</td>\n",
              "      <td>64.7</td>\n",
              "      <td>54.9</td>\n",
              "      <td>36</td>\n",
              "      <td>40.2</td>\n",
              "      <td>58.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GPT4AII-J v1.1-breezy*</td>\n",
              "      <td>74.0</td>\n",
              "      <td>75.1</td>\n",
              "      <td>63.2</td>\n",
              "      <td>63.6</td>\n",
              "      <td>55.4</td>\n",
              "      <td>34.9</td>\n",
              "      <td>38.4</td>\n",
              "      <td>SL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GPT4AIIL-J v1.2-jazzy*</td>\n",
              "      <td>74.8</td>\n",
              "      <td>74.9</td>\n",
              "      <td>63.6</td>\n",
              "      <td>638</td>\n",
              "      <td>56.6</td>\n",
              "      <td>35.3</td>\n",
              "      <td>41</td>\n",
              "      <td>58.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GPT4AII-J v1.3-groovy*</td>\n",
              "      <td>73.6</td>\n",
              "      <td>74.3</td>\n",
              "      <td>63.8</td>\n",
              "      <td>63.5</td>\n",
              "      <td>57.7</td>\n",
              "      <td>35</td>\n",
              "      <td>38.8 ©</td>\n",
              "      <td>58.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GPT4AII-J Lora 6B*</td>\n",
              "      <td>68.6</td>\n",
              "      <td>75.8</td>\n",
              "      <td>66.2</td>\n",
              "      <td>63.5</td>\n",
              "      <td>56.4</td>\n",
              "      <td>35.7</td>\n",
              "      <td>402</td>\n",
              "      <td>58.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3566fd92-f610-46bc-a07d-8cb21e9fbe79')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3566fd92-f610-46bc-a07d-8cb21e9fbe79 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3566fd92-f610-46bc-a07d-8cb21e9fbe79');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7f39a89c-bfaa-47e0-8ffc-ef1bb78cd6b0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7f39a89c-bfaa-47e0-8ffc-ef1bb78cd6b0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7f39a89c-bfaa-47e0-8ffc-ef1bb78cd6b0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 36,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 36,\n        \"samples\": [\n          \"Falcon 7b instruct (Almazrouei et al., 2023)\",\n          \"Alpaca 7B* (Taori et al. , 2023) Alpaca Lora 7B* 2023)\",\n          \"Open Assistant Pythia 12B*\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BoolQ\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15720914.601449972,\n        \"min\": 56.7,\n        \"max\": 94325793.0,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          784.0,\n          68.5,\n          67.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PIQA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 159.68160615593087,\n        \"min\": 3.0,\n        \"max\": 772.0,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          74.2,\n          76.3,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HellaSwag\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 34,\n        \"samples\": [\n          \"76.2\",\n          \"70.7\",\n          \"77.2.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WinoG.\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31,\n        \"samples\": [\n          \"665\",\n          \"63.8\",\n          \"65\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ARC-c\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33,\n        \"samples\": [\n          \"58.7\",\n          \"60\",\n          \"70\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ARC-c.1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"40.5\",\n          \"414\",\n          \"27\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OBQA\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"44\",\n          \"422\",\n          \"42.8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31,\n        \"samples\": [\n          \"617\",\n          \"63.0\",\n          \"62.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    }
  ]
}