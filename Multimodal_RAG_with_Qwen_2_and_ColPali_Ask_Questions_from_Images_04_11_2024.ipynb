{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHPl2/1mUpXWHrgNXTXon8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preetamjumech/LLM/blob/main/Multimodal_RAG_with_Qwen_2_and_ColPali_Ask_Questions_from_Images_04_11_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGEiFYFSH-lu"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade git+https://github.com/huggingface/transformers.git byaldi accelerate flash-attn qwen_vl_utils pdf2image\n",
        "!sudo apt-get install -y poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from byaldi import RAGMultiModalModel\n",
        "from transformers import Qwen2VLForConditionalGeneration,AutoTokenizer, AutoProcessor\n",
        "from qwen_vl_utils import process_vision_info\n",
        "import torch\n",
        "from pdf2image import convert_from_path\n",
        "import os"
      ],
      "metadata": {
        "id": "j-Qmfo_DjdKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_engine = RAGMultiModalModel.from_pretrained(\"vidore/colpali\")\n",
        "vlm = Qwen2VLForConditionalGeneration.from_pretrained(\n",
        "    \"Qwen/Qwen2-VL-7B-Instruct\",\n",
        "    torch_dtype = torch.bfloat16,\n",
        "    attn_implementation = \"flash_attention_2\",\n",
        "    device_map = \"cuda\"\n",
        ")\n",
        ""
      ],
      "metadata": {
        "id": "D7GVHQTTjdNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_engine.index(\n",
        "    input_path = \"docs.pdf\",\n",
        "    index_name = \"index\",\n",
        "    store_collection_with_index=False,\n",
        "    overwrite=True\n",
        ")"
      ],
      "metadata": {
        "id": "m8OXJ8z4jdPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_query = \"\"\"\n",
        "What all Lymph node stations are visible in the case study?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9im4sykkjdSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = rag_engine.search(text_query, k=3)\n",
        "results"
      ],
      "metadata": {
        "id": "2sGZnnCijdUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = convert_from_path(\"docs.pdf\")\n",
        "image_index = results[0][\"page_num\"] - 1"
      ],
      "metadata": {
        "id": "Wgnd3_0NjdWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_index"
      ],
      "metadata": {
        "id": "BT4T1z69jdZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\", trust_remote_code=True)\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\n",
        "                \"type\": \"image\",\n",
        "                \"image\": images[image_index],\n",
        "            },\n",
        "            {\"type\": \"text\", \"text\": text_query},\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "text = processor.apply_chat_template(\n",
        "    messages, tokenize=False, add_generation_prompt=True\n",
        ")\n",
        "\n",
        "image_inputs, video_inputs = process_vision_info(messages)\n",
        "inputs = processor(\n",
        "    text=[text],\n",
        "    images=image_inputs,\n",
        "    videos=video_inputs,\n",
        "    padding=True,\n",
        "    return_tensors=\"pt\",\n",
        ")\n",
        "inputs = inputs.to(\"cuda\")\n",
        "\n",
        "\n",
        "generated_ids = vlm.generate(**inputs, max_new_tokens=512)\n",
        "generated_ids_trimmed = [\n",
        "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "]\n",
        "output_text = processor.batch_decode(\n",
        "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        ")\n",
        "print(output_text)"
      ],
      "metadata": {
        "id": "St_iDnzQjdbs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}