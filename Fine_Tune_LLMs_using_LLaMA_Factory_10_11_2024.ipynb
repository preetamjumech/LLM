{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNVsqaIbDwfjfgEUHtNMhQT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preetamjumech/LLM/blob/main/Fine_Tune_LLMs_using_LLaMA_Factory_10_11_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OUYwt8MGgwv",
        "outputId": "1deaad5d-bb06-4f47-c5d4-affe3188cf7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLaMA-Factory'...\n",
            "remote: Enumerating objects: 18819, done.\u001b[K\n",
            "remote: Counting objects: 100% (857/857), done.\u001b[K\n",
            "remote: Compressing objects: 100% (340/340), done.\u001b[K\n",
            "remote: Total 18819 (delta 531), reused 731 (delta 514), pack-reused 17962 (from 1)\u001b[K\n",
            "Receiving objects: 100% (18819/18819), 231.24 MiB | 18.58 MiB/s, done.\n",
            "Resolving deltas: 100% (13709/13709), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hiyouga/LLaMA-Factory.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd LLaMA-Factory/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrEFniQDKOqk",
        "outputId": "e5b7689d-0ee6-4d2d-9353-61a372bdab9a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLaMA-Factory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMboGOzSKOtj",
        "outputId": "82d9cdd1-2134-49c6-d792-68d27df9e130"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLaMA-Factory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCKdHhSAKOvr",
        "outputId": "60d3cb17-6b68-411b-f8b6-11e4ecd9f4cb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers<=4.46.1,>=4.41.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.44.2)\n",
            "Collecting datasets<=3.1.0,>=2.16.0 (from -r requirements.txt (line 2))\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: accelerate<=1.0.1,>=0.34.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.34.2)\n",
            "Collecting peft<=0.12.0,>=0.11.1 (from -r requirements.txt (line 4))\n",
            "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting trl<=0.9.6,>=0.8.6 (from -r requirements.txt (line 5))\n",
            "  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting gradio<5.0.0,>=4.0.0 (from -r requirements.txt (line 6))\n",
            "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.13.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.8.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.2.0)\n",
            "Collecting tiktoken (from -r requirements.txt (line 11))\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (3.20.3)\n",
            "Collecting uvicorn (from -r requirements.txt (line 13))\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (2.9.2)\n",
            "Collecting fastapi (from -r requirements.txt (line 15))\n",
            "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting sse-starlette (from -r requirements.txt (line 16))\n",
            "  Downloading sse_starlette-2.1.3-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (3.8.0)\n",
            "Collecting fire (from -r requirements.txt (line 18))\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (24.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (6.0.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (1.26.4)\n",
            "Collecting av (from -r requirements.txt (line 22))\n",
            "  Downloading av-13.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (0.24.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2))\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2))\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (3.10.10)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (2.5.0+cu121)\n",
            "Collecting tyro>=0.5.11 (from trl<=0.9.6,>=0.8.6->-r requirements.txt (line 5))\n",
            "  Downloading tyro-0.8.14-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (3.7.1)\n",
            "Collecting ffmpy (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (0.27.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (3.10.10)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (10.4.0)\n",
            "Collecting pydub (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading python_multipart-0.0.17-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (2.2.3)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2024.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->-r requirements.txt (line 13)) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->-r requirements.txt (line 13)) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 14)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 14)) (2.23.4)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi->-r requirements.txt (line 15))\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (3.2.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 18)) (2.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (1.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (1.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (13.9.3)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->-r requirements.txt (line 5)) (0.16)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->-r requirements.txt (line 5))\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (2.18.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (0.1.2)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-2.1.3-py3-none-any.whl (9.4 kB)\n",
            "Downloading av-13.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.17-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.8.14-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=ac01a69791c27ddddf8a359572f16d1566f6b6727f79397736a5006083cb91ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built fire\n",
            "Installing collected packages: pydub, xxhash, websockets, uvicorn, tomlkit, shtab, semantic-version, ruff, python-multipart, markupsafe, fsspec, fire, ffmpy, dill, av, aiofiles, tiktoken, starlette, multiprocess, tyro, sse-starlette, gradio-client, fastapi, gradio, peft, datasets, trl\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.13.2\n",
            "    Uninstalling peft-0.13.2:\n",
            "      Successfully uninstalled peft-0.13.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 av-13.1.0 datasets-3.1.0 dill-0.3.8 fastapi-0.115.4 ffmpy-0.4.0 fire-0.7.0 fsspec-2024.9.0 gradio-4.44.1 gradio-client-1.3.0 markupsafe-2.1.5 multiprocess-0.70.16 peft-0.12.0 pydub-0.25.1 python-multipart-0.0.17 ruff-0.7.3 semantic-version-2.10.0 shtab-1.7.1 sse-starlette-2.1.3 starlette-0.41.2 tiktoken-0.8.0 tomlkit-0.12.0 trl-0.9.6 tyro-0.8.14 uvicorn-0.32.0 websockets-12.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgmstmGUKOx8",
        "outputId": "a097558a-9e61-4cc5-a6e8-dd5935d82d35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.44.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e \".[torch,metrics]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jcaIZtVMVCSF",
        "outputId": "168dc921-a6b8-4220-c50d-86ddad5576c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/LLaMA-Factory\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<=4.46.1,>=4.41.2 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (4.44.2)\n",
            "Requirement already satisfied: datasets<=3.1.0,>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (3.1.0)\n",
            "Requirement already satisfied: accelerate<=1.0.1,>=0.34.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.34.2)\n",
            "Requirement already satisfied: peft<=0.12.0,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.12.0)\n",
            "Requirement already satisfied: trl<=0.9.6,>=0.8.6 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.9.6)\n",
            "Requirement already satisfied: gradio<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (4.44.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (1.13.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.8.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.2.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.8.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (3.20.3)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.32.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.9.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.115.4)\n",
            "Requirement already satisfied: sse-starlette in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.1.3)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (3.8.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (24.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (6.0.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (1.26.4)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (13.1.0)\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.5.0+cu121)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (3.8.1)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.42.1)\n",
            "Collecting rouge-chinese (from llamafactory==0.9.1.dev0)\n",
            "  Downloading rouge_chinese-1.0.3-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate<=1.0.1,>=0.34.0->llamafactory==0.9.1.dev0) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<=1.0.1,>=0.34.0->llamafactory==0.9.1.dev0) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate<=1.0.1,>=0.34.0->llamafactory==0.9.1.dev0) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.10.10)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (3.7.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (0.27.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (3.10.10)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (10.4.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (0.0.17)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (0.7.3)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (2.2.3)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (12.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->llamafactory==0.9.1.dev0) (0.41.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->llamafactory==0.9.1.dev0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->llamafactory==0.9.1.dev0) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.9.1.dev0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.9.1.dev0) (2.23.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.1->llamafactory==0.9.1.dev0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.46.1,>=4.41.2->llamafactory==0.9.1.dev0) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.46.1,>=4.41.2->llamafactory==0.9.1.dev0) (0.19.1)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl<=0.9.6,>=0.8.6->llamafactory==0.9.1.dev0) (0.8.14)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.9.1.dev0) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.9.1.dev0) (0.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory==0.9.1.dev0) (2.5.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->llamafactory==0.9.1.dev0) (1.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge-chinese->llamafactory==0.9.1.dev0) (1.16.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (1.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (1.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.4.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (13.9.3)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->llamafactory==0.9.1.dev0) (0.16)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->llamafactory==0.9.1.dev0) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (2.18.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets<=3.1.0,>=2.16.0->llamafactory==0.9.1.dev0) (0.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->llamafactory==0.9.1.dev0) (0.1.2)\n",
            "Downloading rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\n",
            "Building wheels for collected packages: llamafactory\n",
            "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llamafactory: filename=llamafactory-0.9.1.dev0-0.editable-py3-none-any.whl size=23000 sha256=1cb6b5fe6bf6b5b59f7e1eba31af153d76f731f440b8c6f0196ea10475aea6f5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4fkxrqba/wheels/de/aa/c5/27b5682c5592b7c0eecc3e208f176dedf6b11a61cf2a910b85\n",
            "Successfully built llamafactory\n",
            "Installing collected packages: rouge-chinese, llamafactory\n",
            "Successfully installed llamafactory-0.9.1.dev0 rouge-chinese-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(token=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCMf9a1JYDJW",
        "outputId": "4ee9d6f4-fa81-4d5a-dba7-e33f8593a759"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python src/webui.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXCyoIjbKO2y",
        "outputId": "ba02376c-d2a5-44a3-fe27-6880e585cf50"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-10 14:01:05.314400: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-10 14:01:05.333870: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-10 14:01:05.339662: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-10 14:01:05.353626: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-10 14:01:06.664098: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Running on local URL:  http://0.0.0.0:7860\n",
            "Running on public URL: https://45b02ef0af63ec31d0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "2024-11-10 14:03:12.959290: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-10 14:03:12.998360: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-10 14:03:13.009017: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-10 14:03:14.766594: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[WARNING|2024-11-10 14:03:20] llamafactory.hparams.parser:162 >> We recommend enable `upcast_layernorm` in quantized training.\n",
            "[INFO|2024-11-10 14:03:20] llamafactory.hparams.parser:355 >> Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.bfloat16\n",
            "config.json: 100% 571/571 [00:00<00:00, 3.74MB/s]\n",
            "[INFO|configuration_utils.py:733] 2024-11-10 14:03:20,833 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-11-10 14:03:20,837 >> Model config MistralConfig {\n",
            "  \"_name_or_path\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"sliding_window\": 4096,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "tokenizer_config.json: 100% 2.10k/2.10k [00:00<00:00, 14.4MB/s]\n",
            "tokenizer.model: 100% 493k/493k [00:00<00:00, 16.7MB/s]\n",
            "tokenizer.json: 100% 1.80M/1.80M [00:00<00:00, 9.01MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 2.74MB/s]\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:03:22,040 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/tokenizer.model\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:03:22,040 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:03:22,041 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:03:22,041 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:03:22,041 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/tokenizer_config.json\n",
            "[INFO|configuration_utils.py:733] 2024-11-10 14:03:22,515 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-11-10 14:03:22,516 >> Model config MistralConfig {\n",
            "  \"_name_or_path\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"sliding_window\": 4096,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:03:22,609 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/tokenizer.model\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:03:22,609 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:03:22,609 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:03:22,609 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:03:22,609 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/tokenizer_config.json\n",
            "[INFO|2024-11-10 14:03:22] llamafactory.data.template:157 >> Add pad token: </s>\n",
            "[INFO|2024-11-10 14:03:22] llamafactory.data.loader:157 >> Loading dataset MattCoddity/dockerNLcommands...\n",
            "README.md: 100% 1.46k/1.46k [00:00<00:00, 8.25MB/s]\n",
            "06102023.json: 100% 543k/543k [00:00<00:00, 4.31MB/s]\n",
            "Generating train split: 100% 2415/2415 [00:00<00:00, 35133.66 examples/s]\n",
            "Converting format of dataset (num_proc=16): 100% 100/100 [00:00<00:00, 221.08 examples/s]\n",
            "Running tokenizer on dataset (num_proc=16): 100% 100/100 [00:03<00:00, 29.63 examples/s]\n",
            "training example:\n",
            "input_ids:\n",
            "[1, 733, 16289, 28793, 17824, 456, 12271, 297, 281, 14295, 3445, 13, 28777, 495, 528, 264, 1274, 302, 25399, 369, 506, 272, 500, 28726, 2794, 28718, 3469, 390, 652, 14014, 271, 28723, 733, 28748, 16289, 28793, 281, 14295, 12384, 1939, 4650, 464, 834, 374, 271, 28746, 437, 2794, 28718, 28742, 2]\n",
            "inputs:\n",
            "<s> [INST] translate this sentence in docker command\n",
            "Give me a list of containers that have the Ubuntu image as their ancestor. [/INST] docker ps --filter 'ancestor=ubuntu'</s>\n",
            "label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 281, 14295, 12384, 1939, 4650, 464, 834, 374, 271, 28746, 437, 2794, 28718, 28742, 2]\n",
            "labels:\n",
            "docker ps --filter 'ancestor=ubuntu'</s>\n",
            "[INFO|configuration_utils.py:733] 2024-11-10 14:03:29,761 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-11-10 14:03:29,763 >> Model config MistralConfig {\n",
            "  \"_name_or_path\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"sliding_window\": 4096,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "[INFO|2024-11-10 14:03:29] llamafactory.model.model_utils.quantization:157 >> Quantizing model to 4 bit with bitsandbytes.\n",
            "model.safetensors.index.json: 100% 25.1k/25.1k [00:00<00:00, 80.8MB/s]\n",
            "[INFO|modeling_utils.py:3678] 2024-11-10 14:03:30,363 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/model.safetensors.index.json\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/9.94G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 31.5M/9.94G [00:00<00:40, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 62.9M/9.94G [00:00<00:39, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 94.4M/9.94G [00:00<00:39, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 126M/9.94G [00:00<00:39, 250MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 157M/9.94G [00:00<00:39, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 189M/9.94G [00:00<00:39, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 220M/9.94G [00:00<00:39, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 252M/9.94G [00:01<00:39, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 283M/9.94G [00:01<01:08, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 304M/9.94G [00:01<01:03, 151MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 336M/9.94G [00:01<00:54, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 367M/9.94G [00:01<00:48, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 398M/9.94G [00:01<00:45, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 430M/9.94G [00:02<00:42, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 461M/9.94G [00:02<00:39, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 493M/9.94G [00:02<00:43, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 524M/9.94G [00:02<00:40, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 556M/9.94G [00:02<00:38, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 587M/9.94G [00:02<00:37, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 619M/9.94G [00:02<00:41, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 650M/9.94G [00:02<00:41, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 682M/9.94G [00:03<00:44, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 713M/9.94G [00:03<00:45, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 734M/9.94G [00:03<00:47, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 755M/9.94G [00:03<00:51, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 776M/9.94G [00:03<00:52, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 797M/9.94G [00:03<00:52, 173MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 818M/9.94G [00:03<00:53, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 839M/9.94G [00:04<00:57, 160MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 860M/9.94G [00:04<00:56, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 881M/9.94G [00:04<00:59, 153MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 912M/9.94G [00:04<00:49, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 944M/9.94G [00:04<00:44, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 975M/9.94G [00:04<00:42, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 1.01G/9.94G [00:04<00:40, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 1.04G/9.94G [00:05<00:40, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.07G/9.94G [00:05<00:41, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.10G/9.94G [00:05<00:38, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.13G/9.94G [00:05<00:36, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.16G/9.94G [00:05<00:35, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.20G/9.94G [00:05<00:35, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.23G/9.94G [00:05<00:36, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.26G/9.94G [00:05<00:35, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.29G/9.94G [00:06<00:34, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.32G/9.94G [00:06<00:34, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.35G/9.94G [00:06<00:34, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.38G/9.94G [00:06<00:34, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.42G/9.94G [00:06<00:34, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.45G/9.94G [00:06<00:34, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.48G/9.94G [00:06<00:33, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.51G/9.94G [00:06<00:34, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.54G/9.94G [00:07<00:35, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.57G/9.94G [00:07<00:35, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.60G/9.94G [00:07<00:33, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.64G/9.94G [00:07<00:33, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.67G/9.94G [00:07<00:35, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.70G/9.94G [00:07<00:35, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.73G/9.94G [00:07<00:33, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.76G/9.94G [00:08<00:33, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.79G/9.94G [00:08<00:33, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.82G/9.94G [00:08<00:35, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.86G/9.94G [00:08<00:32, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.89G/9.94G [00:08<00:33, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.92G/9.94G [00:08<00:41, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.95G/9.94G [00:08<00:38, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.98G/9.94G [00:09<00:36, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.01G/9.94G [00:09<00:35, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.04G/9.94G [00:09<00:35, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.08G/9.94G [00:09<00:35, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.11G/9.94G [00:09<00:33, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.14G/9.94G [00:09<00:35, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.17G/9.94G [00:09<00:35, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.20G/9.94G [00:10<00:36, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.23G/9.94G [00:10<00:36, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.26G/9.94G [00:10<00:35, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.30G/9.94G [00:10<00:37, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.32G/9.94G [00:10<00:37, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.35G/9.94G [00:10<00:36, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.38G/9.94G [00:10<00:35, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.41G/9.94G [00:11<00:35, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.44G/9.94G [00:11<00:34, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.47G/9.94G [00:11<00:32, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.51G/9.94G [00:11<00:33, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.54G/9.94G [00:11<00:35, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.57G/9.94G [00:11<00:35, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.59G/9.94G [00:11<00:35, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.62G/9.94G [00:11<00:32, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.65G/9.94G [00:12<00:31, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.68G/9.94G [00:12<00:32, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.72G/9.94G [00:12<00:35, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.75G/9.94G [00:12<00:37, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.78G/9.94G [00:12<00:34, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.81G/9.94G [00:12<00:33, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.84G/9.94G [00:13<00:35, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.87G/9.94G [00:13<00:34, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.90G/9.94G [00:13<00:31, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.94G/9.94G [00:13<00:35, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.97G/9.94G [00:13<00:34, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.00G/9.94G [00:13<00:34, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.02G/9.94G [00:13<00:35, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.04G/9.94G [00:14<00:36, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.06G/9.94G [00:14<00:35, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.09G/9.94G [00:14<00:33, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.11G/9.94G [00:14<00:33, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.15G/9.94G [00:14<00:31, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.18G/9.94G [00:14<00:29, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.21G/9.94G [00:14<00:31, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.25G/9.94G [00:14<00:27, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.28G/9.94G [00:15<00:27, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.31G/9.94G [00:15<00:28, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.34G/9.94G [00:15<00:27, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.38G/9.94G [00:15<00:34, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.41G/9.94G [00:15<00:32, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.44G/9.94G [00:15<00:32, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.47G/9.94G [00:16<00:31, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.50G/9.94G [00:16<00:29, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.53G/9.94G [00:16<00:27, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.57G/9.94G [00:16<00:34, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.60G/9.94G [00:16<00:31, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.63G/9.94G [00:16<00:29, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.66G/9.94G [00:16<00:28, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.69G/9.94G [00:17<00:28, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.72G/9.94G [00:17<00:26, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.75G/9.94G [00:17<00:25, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.79G/9.94G [00:17<00:34, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.82G/9.94G [00:17<00:31, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.85G/9.94G [00:17<00:29, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.88G/9.94G [00:17<00:27, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.91G/9.94G [00:18<00:26, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.94G/9.94G [00:18<00:26, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.97G/9.94G [00:18<00:25, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.01G/9.94G [00:18<00:32, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.04G/9.94G [00:18<00:29, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.07G/9.94G [00:19<00:40, 146MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.10G/9.94G [00:19<00:34, 169MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.13G/9.94G [00:19<00:30, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.16G/9.94G [00:19<00:27, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.19G/9.94G [00:19<00:26, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.23G/9.94G [00:19<00:25, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.26G/9.94G [00:19<00:24, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.29G/9.94G [00:19<00:23, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.32G/9.94G [00:22<02:57, 31.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.35G/9.94G [00:23<02:09, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.38G/9.94G [00:23<01:36, 57.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.41G/9.94G [00:23<01:14, 74.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.45G/9.94G [00:23<00:59, 92.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.48G/9.94G [00:23<00:48, 113MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.51G/9.94G [00:23<00:39, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.54G/9.94G [00:23<00:34, 159MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.57G/9.94G [00:23<00:30, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.60G/9.94G [00:24<00:27, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.63G/9.94G [00:24<00:25, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.67G/9.94G [00:24<00:24, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.70G/9.94G [00:24<00:23, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.73G/9.94G [00:24<00:22, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.76G/9.94G [00:24<00:21, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.79G/9.94G [00:24<00:21, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.82G/9.94G [00:25<00:22, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.85G/9.94G [00:25<00:22, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.89G/9.94G [00:25<00:21, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.92G/9.94G [00:25<00:21, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.95G/9.94G [00:25<00:21, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.98G/9.94G [00:25<00:21, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.01G/9.94G [00:25<00:22, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.04G/9.94G [00:26<00:22, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.08G/9.94G [00:26<00:23, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.11G/9.94G [00:26<00:23, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.13G/9.94G [00:26<00:23, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.16G/9.94G [00:26<00:22, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.19G/9.94G [00:26<00:22, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.22G/9.94G [00:26<00:22, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.24G/9.94G [00:26<00:23, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.27G/9.94G [00:27<00:22, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.31G/9.94G [00:27<00:22, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.34G/9.94G [00:27<00:20, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.37G/9.94G [00:27<00:19, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.40G/9.94G [00:27<00:20, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.43G/9.94G [00:27<00:19, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.46G/9.94G [00:27<00:19, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.49G/9.94G [00:28<00:19, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.53G/9.94G [00:28<00:20, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.56G/9.94G [00:28<00:19, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.59G/9.94G [00:28<00:18, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.62G/9.94G [00:28<00:18, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.65G/9.94G [00:28<00:20, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.68G/9.94G [00:28<00:21, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.70G/9.94G [00:29<00:21, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.73G/9.94G [00:29<00:22, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.75G/9.94G [00:29<00:22, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.78G/9.94G [00:29<00:21, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.81G/9.94G [00:29<00:19, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.84G/9.94G [00:29<00:17, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.87G/9.94G [00:29<00:17, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.90G/9.94G [00:29<00:17, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.93G/9.94G [00:30<00:16, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.97G/9.94G [00:30<00:15, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.00G/9.94G [00:33<02:04, 31.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.03G/9.94G [00:33<01:30, 43.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.06G/9.94G [00:33<01:07, 57.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.09G/9.94G [00:33<00:52, 73.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.12G/9.94G [00:33<00:41, 91.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.16G/9.94G [00:33<00:33, 112MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.19G/9.94G [00:34<00:28, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.22G/9.94G [00:34<00:23, 158MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.25G/9.94G [00:34<00:20, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.28G/9.94G [00:34<00:18, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.31G/9.94G [00:34<00:17, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.34G/9.94G [00:34<00:16, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.38G/9.94G [00:34<00:15, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.41G/9.94G [00:34<00:15, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.44G/9.94G [00:34<00:14, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.47G/9.94G [00:35<00:14, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.50G/9.94G [00:35<00:14, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.53G/9.94G [00:35<00:13, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.56G/9.94G [00:35<00:14, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.60G/9.94G [00:35<00:13, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.63G/9.94G [00:35<00:13, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.66G/9.94G [00:35<00:13, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.69G/9.94G [00:36<00:13, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.72G/9.94G [00:36<00:12, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.75G/9.94G [00:36<00:12, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.78G/9.94G [00:36<00:12, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.82G/9.94G [00:36<00:12, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.85G/9.94G [00:36<00:12, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.88G/9.94G [00:36<00:12, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.91G/9.94G [00:36<00:12, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.94G/9.94G [00:37<00:12, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.97G/9.94G [00:37<00:12, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 7.00G/9.94G [00:37<00:12, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.04G/9.94G [00:37<00:11, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.07G/9.94G [00:37<00:11, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.10G/9.94G [00:37<00:11, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.13G/9.94G [00:37<00:11, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.16G/9.94G [00:37<00:11, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.19G/9.94G [00:38<00:11, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.22G/9.94G [00:38<00:10, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.26G/9.94G [00:38<00:10, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.29G/9.94G [00:38<00:10, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.32G/9.94G [00:38<00:11, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.35G/9.94G [00:38<00:10, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.38G/9.94G [00:38<00:10, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.41G/9.94G [00:38<00:10, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.44G/9.94G [00:39<00:09, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.48G/9.94G [00:39<00:09, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.51G/9.94G [00:39<00:09, 268MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.54G/9.94G [00:39<00:09, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.57G/9.94G [00:39<00:09, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.60G/9.94G [00:39<00:09, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.63G/9.94G [00:39<00:09, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.67G/9.94G [00:40<00:14, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.70G/9.94G [00:40<00:12, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.73G/9.94G [00:40<00:10, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.76G/9.94G [00:40<00:10, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.79G/9.94G [00:40<00:11, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.81G/9.94G [00:40<00:11, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.84G/9.94G [00:41<00:10, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.87G/9.94G [00:41<00:10, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.91G/9.94G [00:41<00:09, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.94G/9.94G [00:41<00:09, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.97G/9.94G [00:41<00:08, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 8.00G/9.94G [00:41<00:08, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.03G/9.94G [00:41<00:08, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.06G/9.94G [00:41<00:08, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.10G/9.94G [00:42<00:07, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.13G/9.94G [00:42<00:08, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.16G/9.94G [00:42<00:08, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.19G/9.94G [00:42<00:08, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.22G/9.94G [00:42<00:08, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.25G/9.94G [00:42<00:07, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.28G/9.94G [00:42<00:07, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.32G/9.94G [00:43<00:07, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.35G/9.94G [00:43<00:07, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.38G/9.94G [00:43<00:06, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.41G/9.94G [00:43<00:06, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.44G/9.94G [00:43<00:06, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.47G/9.94G [00:43<00:07, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.49G/9.94G [00:43<00:07, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.52G/9.94G [00:44<00:06, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.56G/9.94G [00:44<00:06, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.59G/9.94G [00:44<00:06, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.62G/9.94G [00:44<00:06, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.64G/9.94G [00:44<00:06, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.67G/9.94G [00:44<00:05, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.70G/9.94G [00:47<00:37, 33.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.75G/9.94G [00:47<00:24, 49.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.78G/9.94G [00:47<00:18, 64.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.81G/9.94G [00:47<00:13, 81.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.84G/9.94G [00:48<00:11, 99.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.87G/9.94G [00:48<00:08, 121MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.90G/9.94G [00:48<00:07, 143MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.93G/9.94G [00:48<00:06, 163MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.97G/9.94G [00:48<00:05, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 9.00G/9.94G [00:48<00:04, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.03G/9.94G [00:48<00:04, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.06G/9.94G [00:48<00:04, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.09G/9.94G [00:49<00:03, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.12G/9.94G [00:49<00:03, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.15G/9.94G [00:49<00:03, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.19G/9.94G [00:49<00:03, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.22G/9.94G [00:49<00:02, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.25G/9.94G [00:49<00:02, 262MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.28G/9.94G [00:49<00:02, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.31G/9.94G [00:49<00:02, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.34G/9.94G [00:50<00:02, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.37G/9.94G [00:50<00:02, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.41G/9.94G [00:50<00:02, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.44G/9.94G [00:50<00:02, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.47G/9.94G [00:50<00:01, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.50G/9.94G [00:50<00:01, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.53G/9.94G [00:50<00:01, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.56G/9.94G [00:50<00:01, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.59G/9.94G [00:51<00:01, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.63G/9.94G [00:51<00:01, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.66G/9.94G [00:51<00:01, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.69G/9.94G [00:51<00:01, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.72G/9.94G [00:51<00:00, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.75G/9.94G [00:51<00:01, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.78G/9.94G [00:51<00:00, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.81G/9.94G [00:52<00:00, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.85G/9.94G [00:52<00:00, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.88G/9.94G [00:52<00:00, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.91G/9.94G [00:52<00:00, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.94G/9.94G [00:52<00:00, 189MB/s]\n",
            "Downloading shards:  50% 1/2 [00:52<00:52, 52.78s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/4.54G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 31.5M/4.54G [00:00<00:18, 238MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 62.9M/4.54G [00:00<00:18, 245MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 94.4M/4.54G [00:00<00:18, 236MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 126M/4.54G [00:00<00:18, 242MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 157M/4.54G [00:00<00:18, 240MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 189M/4.54G [00:00<00:19, 223MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 220M/4.54G [00:00<00:18, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 252M/4.54G [00:01<00:18, 236MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 283M/4.54G [00:04<02:58, 23.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 315M/4.54G [00:05<02:06, 33.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 346M/4.54G [00:05<01:32, 45.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 377M/4.54G [00:05<01:08, 60.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 409M/4.54G [00:05<00:52, 78.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 440M/4.54G [00:05<00:41, 97.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 472M/4.54G [00:05<00:33, 120MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 503M/4.54G [00:05<00:28, 142MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 535M/4.54G [00:05<00:24, 162MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 566M/4.54G [00:06<00:22, 175MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 598M/4.54G [00:06<00:20, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 629M/4.54G [00:10<02:53, 22.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 650M/4.54G [00:11<02:40, 24.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 682M/4.54G [00:11<01:51, 34.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 713M/4.54G [00:11<01:20, 47.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 744M/4.54G [00:11<01:00, 62.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 776M/4.54G [00:11<00:46, 80.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 807M/4.54G [00:11<00:36, 101MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 839M/4.54G [00:11<00:29, 124MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 870M/4.54G [00:12<00:24, 149MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 902M/4.54G [00:12<00:21, 167MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 933M/4.54G [00:12<00:20, 178MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 965M/4.54G [00:12<00:18, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 996M/4.54G [00:12<00:17, 208MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 1.03G/4.54G [00:12<00:16, 218MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 1.06G/4.54G [00:12<00:15, 221MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 1.09G/4.54G [00:12<00:15, 223MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 1.12G/4.54G [00:13<00:15, 214MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 1.15G/4.54G [00:13<00:15, 221MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 1.18G/4.54G [00:13<00:14, 236MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 1.22G/4.54G [00:13<00:14, 237MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 1.25G/4.54G [00:13<00:13, 238MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 1.28G/4.54G [00:13<00:14, 231MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 1.31G/4.54G [00:13<00:13, 243MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 1.34G/4.54G [00:14<00:12, 249MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 1.37G/4.54G [00:14<00:13, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.41G/4.54G [00:14<00:13, 240MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 1.44G/4.54G [00:14<00:17, 177MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 1.46G/4.54G [00:14<00:24, 125MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 1.48G/4.54G [00:15<00:22, 136MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 1.50G/4.54G [00:15<00:21, 142MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 1.52G/4.54G [00:15<00:19, 155MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.55G/4.54G [00:15<00:16, 182MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 1.58G/4.54G [00:15<00:15, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 1.61G/4.54G [00:15<00:13, 212MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 1.65G/4.54G [00:15<00:12, 224MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.68G/4.54G [00:15<00:12, 225MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 1.71G/4.54G [00:16<00:12, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 1.74G/4.54G [00:16<00:12, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.77G/4.54G [00:16<00:11, 243MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.80G/4.54G [00:16<00:11, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.84G/4.54G [00:16<00:12, 210MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 1.87G/4.54G [00:16<00:12, 213MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.90G/4.54G [00:16<00:12, 218MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.93G/4.54G [00:17<00:12, 210MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.96G/4.54G [00:17<00:11, 227MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.99G/4.54G [00:21<01:54, 22.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 2.03G/4.54G [00:21<01:14, 33.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 2.07G/4.54G [00:21<00:55, 44.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 2.10G/4.54G [00:21<00:42, 57.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 2.13G/4.54G [00:22<00:33, 72.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 2.16G/4.54G [00:22<00:26, 91.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 2.19G/4.54G [00:22<00:20, 112MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 2.22G/4.54G [00:22<00:17, 134MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 2.25G/4.54G [00:22<00:14, 156MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 2.29G/4.54G [00:22<00:12, 176MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 2.32G/4.54G [00:22<00:11, 192MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 2.35G/4.54G [00:22<00:10, 206MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 2.38G/4.54G [00:23<00:10, 206MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 2.41G/4.54G [00:23<00:09, 218MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 2.44G/4.54G [00:23<00:09, 225MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 2.47G/4.54G [00:23<00:08, 231MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 2.51G/4.54G [00:23<00:08, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 2.54G/4.54G [00:23<00:08, 232MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 2.57G/4.54G [00:23<00:08, 236MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 2.60G/4.54G [00:24<00:08, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.63G/4.54G [00:24<00:07, 239MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 2.66G/4.54G [00:24<00:07, 246MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 2.69G/4.54G [00:24<00:07, 247MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 2.73G/4.54G [00:24<00:07, 248MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 2.76G/4.54G [00:24<00:07, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 2.79G/4.54G [00:24<00:07, 244MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 2.82G/4.54G [00:24<00:06, 247MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 2.85G/4.54G [00:25<00:06, 244MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.88G/4.54G [00:25<00:06, 239MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.92G/4.54G [00:25<00:06, 248MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 2.95G/4.54G [00:25<00:06, 246MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 2.98G/4.54G [00:25<00:06, 251MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 3.01G/4.54G [00:25<00:06, 237MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 3.04G/4.54G [00:25<00:06, 236MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 3.07G/4.54G [00:25<00:06, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 3.10G/4.54G [00:26<00:05, 240MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 3.14G/4.54G [00:26<00:05, 244MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 3.17G/4.54G [00:26<00:05, 243MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 3.20G/4.54G [00:26<00:05, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 3.23G/4.54G [00:26<00:05, 245MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 3.26G/4.54G [00:26<00:05, 245MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 3.29G/4.54G [00:26<00:05, 246MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 3.32G/4.54G [00:27<00:04, 256MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 3.36G/4.54G [00:27<00:04, 254MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 3.39G/4.54G [00:27<00:04, 243MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 3.42G/4.54G [00:27<00:04, 248MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 3.45G/4.54G [00:27<00:04, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 3.48G/4.54G [00:27<00:04, 240MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 3.51G/4.54G [00:27<00:04, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 3.54G/4.54G [00:27<00:04, 243MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 3.58G/4.54G [00:28<00:03, 253MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 3.61G/4.54G [00:28<00:03, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 3.64G/4.54G [00:28<00:03, 245MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 3.67G/4.54G [00:28<00:03, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 3.70G/4.54G [00:28<00:03, 242MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 3.73G/4.54G [00:28<00:03, 245MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 3.76G/4.54G [00:28<00:03, 247MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 3.80G/4.54G [00:28<00:03, 237MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 3.83G/4.54G [00:29<00:03, 221MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 3.86G/4.54G [00:29<00:02, 239MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 3.89G/4.54G [00:29<00:02, 227MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 3.92G/4.54G [00:29<00:02, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.95G/4.54G [00:29<00:02, 246MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 3.98G/4.54G [00:29<00:02, 230MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 4.02G/4.54G [00:29<00:02, 221MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 4.05G/4.54G [00:30<00:02, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 4.08G/4.54G [00:30<00:02, 221MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 4.11G/4.54G [00:31<00:05, 76.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 4.14G/4.54G [00:31<00:04, 94.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 4.16G/4.54G [00:31<00:03, 106MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 4.18G/4.54G [00:31<00:02, 120MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 4.20G/4.54G [00:31<00:02, 132MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 4.24G/4.54G [00:31<00:01, 152MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 4.27G/4.54G [00:32<00:01, 168MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 4.30G/4.54G [00:32<00:01, 188MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 4.33G/4.54G [00:32<00:01, 204MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 4.36G/4.54G [00:32<00:00, 215MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 4.39G/4.54G [00:32<00:00, 224MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 4.42G/4.54G [00:32<00:00, 225MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 4.46G/4.54G [00:32<00:00, 223MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 4.49G/4.54G [00:32<00:00, 232MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 4.54G/4.54G [00:33<00:00, 137MB/s]\n",
            "Downloading shards: 100% 2/2 [01:26<00:00, 43.04s/it]\n",
            "[INFO|modeling_utils.py:1606] 2024-11-10 14:04:56,449 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.\n",
            "[INFO|configuration_utils.py:1038] 2024-11-10 14:04:56,450 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2\n",
            "}\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [01:09<00:00, 34.55s/it]\n",
            "[INFO|modeling_utils.py:4507] 2024-11-10 14:06:06,267 >> All model checkpoint weights were used when initializing MistralForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:4515] 2024-11-10 14:06:06,267 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at mistralai/Mistral-7B-Instruct-v0.1.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\n",
            "generation_config.json: 100% 116/116 [00:00<00:00, 760kB/s]\n",
            "[INFO|configuration_utils.py:993] 2024-11-10 14:06:06,506 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/generation_config.json\n",
            "[INFO|configuration_utils.py:1038] 2024-11-10 14:06:06,506 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2\n",
            "}\n",
            "\n",
            "[INFO|2024-11-10 14:06:06] llamafactory.model.model_utils.checkpointing:157 >> Gradient checkpointing enabled.\n",
            "[INFO|2024-11-10 14:06:06] llamafactory.model.model_utils.attention:157 >> Using torch SDPA for faster training and inference.\n",
            "[INFO|2024-11-10 14:06:06] llamafactory.model.adapter:157 >> Upcasting trainable params to float32.\n",
            "[INFO|2024-11-10 14:06:06] llamafactory.model.adapter:157 >> Fine-tuning method: LoRA\n",
            "[INFO|2024-11-10 14:06:06] llamafactory.model.model_utils.misc:157 >> Found linear modules: up_proj,down_proj,v_proj,q_proj,k_proj,o_proj,gate_proj\n",
            "[INFO|2024-11-10 14:06:07] llamafactory.model.loader:157 >> trainable params: 20,971,520 || all params: 7,262,703,616 || trainable%: 0.2888\n",
            "[INFO|trainer.py:648] 2024-11-10 14:06:07,293 >> Using auto half precision backend\n",
            "[INFO|trainer.py:2134] 2024-11-10 14:06:07,701 >> ***** Running training *****\n",
            "[INFO|trainer.py:2135] 2024-11-10 14:06:07,701 >>   Num examples = 100\n",
            "[INFO|trainer.py:2136] 2024-11-10 14:06:07,701 >>   Num Epochs = 1\n",
            "[INFO|trainer.py:2137] 2024-11-10 14:06:07,701 >>   Instantaneous batch size per device = 4\n",
            "[INFO|trainer.py:2140] 2024-11-10 14:06:07,701 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "[INFO|trainer.py:2141] 2024-11-10 14:06:07,701 >>   Gradient Accumulation steps = 8\n",
            "[INFO|trainer.py:2142] 2024-11-10 14:06:07,702 >>   Total optimization steps = 3\n",
            "[INFO|trainer.py:2143] 2024-11-10 14:06:07,706 >>   Number of trainable parameters = 20,971,520\n",
            "100% 3/3 [02:19<00:00, 45.95s/it][INFO|trainer.py:3503] 2024-11-10 14:08:27,337 >> Saving model checkpoint to saves/Mistral-7B-Instruct-v0.1/lora/train_2024-11-10-14-01-24/checkpoint-3\n",
            "[INFO|configuration_utils.py:733] 2024-11-10 14:08:27,623 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-11-10 14:08:27,625 >> Model config MistralConfig {\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"sliding_window\": 4096,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2684] 2024-11-10 14:08:27,945 >> tokenizer config file saved in saves/Mistral-7B-Instruct-v0.1/lora/train_2024-11-10-14-01-24/checkpoint-3/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2693] 2024-11-10 14:08:27,946 >> Special tokens file saved in saves/Mistral-7B-Instruct-v0.1/lora/train_2024-11-10-14-01-24/checkpoint-3/special_tokens_map.json\n",
            "[INFO|trainer.py:2394] 2024-11-10 14:08:32,048 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 144.342, 'train_samples_per_second': 0.693, 'train_steps_per_second': 0.021, 'train_loss': 0.6835472583770752, 'epoch': 0.96, 'num_input_tokens_seen': 6112}\n",
            "100% 3/3 [02:24<00:00, 48.11s/it]\n",
            "[INFO|trainer.py:3503] 2024-11-10 14:08:32,050 >> Saving model checkpoint to saves/Mistral-7B-Instruct-v0.1/lora/train_2024-11-10-14-01-24\n",
            "[INFO|configuration_utils.py:733] 2024-11-10 14:08:32,284 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-11-10 14:08:32,285 >> Model config MistralConfig {\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"sliding_window\": 4096,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2684] 2024-11-10 14:08:32,524 >> tokenizer config file saved in saves/Mistral-7B-Instruct-v0.1/lora/train_2024-11-10-14-01-24/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2693] 2024-11-10 14:08:32,526 >> Special tokens file saved in saves/Mistral-7B-Instruct-v0.1/lora/train_2024-11-10-14-01-24/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =       0.96\n",
            "  num_input_tokens_seen    =       6112\n",
            "  total_flos               =   243569GF\n",
            "  train_loss               =     0.6835\n",
            "  train_runtime            = 0:02:24.34\n",
            "  train_samples_per_second =      0.693\n",
            "  train_steps_per_second   =      0.021\n",
            "[WARNING|2024-11-10 14:08:32] llamafactory.extras.ploting:162 >> No metric loss to plot.\n",
            "[WARNING|2024-11-10 14:08:32] llamafactory.extras.ploting:162 >> No metric eval_loss to plot.\n",
            "[WARNING|2024-11-10 14:08:32] llamafactory.extras.ploting:162 >> No metric eval_accuracy to plot.\n",
            "[INFO|modelcard.py:449] 2024-11-10 14:08:32,625 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n",
            "[INFO|configuration_utils.py:733] 2024-11-10 14:10:58,886 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-11-10 14:10:58,889 >> Model config MistralConfig {\n",
            "  \"_name_or_path\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"sliding_window\": 4096,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:10:58,977 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/tokenizer.model\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:10:58,977 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:10:58,977 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:10:58,977 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:10:58,977 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/tokenizer_config.json\n",
            "[INFO|configuration_utils.py:733] 2024-11-10 14:10:59,424 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-11-10 14:10:59,425 >> Model config MistralConfig {\n",
            "  \"_name_or_path\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"sliding_window\": 4096,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:10:59,510 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/tokenizer.model\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:10:59,510 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:10:59,510 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:10:59,510 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-11-10 14:10:59,510 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/tokenizer_config.json\n",
            "[INFO|2024-11-10 14:10:59] llamafactory.data.template:157 >> Add pad token: </s>\n",
            "[INFO|configuration_utils.py:733] 2024-11-10 14:10:59,667 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-11-10 14:10:59,668 >> Model config MistralConfig {\n",
            "  \"_name_or_path\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"sliding_window\": 4096,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "[INFO|2024-11-10 14:10:59] llamafactory.model.model_utils.quantization:157 >> Quantizing model to 4 bit with bitsandbytes.\n",
            "[INFO|2024-11-10 14:10:59] llamafactory.model.patcher:157 >> Using KV cache for faster generation.\n",
            "[INFO|modeling_utils.py:3678] 2024-11-10 14:10:59,724 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/model.safetensors.index.json\n",
            "[INFO|modeling_utils.py:1606] 2024-11-10 14:10:59,727 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.\n",
            "[INFO|configuration_utils.py:1038] 2024-11-10 14:10:59,729 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2\n",
            "}\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [01:06<00:00, 33.20s/it]\n",
            "[INFO|modeling_utils.py:4507] 2024-11-10 14:12:06,396 >> All model checkpoint weights were used when initializing MistralForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:4515] 2024-11-10 14:12:06,396 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at mistralai/Mistral-7B-Instruct-v0.1.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\n",
            "[INFO|configuration_utils.py:993] 2024-11-10 14:12:06,490 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/generation_config.json\n",
            "[INFO|configuration_utils.py:1038] 2024-11-10 14:12:06,490 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2\n",
            "}\n",
            "\n",
            "[INFO|2024-11-10 14:12:06] llamafactory.model.model_utils.attention:157 >> Using torch SDPA for faster training and inference.\n",
            "[INFO|2024-11-10 14:12:07] llamafactory.model.adapter:157 >> Loaded adapter(s): saves/Mistral-7B-Instruct-v0.1/lora/train_2024-11-10-14-01-24\n",
            "[INFO|2024-11-10 14:12:07] llamafactory.model.loader:157 >> all params: 7,262,703,616\n",
            "[WARNING|2024-11-10 14:12:07] llamafactory.chat.hf_engine:168 >> There is no current event loop, creating a new one.\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2709, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/LLaMA-Factory/src/webui.py\", line 28, in <module>\n",
            "    main()\n",
            "  File \"/content/LLaMA-Factory/src/webui.py\", line 24, in main\n",
            "    create_ui().queue().launch(share=True, server_name=server_name, inbrowser=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2614, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2713, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/http_server.py\", line 68, in close\n",
            "    self.thread.join(timeout=5)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1100, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 0.0.0.0:7860 <> https://45b02ef0af63ec31d0.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hjVcbjSGKO5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1sYGntlbKO70"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}